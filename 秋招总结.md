# 面试高频题

## 一、C++

### 1、C++基础知识

#### 1.1、指针

##### 1、指针函数和函数指针

###### 1）函数指针

​		本质是一个**指针**，该指针指向这个函数  int (*fun)(int x,int y);

​		函数指针指向的是特殊的数据类型，函数的类型是由其返回的数据类型和其参数列表共同决定的，而函数的名称则不是其类型的一部分。函数指针与数据项相似，函数也有地址，也就是说在同一个函数中通过使用相同的形参在不同的时间使用产生不同的效果。**一个函数名就是一个指针，它指向函数的代码，一个函数地址是该函数的进入点，也就是调用函数的地址**。函数的调用可以通过函数名，也可以通过指向函数的指针来调用，函数指针还运行将函数作为变元传递给其他函数。

```c++
int add(int x,int y){
    return x+y;
}
int sub(int x,int y){
    return x-y;
}
//函数指针
int (*fun)(int x,int y);
int main()
{
    //第一种写法
    fun = add; cout << "(*fun)(1,2) = " << (*fun)(1,2) ; //3
	//第二种写法
    fun = &sub; cout << "(*fun)(5,3) = " << (*fun)(5,3)  << fun(5,3)； //2 2
    return 0;
}
```

###### 2）指针函数

​		返回一个指针的函数，本质是一个**函数**，该函数的返回值是一个指针 int *fun(int x,int y);

```c++
typedef struct _Data{
    int a;
    int b;
}Data;
//指针函数
Data* f(int a,int b){
    Data * data = new Data;
    data->a = a;
    data->b = b;
    return data;
}
int main()
{
    //调用指针函数
    Data * myData = f(4,5);
    cout << "f(4,5) = " << myData->a << myData->b; //f(4,5) = 4 5
    return 0;
}
```

###### 3）举个例子

- int *p[10]表示指针数组，强调数组概念，是一个数组变量，数组大小为10，数组内每个元素都是指向int类型的指针变量。

- int (*p)[10]表示数组指针，强调是指针，只有一个变量，是指针类型，不过指向的是一个int类型的数组，这个数组大小是10。

- int *p(int)是函数声明，函数名是p，参数是int类型的，返回值是int *类型的。

- int (*p)(int)是函数指针，强调是指针，该指针指向的函数具有int类型参数，并且返回值是int类型的。

##### 2、常量指针和指针常量

- 指针常量是一个指针，读成常量的指针，指向一个只读变量，也就是后面所指明的int const 和 const int，都是一个常量，可以写作int const *p或const int *p。

- 常量指针是一个不能给改变指向的指针。指针是个常量，必须初始化，一旦初始化完成，它的值（也就是存放在指针中的地址）就不能在改变了，即不能中途改变指向，如int *const p。

##### 3、野指针

 		都是是指向无效内存区域(这里的无效指的是"不安全不可控")的指针，访问行为将会导致未定义行为。

###### 1）野指针的概念

- 野指针指向一个已删除的对象或不可用的地址的指针。
- 指针变量中的值是非法的内存地址，进而形成野指针。
- 野指针不是NULL指针，是指向不可用内存地址的指针。

###### 2）出现原因：

- 指针定义时未被初始化；程序未对指针进行初始化，会随机指向一个区域，除了static修饰的指针；
- 指针被释放时没有置空；指针指向的内存空间在free()和delete()释放后，没有进行置空操作的话，就会称为一个野指针；
- 指针操作超越变量作用域；不要返回指向栈内存的指针或者引用，栈内存在函数结束的时候就会自动被释放；

###### 3）解决或避免：

​		delete后置为NULL，新建指针时判断是否为NULL，不是则释放并置为NULL，尽量不使用超出作用范围的指针

###### 4）野指针：delete 指针后为什么需要置为NULL?

​		首先delete指针只是编译器释放该指针所指向的内存空间（该空间可以给其他变量使用），而不会删除这个指针本身。这可能会导致后续申请指针时，系统新建的指针指向的地址可能会跟delete掉的指针相同，此时如果修改delete掉的指针的内容就会导致对新建的指针内容的修改。

​		所以为了防止这种情况的发生，需要delete掉后立即置为NULL（避免变成野指针），同时在新建指针的时候需要判断新建的指针是否为NULL，为NULL才是申请成功。

​		对null的delete可以无数次，因为delete会直接跳过NULL

​		原文链接：https://blog.csdn.net/weixin_42067304/article/details/108451031

##### 4、悬空指针

###### 1）悬空指针概念

​		悬空指针，指针最初指向的内存已经被释放了的一种指针。

```c++
int main(void) { 
 int * p = nullptr;
 int* p2 = new int;
 
 p = p2;
 delete p2; 
}
```

​		此时 p和p2就是悬空指针，指向的内存已经被释放。继续使用这两个指针，行为不可预料。需要设置为p=p2=nullptr。此时再使用，编译器会直接保错。c++引入了智能指针，C++智能指针的本质就是避免悬空指针的产生。

###### 2）产生原因及解决办法：

​		指针free或delete之后没有及时置空 => 释放操作后立即置空。

##### 5、指针加减需要注意什么？

​		指针加减本质是对其所指地址的移动，移动的步长跟指针的类型是有关系的，因此在涉及到指针加减运算需要十分小心，加多或者减多都会导致指针指向一块未知的内存地址，如果再进行操作就会很危险。遇到指针的计算，**需要明确的是指针每移动一位，它实际跨越的内存间隔是指针类型的长度，建议都转成10进制计算，计算结果除以类型长度取得结果**。



#### 1.2、指针和引用

##### 1、在传递函数参数时，什么时候使用指针，什么时候使用引用？

**==总结==**

- 需要返回函数内局部变量的内存的时候用指针。使用指针传参需要开辟内存，用完要记得释放指针，不然会内存泄漏。而返回局部变量的引用是没有意义的。
- 对栈空间大小比较敏感（比如递归）的时候使用引用。使用引用传递不需要创建临时变量，开销要更小。
- 类对象作为参数传递的时候使用引用，这是C++类对象传递的标准方式。

###### 1）使用引用参数的主要原因有两个：

- 程序员能修改调用函数中的数据对象

- 通过传递引用而不是整个数据–对象，可以提高程序的运行速度

###### 2）一般的原则：

- 对于使用引用的值而不做修改的函数：

- 如果数据对象很小，如内置数据类型或者小型结构，则按照值传递；

- 如果数据对象是数组，则使用指针（唯一的选择），并且指针声明为指向const的指针；

- 如果数据对象是较大的结构，则使用const指针或者引用，已提高程序的效率。这样可以节省结构所需的时间和空间；
- 如果数据对象是类对象，则使用const引用（传递类对象参数的标准方式是按照引用传递）；

###### 3）对于修改函数中数据的函数：

- 如果数据是内置数据类型，则使用指针
- 如果数据对象是数组，则只能使用指针
- 如果数据对象是结构，则使用引用或者指针
- 如果数据是类对象，则使用引用



##### 2、值传递、指针传递、引用传递去区别和效率？

- 值传递：有一个形参向函数所属的栈拷贝数据的过程，如果值传递的对象是类对象 或是大的结构体对象，将耗费一定的时间和空间。（传值）
- 指针传递：同样有一个形参向函数所属的栈拷贝数据的过程，但拷贝的数据是一个固定为4字节的地址。（传值，传递的是地址值）
- 引用传递：同样有上述的数据拷贝过程，但其是针对地址的，相当于为该数据所在的地址起了一个别名。（传地址）
- 效率上讲，指针传递和引用传递比值传递效率高。一般主张使用引用传递，代码逻辑上更加紧凑、清晰。

##### 3、C++中的指针参数传递和引用参数传递有什么区别？（底层）

- **指针**参数传递本质上是**值传递**，它所传递的是一个**地址值**。

​		值传递过程中，被调函数的形式参数作为被调函数的**局部**变量处理，会在栈中开辟内存空间以存放由主调函数传递进来的实参值，从而形成了实参的一个副本（替身）。

​		**值传递的特点是，被调函数对形式参数的任何操作都是作为局部变量进行的，不会影响主调函数的实参变量的值**（形参指针变了，实参指针不会变）。

- **引用**参数传递过程中，被调函数的形式参数也作为局部变量在栈中开辟了内存空间，但是这时存放的是由主调函数放进来的实参变量的地址。

​		被调函数对形参（本体）的任何操作都被处理成间接寻址，即通过栈中存放的地址访问主调函数中的实参变量（根据别名找到主调函数中的本体）。

​		因此，被调函数对形参的任何操作都会**影响**主调函数中的**实参**变量。

- 引用传递和指针传递是不同的，虽然他们都是在被调函数栈空间上的一个局部变量，但是任何对于引用参数的处理都会通过一个间接寻址的方式操作到主调函数中的相关变量。

​		而对于指针传递的参数，如果改变被调函数中的指针地址，它将应用不到主调函数的相关变量。如果想通过指针参数传递来改变主调函数中的相关变量（地址），那就得使用指向指针的指针或者指针引用。

- 从编译的角度来讲，程序在编译时分别将指针和引用添加到符号表上，符号表中记录的是变量名及变量所对应地址。

​		指针变量在符号表上对应的地址值为指针变量的地址值，而引用在符号表上对应的地址值为引用对象的地址值（与实参名字不同，地址相同）。

​		符号表生成之后就不会再改，因此指针可以改变其指向的对象（指针变量中的值可以改），而引用对象则不能修改。

##### 4、继承机制中对象之间如何转换？指针和引用之间如何转换？

###### 1）向上类型转换

​		将派生类指针或引用转换为基类的指针或引用被称为向上类型转换，向上类型转换会自动进行，而且向上类型转换是安全的。

###### 2）向下类型转换

​		将基类指针或引用转换为派生类指针或引用被称为向下类型转换，向下类型转换不会自动进行，因为一个基类对应几个派生类，所以向下类型转换时不知道对应哪个派生类，所以在向下类型转换时必须加动态类型识别技术。RTTI技术，用dynamic_cast进行向下类型转换。

##### 5、将引用作为函数参数有哪些好处？

- 传递引用给函数与传递指针的效果是一样的。这时，被调函数的形参就成为原来主调函数中的实参变量或对象的一个别名来使用，所以在被调函数中对形参变量的操作就是对其相应的目标对象（在主调函数中）的操作。

- 使用引用传递函数的参数，在内存中并没有产生实参的副本，它是直接对实参操作；而使用一般变量传递函数的参数，当发生函数调用时，需要给形参分配存储单元，形参变量是实参变量的副本；如果传递的是对象，还将调用拷贝构造函数。因此，当参数传递的数据较大时，用引用比用一般变量传递参数的效率和所占空间都好。

- 使用指针作为函数的参数虽然也能达到与使用引用的效果，但是，在被调函数中同样要给形参分配存储单元，且需要重复使用"*指针变量名"的形式进行运算，这很容易产生错误且程序的阅读性较差；另一方面，在主调函数的调用点处，必须用变量的地址作为实参。而引用更容易使用，更清晰。



#### 1.3、指针和引用的区别

- 指针是一个变量，存储的是一个地址，引用跟原来的变量实质上是同一个东西，是原变量的别名

- 指针可以有多级，引用只有一级

- 指针可以为空，引用不能为NULL且在定义时必须初始化

- 指针在初始化后可以改变指向，而引用在初始化之后不可再改变

- sizeof指针得到的是本指针的大小，sizeof引用得到的是引用所指向变量的大小

- 当把指针作为参数进行传递时，也是将实参的一个拷贝传递给形参，两者指向的地址相同，但不是同一个变量，在函数中改变这个变量的指向不影响实参，而引用却可以。

- 引用本质是一个指针，同样会占4字节内存；指针是具体变量，需要占用存储空间（具体情况还要具体分析）。

- 引用在声明时必须初始化为另一变量，一旦出现必须为typename refname &varname形式；指针声明和定义可以分开，可以先只声明指针变量而不初始化，等用到时再指向具体变量。

- 引用一旦初始化之后就不可以再改变（变量可以被引用为多次，但引用只能作为一个变量引用）；指针变量可以重新指向别的变量。

- 不存在指向空值的引用，必须有具体实体；但是存在指向空值的指针。



#### 1.4、结构对齐

##### 1、字节对齐概念

​     计算机系统对基本数据类型合法地址做出的限制，要求某种类型对象的地址必须是某个值（通常是2、4或8）的倍数。对齐跟数据在内存中的位置有关。

- 分配内存的顺序是按照声明的顺序。
- 每个变量相对于起始位置的偏移量必须是该变量类型大小的整数倍，不是整数倍空出内存，直到偏移量是整数倍为止。
-  最后整个结构体的大小必须是里面变量类型最大值的整数倍。

##### 2、字节对齐单位决定因素：

（以上三者取最小的一个）

- WIN、VS、qt默认8字节对齐；LINUX 32位默认4字节对齐，64位默认8字节对齐；
- 结构体最大成员变量；
- 预编译指令#pragma pack(n)   n只能填1、2、4、8、16；

##### 3、为什么要字节对齐

​      需要字节对齐的原因在于CPU访问数据的效率问题。例，一个整型变量的地址不是自然对齐，如0x00000002，CPU访问这个整型数据需要访问两次内存，第一次取从0x00000002-0x00000003的一个short，第二次取从0x00000004-0x00000005的一个short然后组合得到所要的数据。要是变量在自然对齐位置上，则只需要一次就可以取出数据。

​      对于32位机来说，4字节能够提高CPU访问速度，但是在32位中使用1字节或两字节对齐，会降低访问速度，所以字节对齐需要考虑处理器类型。在VC中默认是4字节对齐的，GCC也是默认4字节对齐，所以需要综合考虑处理器类型和编译器类型。

​     在设计不同CPU通信的协议时，或者编写硬件驱动程序时寄存器的结构，都需要字节对齐，因为不同编译器生成的代码不一样，所以本身就自然对齐的也要使其对齐。

##### 4、如何处理字节对齐

​		编译器按照的字节对齐原则：

- 数据类型自身的字节对齐值：指定平台上基本类型的长度。char自身对齐值为1，short为2，int\float\double为4；
- 结构体或类的自身对齐值：成员中自身对齐值最大的那个值；
- 指定对齐值：#pragma pack(value)时的指定对齐值value，#pragma pack ()取消自定义字节对齐方式；
- 数据成员、结构体和类的有效对齐值：自身对齐值和指定对齐值中取小的那个值；
- 标准的数据类型，地址只要是长度的整数倍就行了。对于非标准的数据类型，**数组：**按照基本数据类型对齐，第一个对齐了后面自然对齐；==联合：==按其包含的长度最大的数据类型对齐；**结构体：**结构体中每个数据类型都要对齐。

​      数据类型为结构体时 ，编译器可能会在结构体字段的分配中插入间隙，以保证结构体中每个元素都满足它的对齐要求。第一个数据变量的起始地址就是数据结构的起始地址。结构体的成员变量要对齐，结构体本身也要对齐（就是说结构体总长度需要是结构体有效对齐值的整数倍），因此，有时需要在结构末尾填充空间，来满足结构体的自身对齐。

##### 5、字节对齐的结构体举例

```C++
struct test01
{
    char a;    //1字节
    short b;   //2字节
    int c;     //4字节
    long d;    //4字节
};

struct test02
{
    char a;    //1字节
    int c;     //4字节
    long d;    //4字节
    short b;   //2字节
};
    test01 t1 = { 0 };
    cout << sizeof(t1) << endl; //12字节  因为char和short之间要自动补齐1字节
    test02 t2 = { 0 };
    cout << sizeof(t2) << endl; //16字节  因为char自动补齐3字节，short自动补齐2字节

struct test
{
    int c;     //4字节
    long d;    //4字节
    char a;    //1字节
};  //char自动补齐3字节，总共是12字节

#pragma pack(2)
struct test02
{
    int a;    //4字节
    long c;     //4字节
    char b;   //1字节
};
#pragma pack()  //按两字节对齐，就是10字节
```

​		所以适当地编排结构体成员地顺序，可以在保存相同信息地情况下尽可能节约空间。



#### 1.5、大小端

##### 1、大小端存储概念

- 大端存储：字数据的高字节存储在低地址中

- 小端存储：字数据的低字节存储在低地址中

在Socket编程中，往往需要将操作系统所用的小端存储的IP地址转换为大端存储，这样才能进行网络传输。

<img src="总结面试题.assets/image-20210908213455812.png" alt="image-20210908213455812" style="zoom:80%;" />

##### 2、如何判断大小端

###### 1）强制转换

```c++
int main()
{
    int a = 0x1234;
    char c = (char)(a);//由于int和char的长度不同，借助int型转换成char型，只会留下低地址的部分
    if(c == 0x12) 
        cout << "big endian" << endl;
    else if(c == 0x34) 
        cout << "little endian" << endl;
}
```

###### 2）union

```c++
//union联合体的重叠式存储，endian联合体占用内存的空间为每个成员字节长度的最大值
union endian
{
    int a;
    char ch;
};
int main(){
    endian value;
    value.a = 0x1234;//a和ch共用4字节内存空间
    if(value.ch == 0x12)
        cout << "big endian" << endl;
    else if(value.ch == 0x34)
        cout << "little endian" << endl;
}
```



#### 1.6、组合和继承

##### 1、组合

​		组合也就是设计类的时候把要组合的类的对象加入到该类中作为自己的成员变量。

###### 1）组合的优点：

- 当前对象只能通过所包含的那个对象去调用其方法，所以所包含的对象的内部细节对当前对象时不可见的。

- 当前对象与包含的对象是一个低耦合关系，如果修改包含对象的类中代码不需要修改当前对象类的代码。

- 当前对象可以在运行时动态的绑定所包含的对象。可以通过set方法给所包含对象赋值。

###### 2）组合的缺点：

- 容易产生过多的对象。
- 为了能组合多个对象，必须仔细对接口进行定义

##### 2、继承

​		继承是Is a 的关系，比如说Student继承Person,则说明Student is a Person。继承的优点是子类可以重写父类的方法来方便地实现对父类的扩展。

###### 1）继承的缺点

- 父类的内部细节对子类是可见的。
- 子类从父类继承的方法在编译时就确定下来了，所以无法在运行期间改变从父类继承的方法的行为。
- 如果对父类的方法做了修改的话（比如增加了一个参数），则子类的方法必须做出相应的修改。所以说子类与父类是一种高耦合，违背了面向对象思想。



#### 1.7、实参和形参的区别

- 形参变量只有在被调用时才分配内存单元，在调用结束时， 即刻释放所分配的内存单元。因此，形参只有在函数内部有效。 函数调用结束返回主调函数后则不能再使用该形参变量。
- 实参可以是常量、变量、表达式、函数等， 无论实参是何种类型的量，在进行函数调用时，它们都必须具有确定的值， 以便把这些值传送给形参。 因此应预先用赋值，输入等办法使实参获得确定值，会产生一个临时变量。
- 实参和形参在数量上，类型上，顺序上应严格一致， 否则会发生“类型不匹配”的错误。
- 函数调用中发生的数据传送是单向的。 即只能把实参的值传送给形参，而不能把形参的值反向地传送给实参。 因此在函数调用过程中，形参的值发生改变，而实参中的值不会变化。
- 当形参和实参不是指针类型时，在该函数运行时，形参和实参是不同的变量，他们在内存中位于不同的位置，形参将实参的内容复制一份，在该函数运行结束的时候形参被释放，而实参内容不会改变。

#### 1.8、声明和定义的区别

##### 1、如果是指变量的声明和定义

​		从编译原理上来说，声明是仅仅告诉编译器，有个某类型的变量会被使用，但是编译器并不会为它分配任何内存。而定义就是分配了内存。

##### 2、如果是指函数的声明和定义

​		声明：一般在头文件里，对编译器说：这里我有一个函数叫function() 让编译器知道这个函数的存在。

​		定义：一般在源文件里，具体就是函数的实现过程 写明函数体。

#### 1.9、ifdef 和 endif 代表什么？

1、 一般情况下，源程序中所有的行都参加编译。但是有时希望对其中一部分内容只在满足一定条件才进行编译，也就是对一部分内容指定编译的条件，这就是“条件编译”。有时，希望当满足某条件时对一组语句进行编译，而当条件不满足时则编译另一组语句。

2、条件编译命令最常见的形式为：

```c++
\#ifdef
    //程序段1
\#else
    //程序段2
\endif
```

​		它的作用是：当标识符已经被定义过(一般是用#define命令定义)，则对程序段1进行编译，否则编译程序段2。

3、 在一个大的软件工程里面，可能会有多个文件同时包含一个头文件，当这些文件编译链接成一个可执行文件上时，就会出现大量“重定义”错误。在头文件中使用#define、#ifndef、#ifdef、#endif能**避免头文件重定义**。

#### 1.10、C和C++类型安全

##### 1、C和C++的区别

- C++中new和delete是对内存分配的运算符，取代了C中的malloc和free。
- 标准C++中的字符串类取代了标准C函数库头文件中的字符数组处理函数（C中没有字符串类型）。
- C++中用来做控制态输入输出的iostream类库替代了标准C中的stdio函数库。
- C++中的try/catch/throw异常处理机制取代了标准C中的setjmp()和longjmp()函数。
- 在C++中，允许有相同的函数名，不过它们的参数类型不能完全相同，这样这些函数就可以相互区别开来。而这在C语言中是不允许的。也就是C++可以重载，C语言不允许。
- C++语言中，允许变量定义语句在程序中的任何地方，只要在是使用它之前就可以；而C语言中，必须要在函数开头部分。而且C++允许重复定义变量，C语言也是做不到这一点的
- 在C++中，除了值和指针之外，新增了引用。引用型变量是其他变量的一个别名，我们可以认为他们只是名字不相同，其他都是相同的。
- C++相对与C增加了一些关键字，如：bool、using、dynamic_cast、namespace等等

##### 2、什么是类型安全？

​		类型安全很大程度上可以等价于内存安全，类型安全的代码不会试图访问自己没被授权的内存区域。“类型安全”常被用来形容编程语言，其根据在于该门编程语言是否提供保障类型安全的机制；有的时候也用“类型安全”形容某个程序，判别的标准在于该程序是否隐含类型错误。类型安全的编程语言与类型安全的程序之间，没有必然联系。好的程序员可以使用类型不那么安全的语言写出类型相当安全的程序，相反的，差一点儿的程序员可能使用类型相当安全的语言写出类型不太安全的程序。绝对类型安全的编程语言暂时还没有。

##### 3、C的类型安全

​		C只在局部上下文中表现出类型安全，比如试图从一种结构体的指针转换成另一种结构体的指针时，编译器将会报告错误，除非使用显式类型转换。然而，C中相当多的操作是不安全的。

###### 1）printf格式输出

###### 2）malloc的返回值

​		malloc是C中进行内存分配的函数，它的返回类型是void*即空类型指针，常常有这样的用法：

```c++
char* pStr=(char*)malloc(100*sizeof(char)) //语句1
int* pInt=(int*)malloc(100*sizeof(char))   //语句2
```

​		这里明显做了显式的类型转换。类型匹配尚且没有问题，但是一旦出现**语句2**就很可能带来一些问题，而这样的转换C并不会提示错误。

##### 4、C++的类型安全

​		如果C++使用得当，它将远比C更有类型安全性。相比于C语言，C++提供了一些新的机制保障类型安全：

- 操作符new返回的指针类型严格与对象匹配，而不是void；
- C中很多以void为参数的函数可以改写为C++模板函数，而模板是支持类型检查的；
- 引入const关键字代替#define constants，它是有类型、有作用域的，而#define constants只是简单的文本替换；
- 一些#define宏可被改写为inline函数，结合函数的重载，可在类型安全的前提下支持多种类型，当然改写为模板也能保证类型安全；
- C++提供了**dynamic_cast**关键字，使得转换过程更加安全，因为dynamic_cast比static_cast涉及更多具体的类型检查。



#### 1.11、回调函数

- 当发生某种事件时，系统或其他函数将会自动调用你定义的一段函数；
-  回调函数就相当于一个中断处理函数，由系统在符合你设定的条件时自动调用。为此，你需要做三件事：1，声明；2，定义；3，设置触发条件，就是在你的函数中把你的回调函数名称转化为地址作为一个参数，以便于系统调用；
- 回调函数就是一个通过函数指针调用的函数。如果你把函数的指针（地址）作为参数传递给另一个函数，当这个指针被用为调用它所指向的函数时，我们就说这是回调函数；
- 因为可以把调用者与被调用者分开。调用者不关心谁是被调用者，所有它需知道的，只是存在一个具有某种特定原型、某些限制条件（如返回值为int）的被调用函数。

#### 1.12、拷贝初始化和直接初始化

- 当用于类类型对象时，初始化的拷贝形式和直接形式有所不同：直接初始化直接调用与实参匹配的构造函数，拷贝初始化总是调用拷贝构造函数。拷贝初始化首先使用指定构造函数创建一个临时对象，然后用拷贝构造函数将那个临时对象拷贝到正在创建的对象。
- **为了提高效率，允许编译器跳过创建临时对象这一步，**直接调用构造函数构造要创建的对象，这样就完全等价于**直接初始化了**（语句1和语句3等价），但是需要辨别两种情况。
  - 当拷贝构造函数为private时：语句3和语句4在编译时会报错
  - 使用explicit修饰构造函数时：如果构造函数存在隐式转换，编译时会报错

#### 1.13、深拷贝和浅拷贝

##### 1、深拷贝

​		深拷贝不仅拷贝值，还开辟出一块新的空间用来存放新的值，即使原先的对象被析构掉，释放内存了也不会影响到深拷贝得到的值。在自己实现拷贝赋值的时候，如果有指针变量的话是需要自己实现深拷贝的。

##### 2、浅拷贝

​		浅拷贝只是拷贝一个指针，并没有新开辟一个地址，拷贝的指针和原来的指针指向同一块地址，如果原来的指针所指向的资源释放了，那么再释放浅拷贝的指针的资源就会出现错误。	

​		浅拷贝在对象的拷贝创建时存在风险，即被拷贝的对象析构释放资源之后，拷贝对象析构时会再次释放一个已经释放的资源，深拷贝的结果是两个对象之间没有任何关系，各自成员地址不同。

​		**浅拷贝带来问题的本质在于析构函数释放多次堆内存，使用std::shared_ptr，可以完美解决这个问题！！**

#### 1.14、public、private、protected

​		public的变量和函数在类的内部外部都可以访问；protected的变量和函数只能在类的内部和其派生类中访问；private修饰的元素只能在类内访问。

##### 1、访问权限

​		派生类可以继承基类中除了构造/析构、赋值运算符重载函数之外的成员，但是这些成员的访问属性在派生过程中也是可以调整的，三种派生方式的访问权限如下表所示：注意外部访问并不是真正的外部访问，而是在通过派生类的对象对基类成员的访问。

| 基类成员 | public  | private | protected | public    | private | protected | public | private | protected |
| -------- | ------- | ------- | --------- | --------- | ------- | --------- | ------ | ------- | --------- |
| 派生方式 |         |         | private   |           |         | protected |        |         | public    |
| 派生类中 | private | 不可见  | private   | protected | 不可见  | protected | public | 不可见  | protected |
| 外部     | 不可见  | 不可见  | 不可见    | 不可见    | 不可见  | 不可见    | 可见   | 不可见  | 不可见    |

派生类对基类成员的访问形象有如下两种：

- 内部访问：由派生类中新增的成员函数对从基类继承来的成员的访问
- **外部访问**：在派生类外部，通过派生类的对象对从基类继承来的成员的访问

###### 访问权限总结：

- public:用该关键字修饰的成员表示公有成员，该成员不仅可以在类内可以被 访问，在类外也是可以被访问的，是类对外提供的可访问接口；
- private:用该关键字修饰的成员表示私有成员，该成员仅在类内可以被访问，在类体外是隐藏状态；
- protected:用该关键字修饰的成员表示保护成员，保护成员在类体外同样是隐藏状态，但是对于该类的派生类来说，相当于公有成员，在派生类中可以被访问。

##### 2、继承权限

###### 1）public继承

​		公有继承的特点是基类的公有成员和保护成员作为派生类的成员时，都保持原有的状态，而基类的私有成员任然是私有的，不能被这个派生类的子类所访问。

###### 2）private继承

​		私有继承的特点是基类的所有公有成员和保护成员都成为派生类的私有成员，并不被它的派生类的子类所访问，基类的成员只能由自己派生类访问，无法再往下继承，访问规则如下表：

| 基类成员 | public成员 | private成员 | protected成员 |
| -------- | ---------- | ----------- | :------------ |
| 内部访问 | 可访问     | 不可访问    | 可访问        |
| 外部访问 | 不可访问   | 不可访问    | 不可访问      |

###### 3）protected继承

​		保护继承的特点是基类的所有公有成员和保护成员都成为派生类的保护成员，并且只能被它的派生类成员函数或友元函数访问，基类的私有成员仍然是私有的，访问规则如下表：

| 基类成员 | public成员 | private成员 | protected成员 |
| -------- | ---------- | ----------- | :------------ |
| 内部访问 | 可访问     | 不可访问    | 可访问        |
| 外部访问 | 不可访问   | 不可访问    | 不可访问      |

###### 4）继承权限总结

- 若继承方式是public，基类成员在派生类中的访问权限保持不变，也就是说，基类中的成员访问权限，在派生类中仍然保持原来的访问权限；
- 若继承方式是private，基类所有成员在派生类中的访问权限都会变为私有(private)权限；
- 若继承方式是protected，基类的共有成员和保护成员在派生类中的访问权限都会变为保护(protected)权限，私有成员在派生类中的访问权限仍然是私有(private)权限。



#### 1.15、异常处理

##### 1、常见的异常

- 数组下标越界
- 除法计算时除数为0
- 动态分配的内存空间不足
- ...

##### 2、try、 throw、 catch关键字

​		程序的执行流程是先执行try包裹的语句块，如果执行过程中没有异常发生，则不会进入任何catch包裹的语句块，如果发生异常，则使用throw进行异常抛出，再由catch进行捕获，throw可以抛出各种数据类型的信息，代码中使用的是数字，也可以自定义异常class。**catch根据throw抛出的数据类型进行精确捕获（不会出现类型转换），如果匹配不到就直接报错，可以使用catch(...)的方式捕获任何异常（不推荐）**。当然，如果catch了异常，当前函数如果不进行处理，或者已经处理了想通知上一层的调用者，可以在catch里面再throw异常。

##### 3、函数的异常声明列表

​		有时候，程序员在定义函数的时候知道函数可能发生的异常，可以在函数声明和定义时，指出所能抛出异常的列表，写法如下：

```c++
int fun() throw(int,double,A,B,C){...};
```

​		这种写法表名函数可能会抛出int,double型或者A、B、C三种类型的异常，如果throw中为空，表明不会抛出任何异常，如果没有throw则可能抛出任何异常。

##### 4、exception

<img src="总结面试题.assets/Image-16316123721891.png" alt="Image" style="zoom:67%;" /><img src="总结面试题.assets/Image-16316123783862.png" alt="Image" style="zoom:67%;" />

- bad_typeid：使用typeid运算符，如果其操作数是一个多态类的指针，而该指针的值为 NULL，则会拋出此异常；

- bad_cast：在用 dynamic_cast 进行从多态基类对象（或引用）到派生类的引用的强制类型转换时，如果转换是不安全的，则会拋出此异常
- bad_alloc：在用 new 运算符进行动态内存分配时，如果没有足够的内存，则会引发此异常
- out_of_range：用 vector 或 string的at 成员函数根据下标访问元素时，如果下标越界，则会拋出此异常

#### 1.16、coredump错误

​		**coredump是程序由于异常或者bug在运行时异常退出或者终止**，在一定的条件下生成的一个叫做core的文件，这个core文件会记录程序在运行时的内存，寄存器状态，内存指针和函数堆栈信息等等。对这个文件进行分析可以定位到程序异常的时候对应的堆栈调用信息。

#### 1.17、怎么快速定位错误位置？

- 如果是简单的错误，可以直接双击错误列表里的错误项或者生成输出的错误信息中带行号的地方就可以让编辑窗口定位到错误的位置上。
- 对于复杂的模板错误，最好使用生成输出窗口。多数情况下出发错误的位置是最靠后的引用位置。如果这样确定不了错误，就需要先把自己写的代码里的引用位置找出来，然后逐个分析了。

#### 1.18、四种强制转换

##### 1、reinterpret_cast

```c++
reinterpret_cast<type-id> (expression)
```

​		type-id 必须是一个指针、引用、算术类型、函数指针或者成员指针。它可以用于类型之间进行强制转换。

##### 2、const_cast

```c++
const_cast<type_id> (expression)
```

​	该运算符用来修改类型的const或volatile属性。除了const 或volatile修饰之外， type_id和expression的类型是一样的。用法如下：

- 常量指针被转化成非常量的指针，并且仍然指向原来的对象
- 常量引用被转换成非常量的引用，并且仍然指向原来的对象
- const_cast一般用于修改底指针。如const char *p形式

##### 3、static_cast

```c++
static_cast < type-id > (expression)
```

​	该运算符把expression转换为type-id类型，但没有运行时类型检查来保证转换的安全性。它主要有如下几种用法：

- 用于类层次结构中基类（父类）和派生类（子类）之间指针或引用引用的转换

  - 进行上行转换（把派生类的指针或引用转换成基类表示）是安全的
  - 进行下行转换（把基类指针或引用转换成派生类表示）时，由于没有动态类型检查，所以是不安全的

- 用于基本数据类型之间的转换，如把int转换成char，把int转换成enum。这种转换的安全性也要开发人员来保证。

- 把空指针转换成目标类型的空指针

- 把任何类型的表达式转换成void类型

  **注意：static_cast不能转换掉expression的const、volatile、或者__unaligned属性。**

##### 4、dynamic_cast

​		有类型检查，基类向派生类转换比较安全，但是派生类向基类转换则不太安全

```c++
dynamic_cast (expression)
```

​		该运算符把expression转换成type-id类型的对象。type-id 必须是类的指针、类的引用或者void*

- 如果 type-id 是类指针类型，那么expression也必须是一个指针，如果 type-id 是一个引用，那么expression 也必须是一个引用
- dynamic_cast运算符可以在执行期决定真正的类型，也就是说expression必须是多态类型。如果下行转换是安全的（也就说，如果基类指针或者引用确实指向一个派生类对象）这个运算符会传回适当转型过的指针。如果 如果下行转换不安全，这个运算符会传回空指针（也就是说，基类指针或者引用没有指向一个派生类对象）
- dynamic_cast主要用于类层次间的上行转换和下行转换，还可以用于类之间的交叉转换
  - 在类层次间进行上行转换时，dynamic_cast和static_cast的效果是一样的
  - 在进行下行转换时，dynamic_cast具有类型检查的功能，比static_cast更安全

​		**在进行下行转换时，dynamic_cast安全的，如果下行转换不安全的话其会返回空指针，这样在进行操作的时候可以预先判断。而使用static_cast下行转换存在不安全的情况也可以转换成功，但是直接使用转换后的对象进行操作容易造成错误。**



#### 1.19、程序的运行过程

![image-20210914214743482](总结面试题.assets/image-20210914214743482.png)

##### 1、预编译

​		主要处理源代码文件中的以“#”开头的预编译指令。处理规则见下：

- 删除所有的#define，展开所有的宏定义。
- 处理所有的条件预编译指令，如“#if”、“#endif”、“#ifdef”、“#elif”和“#else”。
- 处理“#include”预编译指令，将文件内容替换到它的位置，这个过程是递归进行的，文件中包含其他文件。
- 删除所有的注释，“//”和“/**/”。
- 保留所有的#pragma 编译器指令，编译器需要用到他们，如：#pragma once 是为了防止有文件被重复引用。
- 添加行号和文件标识，便于编译时编译器产生调试用的行号信息，和编译时产生编译错误或警告是能够显示行号。

##### 2、编译

​		把预编译之后生成的xxx.i或xxx.ii文件，进行一系列词法分析、语法分析、语义分析及优化后，生成相应的汇编代码文件。

- 词法分析：利用类似于“有限状态机”的算法，将源代码程序输入到扫描机中，将其中的字符序列分割成一系列的记号。
- 语法分析：语法分析器对由扫描器产生的记号，进行语法分析，产生语法树。由语法分析器输出的语法树是一种以表达式为节点的树。
- 语义分析：语法分析器只是完成了对表达式语法层面的分析，语义分析器则对表达式是否有意义进行判断，其分析的语义是静态语义——在编译期能分期的语义，相对应的动态语义是在运行期才能确定的语义。
- 优化：源代码级别的一个优化过程。
- 目标代码生成：由代码生成器将中间代码转换成目标机器代码，生成一系列的代码序列——汇编语言表示。
- 目标代码优化：目标代码优化器对上述的目标机器代码进行优化：寻找合适的寻址方式、使用位移来替代乘法运算、删除多余的指令等。

##### 3、汇编

​		将汇编代码转变成机器可以执行的指令(机器码文件)。 汇编器的汇编过程相对于编译器来说更简单，没有复杂的语法，也没有语义，更不需要做指令优化，只是根据汇编指令和机器指令的对照表一一翻译过来，汇编过程有汇编器as完成。经汇编之后，产生目标文件(与可执行文件格式几乎一样)xxx.o(Windows下)、xxx.obj(Linux下)。 

##### 4、链接

​		将不同的源文件产生的目标文件进行链接，从而形成一个可以执行的程序。链接分为静态链接和动态链接：

###### 1）静态链接

​		函数和数据被编译进一个二进制文件。在使用静态库的情况下，在编译链接可执行文件时，链接器从库中复制这些函数和数据并把它们和应用程序的其它模块组合起来创建最终的可执行文件。

- **空间浪费**：因为每个可执行程序中对所有需要的目标文件都要有一份副本，所以如果多个程序对同一个目标文件都有依赖，会出现同一个目标文件都在内存存在多个副本；

- **更新困难**：每当库函数的代码修改了，这个时候就需要重新进行编译链接形成可执行程序。
- **运行速度快**：但是静态链接的优点就是，在可执行程序中已经具备了所有执行程序所需要的任何东西，在执行的时候运行速度快。

###### 2）动态链接

​		动态链接的基本思想是把程序按照模块拆分成各个相对独立部分，在程序运行时才将它们链接在一起形成一个完整的程序，而不是像静态链接一样把所有程序模块都链接成一个单独的可执行文件。

- **共享库**：就是即使需要每个程序都依赖同一个库，但是该库不会像静态链接那样在内存中存在多分，副本，而是这多个程序在执行时共享同一份副本；
- **更新方便**：更新时只需要替换原来的目标文件，而无需将所有的程序再重新链接一遍。当程序下一次运行时，新版本的目标文件会被自动加载到内存并且链接起来，程序就完成了升级的目标。
- **性能损耗**：因为把链接推迟到了程序运行时，所以每次执行程序都需要进行链接，所以性能会有一定损失。

#### 1.20、动态编译和静态编译

##### 1、静态编译

​		编译器在编译可执行文件时，把需要用到的对应动态链接库中的部分提取出来，连接到可执行文件中去，使可执行文件在运行时不需要依赖于动态链接库；

##### 2、动态编译

​		动态编译的可执行文件需要附带一个动态链接库，在执行时，需要调用其对应动态链接库的命令。

###### 1）优点：

- 缩小了执行文件本身的体积
- 加快了编译速度，节省了系统资源

###### 2）缺点：

- 缺点是哪怕是很简单的程序，只用到了链接库的一两条命令，也需要附带一个相对庞大的链接库；
- 二是如果其他计算机上没有安装对应的运行库，则用动态编译的可执行文件就不能运行。



#### 1.21、友元

##### 1、为什么友元函数必须声明在类内部？

​		因为编译器必须能够读取这个结构的声明以理解这个数据类型的大、行为等方面的所有规则。有一条规则在任何关系中都很重要，那就是谁可以访问我的私有部分。

##### 2、友元函数和友元类

​		友元提供了不同类的成员函数之间、类的成员函数和一般函数之间进行数据共享的机制。通过友元，一个不同函数或者另一个类中的成员函数可以访问类中的私有成员和保护成员。友元的正确使用能提高程序的运行效率，但同时也破坏了类的封装性和数据的隐藏性，导致程序可维护性变差。

###### 1）友元函数

​		友元函数是定义在**类外**的普通函数，不属于任何类，可以访问其他类的**私有成员**。但是需要在类的定义中声明所有可以访问它的友元函数。一个函数可以是多个类的友元函数，但是每个类中都要声明这个函数。

###### 2）友元类

​		友元类的所有成员函数都是另一个类的友元函数，都可以访问另一个类中的隐藏信息（包括私有成员和保护成员）。 但是另一个类里面也要相应的进行声明。

**使用友元类时注意：**

- 友元关系不能被继承。
- 友元关系是单向的，不具有交换性。若类B是类A的友元，类A不一定是类B的友元，要看在类中是否有相应的声明。
- 友元关系不具有传递性。若类B是类A的友元，类C是B的友元，类C不一定是类A的友元，同样要看类中是否有相应的申明。

#### 1.22、类占内存的大小

​		 一般类所占的内存大小是非静态数据成员（在全局区）的总和大小 。

##### 1、空类

 		空类的大小讲道理应该是0，但实际上是1。就是涉及到一个实例化的问题，空类同样可以被实例化，每个实例在内存中都有一个独一无二的地址，所以编译器往往会给一个空类隐含的加一个字节，这样空类在实例化后在内存中就得到了一个独一无二的地址，所以空类所占内存大小为1。

##### 2、virtual

​		动态多态，会有个虚函数指针，就是指针的大小（64位指针所占内存是8字节）。



### 2、C++内存管理

#### 2.1、内存分区

<img src="总结面试题.assets/Image-16309179999242.png" alt="Image" style="zoom:80%;" />

​		原文链接：[C/C++内存管理详解 | ShinChan's Blog (chenqx.github.io)](https://chenqx.github.io/2014/09/25/Cpp-Memory-Management/)

​	**栈**：在执行函数时，函数内局部变量的存储单元都可以在栈上创建，函数执行结束时这些存储单元自动被释放。栈内存分配运算内置于处理器的指令集中，效率很高，但是分配的内存容量有限

​	**堆**：就是那些由 new分配的内存块，他们的释放编译器不去管，由我们的应用程序去控制，一般一个new就要对应一个 delete。如果程序员没有释放掉，那么在程序结束后，操作系统会自动回收

​	**自由存储区**：如果说堆是操作系统维护的一块内存，那么自由存储区就是C++中通过new和delete动态分配和释放对象的抽象概念。需要注意的是，自由存储区和堆比较像，但不等价。

​	**全局****/****静态存储区**：全局变量和静态变量被分配到同一块内存中，在以前的C语言中，全局变量和静态变量又分为初始化的和未初始化的，在C++里面没有这个区分了，它们共同占用同一块内存区，在该区定义的变量若没有初始化，则会被自动初始化，例如int型变量自动初始为0

​	**常量存储区**：这是一块比较特殊的存储区，这里面存放的是常量，不允许修改

​	**代码区**：存放函数体的二进制代码



#### 2.2、堆和栈

##### 1、堆与栈的区别

|              | 堆                                                           | 栈                                                           |
| :----------: | ------------------------------------------------------------ | ------------------------------------------------------------ |
|   管理方式   | 堆中资源由**程序员**分配，速度慢，有碎片                     | 栈由**系统**分配，速度快，不会存在碎片                       |
| 内存管理机制 | 系统有一个记录空闲内存地址的**链表**，当系统收到程序申请时，遍历该链表，寻找第一个空间大于申请空间的堆结点，删除空闲结点链表中的该结点，并将该结点空间分配给程序 | 只要栈的剩余空间大于所申请空间，系统为程序提供内存，否则，异常：栈溢出 |
|   空间大小   | 堆是不连续的内存区域（系统用链表来存储空闲内存地址，不连续），堆大小受限于计算机系统中的有效的虚拟内存（32位 -> 4G）,堆内存空间灵活，空间大 | 栈是一块连续的内存区域，大小由操作系统设置，windows下一般2M。可以通过**ulimit -a查看，由ulimit -s修改** |
|   碎片问题   | 堆中要频繁new / delete 会造成大量碎片，使程序效率降低        | 对于栈，它是有点类似于数据结构上的一个先进后出的栈，进出一一对应，不会产生碎片。 |
|   生长方向   | 堆向上，向高地址方向增长                                     | 栈向下，向低地址方向增长                                     |
|   分配方式   | 堆都是动态分配（没有静态分配的堆）                           | 栈有**静态**分配和**动态**分配，静态分配由编译器完成（如局部变量分配），动态分配由alloca函数分配（编译器释放） |
|   分配效率   | 堆由C/C++函数库提供，机制很复杂。在分配堆内存的时候需要一定的算法寻找合适大小的内存，并且获取堆的内容需要**两次访问**，第一次**访问指针**，第二次根据指针保存的地址**访问内存**，因此堆比较慢。 | 栈是其系统提供的数据结构，计算机载底层对栈提供支持，分配专门**寄存器存放栈地址**，栈操作有专门的**指令**，且入栈和出栈比较简单。 |

##### 2、为什么栈的速度比堆快？底层如何实现的？

- **申请速度快**：栈是程序运行前就已经分配好的空间，所以运行时分配几乎不需要时间。而堆是运行时malloc动态申请的 ，调用brk/sbrk 系统调用函数控制堆顶_edata往高地址方向变化，相当于将分配内存的耗时由编译阶段转嫁到了机器运行阶段，将分配过程从编译器搬到了运行的代码中。于是动态分配的速度不仅与分配算法有关，还与机器运行速度有关。 且malloc还需要动态的回收垃圾空间，一定程度上影响运行速度。

  - （栈是编译时分配空间，而堆是动态分配（运行时分配空间），所以栈的申请速度快）

- **存储寻址速度快**：栈的**物理地址空间是连续的**，而堆未必，查找堆的链表也会耗费较多时间，所以存储寻址速度慢。

- **CPU硬件操作速度快**：cpu有专门的寄存器(**rsp**，**rbp**）来操作栈，堆是使用间接寻址的，所以栈快。

- 硬件支持不同：栈是在一级缓存中做缓存的, 而堆则是在二级缓存中, 两者在硬件性能上差异巨大

  原文链接：https://blog.csdn.net/h2517956473/article/details/115317689

##### 3、为什么不能多使用栈？

​		**栈的地址空间必须连续**，如果任其任意成长，会给内存管理带来困难。对于**多线程程序**来说，**每个线程都必须分配一个栈，因此没办法让默认值太大。**

##### 4、栈的底层原理：汇编？

<img src="https://img-blog.csdn.net/20180510133702456?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3RlY18xNTM1/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt="img" style="zoom: 67%;" />

```C++
//举个栗子：实现两个数相加
int my_add(int a, int b)
{
	int z = a + b;
	return z;
}
 
int main()
{
	int a = 0XAAAAAAAA;
	int b = 0xFFFFFFFF;
	int add = my_add(a,b);
	cout << add << endl;
	return 0;
}
```

<img src="https://img-blog.csdn.net/20180510110509640?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3RlY18xNTM1/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt="img" style="zoom: 67%;" />

###### 1）栈帧

​		机器用栈来传递过程参数、存储返回信息、保存寄存器用于以后恢复，以及本地存储。而为单个过程分配的那部分栈称为帧栈；帧栈可以认为是程序栈的一段，它有两个端点，一个标识起始地址，一个标识着结束地址，两个指针结束地址指针esp，开始地址指针ebp;

###### 2）指针移动

​		由一系列栈帧构成，这些栈帧对应一个过程，而且每一个栈指针+4的位置存储函数返回地址；每一个栈帧都建立在调用者的下方，当被调用者执行完毕时，这一段栈帧会被释放。由于栈帧是向地址递减的方向延伸，因此如果我们将栈指针减去一定的值，就相当于给栈帧分配了一定空间的内存。如果将栈指针加上一定的值，也就是向上移动，那么就相当于压缩了栈帧的长度，也就是说内存被释放了。

###### 3）函数调用过程实现

- 备份原来的帧指针，调整当前的栈帧指针到栈指针位置；
- 建立起来的栈帧就是为被调用者准备的，当被调用者使用栈帧时，需要给临时变量分配预留内存；
- 使用建立好的栈帧，比如读取和写入，一般使用mov，push以及pop指令等等。
- 恢复被调用者寄存器当中的值，这一过程其实是从栈帧中将备份的值再恢复到寄存器，不过此时这些值可能已经不在栈顶了
- 恢复被调用者寄存器当中的值，这一过程其实是从栈帧中将备份的值再恢复到寄存器，不过此时这些值可能已经不在栈顶了。
- 释放被调用者的栈帧，释放就意味着将栈指针加大，而具体的做法一般是直接将栈指针指向帧指针，因此会采用类似下面的汇编代码处理。
- 恢复调用者的栈帧，恢复其实就是调整栈帧两端，使得当前栈帧的区域又回到了原始的位置。
- 弹出返回地址，跳出当前过程，继续执行调用者的代码。

###### 4）过程调用和返回指令

- call指令

- leave指令

- ret指令

  原文链接：https://blog.csdn.net/tec_1535/article/details/80260839

##### 5、怎么确定栈中某变量i的位置？

​		确定一个变量i的位置，根据与ebp的**偏移量**。

​		ebp：指向栈底；esp：指向栈顶

​		**ebp+i表示的是取参数的地址，ebp-i表示的是取函数内部的局部变量地址,0则表示的是函数的返回地址**。

​		函数的参数压栈方向是从右向左，最后将函数的地址压栈；而函数内部的变量是从上到下依次压栈。

​		ret 地址，也就是函数return的返回地址，通常是保存在esp中的地址，而有时候函数会有返回值，该值一般保存在eax寄存器中返回，函数退出前，会pop出esp指向的数据作为返回函数的地址。

##### 6、栈溢出

###### 1）定义

​		栈溢出是程序向栈中写入某元素的字节数超过栈中所申请的字节数，导致其相邻的值都被改变；

###### 2）原因：

- **局部数组过大**：栈中存放的是局部变量，当向栈中定义的局部数据过大的话，会导致栈溢出 -> 增大栈空间内存、使用动态分配内存存储、改用一个static静态变量（不会占用栈内存）；
- **递归次数太多**导致栈溢出 ：使用动态分配内存，并在每一次递归结束释放内存；
- **指针/数组越界**：拷贝字符串、输入元素 -> 动态分配内存；

##### 7、修改堆栈的方法

​		Linux环境下有操作系统决定，一般是8KB，8192kbytes，通过ulimit命令查看以及修改；

​		Windows环境下由编译器决定，VC++6.0一般是1M

###### 1）Window

​		程序栈空间的大小，VC++ 6.0 默认的栈空间是1M。

​		VC6.0中修改堆栈大小的方法：

```c++
选择 "Project->Setting"
选择 "Link"
选择 "Category"中的 "Output"
在 "Stack allocations"中的"Reserve:"中输栈的大小
```

###### 2）Linux

​		linux下非编译器决定栈大小，而是由操作系统环境决定，默认是8192KB（8M）；而在Windows平台下栈的大小是被记录在可执行文件中的（由编译器来设置)，即：windows下可以由编译器决定栈大小，而在Linux下是由系统环境变量来控制栈的大小的。在Linux下通过如下命令可查看和设置栈的大小：

```c++
$ ulimit -a # 显示当前栈的大小 （ulimit为系统命令，非编译器命令） 
$ ulimit -s 32768 # 设置当前栈的大小为32M
```



#### 2.3、malloc / free 与 new / delete

##### 1、malloc/free底层原理

###### 1）底层函数

​		malloc/free的函数底层是由**brk、mmap、munmap**这些**系统调用**实现的。

```c++
//brk()和sbrk()函数
#include <unistd.h>
int brk( const void *addr )
void* sbrk ( intptr_t incr );
```

- 两者的作用是扩展heap的上界brk
  - brk（）的参数设置为新的brk上界地址，成功返回1，失败返回0；
  - sbrk（）的参数为申请内存的大小，返回heap新的上界brk的地址。

```c++
//mmap()和munmap()函数
#include <sys/mman.h>
void *mmap(void *addr, size\_t length, int prot, int flags, int fd, off\_t offset);
int munmap(void *addr, size_t length);
```

- mmap的第一种用法是映射此盘文件到内存中；第二种用法是匿名映射，不映射磁盘文件，而向映射区申请一块内存。
  - malloc使用的是mmap的第二种用法（匿名映射）;
  - munmap函数用于释放内存。

###### 2）实现原理

​		brk是将数据段（.data）的最高地址指针**_edata往高地址推**，mmap（）是在进程的虚拟地址空间中找一块空闲的虚拟内存，这两种方式分配的都是虚拟内存，没有分配物理内存。在第一次访问的时候访问已分配的虚拟地址空间的时候，发生**缺页中断**，然后操作系统就会分配物理内存，并且建立虚拟内存和物理内存之间的**映射关系**。

​    malloc小于128K的内存，使用brk分配内存，将_edata往高地址推；malloc大于128K的内存，就使用mmap进行分配。malloc是从堆里面申请内存，也就是说调用这个函数返回的指针是指向堆里面的一块内存，操作系统中有一个记录空闲内存地址的链表，当操作系统收到程序的申请的时候，就会遍历该链表，然后寻找第一个空间大于所申请空间的堆结点，把该节点从空闲结点链表中删除，并将该结点的空间分配给程序。

​		**malloc函数分配内存，如果请求内存大于128K（可由M_MMAP_THRESHOLD选项调节），那就不是去推_edata指针了，而是利用mmap系统调用，从堆和栈的中间分配一块虚拟内存**。

**这样子做主要是因为:**

　　**brk() 分配的内存需要等到高地址内存释放以后才能释放**（例如，在B释放之前，A是不可能释放的，因为只有一个_edata 指针，这就是内存碎片产生的原因，当**最高地址空间的空闲内存超过128K**（可由M_TRIM_THRESHOLD选项调节）时，执行**内存紧缩（trim）**。在上一个步骤free的时候，发现最高地址空闲内存超过128K，于是内存紧缩），而mmap() 分配的内存可以单独释放。

​		**==注==：将_edata往高地址推(只分配虚拟空间，不对应物理内存(因此没有初始化)，第一次读/写数据时，引起内核缺页中断，内核才分配对应的物理内存，然后虚拟地址空间建立映射关系)**。

###### 3）缺页中断后发生的具体内容：

- 当一个进程发生缺页中断的时候，进程会陷入核心态，执行以下操作：
  - 检查要访问的虚拟地址是否合法
  - 查找/分配一个物理页
  - 填充物理页内容（读取磁盘，或者直接置0，或者什么都不做）
  - 建立映射关系（虚拟地址到物理地址的映射关系）
  - 重复执行发生缺页中断的那条指令

  ​	如果第3步，需要读取磁盘，那么这次缺页就是 majfit(major fault：大错误),否则就是 minflt(minor fault：小错误)。

  ​	原文链接：https://www.cnblogs.com/zpcoding/p/10808969.html

###### 4）ptmalloc

​		因为brk、sbrk、mmap都属于系统调用，若每次申请内存，都调用这三个，那么每次都会产生系统调用，影响性能；其次，这样申请的内存容易产生碎片，因为堆是从低地址到高地址，如果高地址的内存没有被释放，低地址的内存就不能被回收。
　　
　　所以malloc采用的是**内存池的管理方式（ptmalloc）**，Ptmalloc 采用**边界标记法**（内存碎片处理方法）将内存划分成很多块，从而对内存的分配与回收进行管理。为了内存分配函数malloc的高效性，ptmalloc会预先向操作系统申请一块内存供用户使用，当我们申请和释放内存的时候，ptmalloc会将这些内存管理起来，并通过一些策略来判断是否将其回收给操作系统。这样做的最大好处就是，使用户申请和释放内存的时候更加高效，避免产生过多的内存碎片。

​		原文链接：https://blog.csdn.net/z_ryan/article/details/79950737

##### 2、new / delete 是如何实现的？

- new的实现过程是：首先调用名为**operator new**的标准库函数，分配足够大的原始为类型化的内存，以保存指定类型的一个对象；接下来运行该类型的一个构造函数，用指定初始化构造对象；最后返回指向新分配并构造后的的对象的指针。
- delete的实现过程：对指针指向的对象运行适当的析构函数；然后通过调用名为**operator delete**的标准库函数释放该对象所用内存。
- **注：new / delete 底层都是malloc / free实现的**

###### 1）new实现原理：

​		new简单类型直接调用operator new分配内存；而对于复杂结构，先调用operator new分配内存，然后在分配的内存上调用构造函数；

​		对于简单类型，new[]计算好大小后调用operator new；对于复杂数据结构，new[]先调用operator new[]分配内存，然后在p的前四个字节写入数组大小n，然后调用n次构造函数，针对复杂类型，new[]会额外存储数组大小；

- new表达式调用一个名为operator new(operator new[])函数，分配一块足够大的、原始的、未命名的内存空间；
- 编译器运行相应的构造函数以构造这些对象，并为其传入初始值；
- 对象被分配了空间并构造完成，返回一个指向该对象的指针。

###### 2）delete是如何知道释放内存的大小的？

- delete简单数据类型默认只是调用free函数；复杂数据类型先调用析构函数再调用operator delete；针对简单类型，delete和delete[]等同。假设指针p指向new[]分配的内存。因为要4字节存储数组大小，实际分配的内存地址为[p-4]，系统记录的也是这个地址。delete[]实际释放的就是p-4指向的内存。而delete会直接释放p指向的内存，这个内存根本没有被系统记录，所以会崩溃。
- 需要在 new [] 一个对象数组时，需要保存数组的维度，C++ 的做法是**在分配数组空间时多分配了 4 个字节的大小，专门保存数组的大小，在 delete [] 时就可以取出这个保存的数**，就知道了需要调用析构函数多少次了。



##### 3、malloc / free 与 new / delete 区别

|            | malloc / free                                                | new / delete                                                 |
| ---------- | ------------------------------------------------------------ | ------------------------------------------------------------ |
| 属性       | malloc/free是**库函数**，需要头文件支持                      | new/delete是C++**关键字**，需要编译器支持                    |
| 参数       | malloc需要显式地指出所需内存大小                             | new操作符申请内存分配时无需指定**内存块的大小**，编译器自动计算 |
| 返回类型   | malloc内存分配成功则是返回void * ，需要通过**强制类型转换**将void *指针转换成需要的类型； | new操作符内存分配成功时，返回对象类型指针，**类型严格与对象匹配**，无需进行类型转换，new是符合类型**安全**性的操作符。 |
| 分配失败   | malloc分配内存失败返回**NULL**                               | new会抛出**bac_alloc**异常                                   |
| 构造和析构 | malloc/free无法满足动态对象的要求，是库函数，只能实现动态的申请和释放内存，无法满足动态对象的要求，对象在创建的同时要自动执行构造函数，对象消亡时要自动执行析构函数，无法强制要求其做自定义类型对象的构造和析构工作。也是因为malloc/free是库函数，不在编译器权限范围之内，不能够把执行构造函数和析构函数的任务强加于malloc/free。 | new首先会调用operator new函数，申请内存（底层通常由malloc实现），然后调用该类型的**构造函数**，初始化成员变量，最后返回对象类型的指针；delete先调用**析构函数**，然后调用operator delete释放内存（底层通常由free实现） |
| 关系       |                                                              | new是封装了malloc，直接free不会报错，但是这只是释放内存，而不会析构对象 |

```C++
 Animal* s = new Cat("Tom"); //new可以调用构造函数
```

​       注意： malloc分配的内存空间在虚拟地址空间上是连续的，但是转换到物理内存空间上，有可能不连续，因为有可能相邻两个字节是在不同的物理分页上；**delete []：**可以不带[]，主要是连续地址和不连续的地址，连续开辟的地址就可以不带括号，不连续的就不行。

##### 4、怎么确定free具体的地址？

​		free函数释放动态申请的内存时只需要把内存块的**首地址**传过去就行了，Linux里面glibc在分配内存的时候会在内存块的地址**前面的4个字节出存放内存块的大小**，Windows里面当我们使用free函数释放内存的时候，函数会把内存块的**首地址加上16**，从这个位置就可以找到内存块的大小。

​		原文链接：https://blog.csdn.net/don_chiang709/article/details/89155340

##### 5、double free会发生什么情况？

###### 1）后果

​		潜在导致**对未知内存位置的修改**。当程序调用两次带有同一参数的free()，程序的内存管理数据结构会崩溃。程序也随之崩溃，或者在某些情况下，会后续导致两次调用返回统一指针malloc()。如果malloc()返回同一指针两次，攻击者将获得对这段两次分配的内存中写入的数据的控制，对于缓冲区溢出攻击，程序会变得脆弱不堪。

###### 2）错误定位：

- 一般都配置**coredump**，可以直接用gdb从core文件中找到报错的堆栈；
- 在没有coredump的情况下，可以通过**addr2line**结合上面的报错堆栈把函数调用打出来：

​		有时double free的问题并不是那么好定位，尤其是使用**tcmalloc**等内存管理的library时，程序free一个已经释放的空间时，并不会立即报错（这块内存并没有返回系统），只是在做真正gc或者内存重分配时，才会报错，这个错误堆栈就和double free的位置相差甚远了。这个时候使用上面的方法就不太容易解决了。

- 设置**MALLOC_CHECK_**环境变量，实现对内存的分配和释放的检查：
  - MALLOC_CHECK_=0：关闭所有检查；
  - MALLOC_CHECK_=1：当有错误被探测到时，在标准错误输出(stderr)上打印错误信息；
  - MALLOC_CHECK_=2：当有错误被探测到时，不显示错误信息,直接进行中断。
- 也可以通过`**mtrace**`来做检测，只是该方法对业务代码有侵入，需要在应用程序中设置环境变量。
- 也可以通过`**systap**`在程序中加一些探点来做，参照文章：https://cjfeii.blog.csdn.net/article/details/51518437

​		原文链接：https://blog.csdn.net/cjfeii/article/details/114918107

##### 6、被free回收的内存是立即返回给系统吗？

​		不是的，被free回收的内存会首先被**ptmalloc**使用**双链表**保存起来，当用户下一次申请内存的时候，会尝试从这些内存中寻找合适的返回。这样就避免了频繁的系统调用，占用过多的系统资源。同时ptmalloc也会尝试**对小块内存进行合并**，**避免**过多的**内存碎片**。



#### 2.4、内存碎片

##### 1、内存碎片问题

​     直接使用new、malloc等API申请分配内存，这样做的缺点在于：由于所申请内存块的大小不定，当频繁使用时会造成大量的内存碎片并进而降低性能。内存碎片就是一般是由于空闲的连续空间比要申请的空间小，导致这些小内存块不能被利用，就造成了内存浪费。所以其实可以考虑realloc重新分配内存。

##### 2、避免碎片

​    一般是处理外部碎片问题，就是所有空闲内存合起来满足一个分配要求，但是没有一个单独的空闲块可以满足这个要求。主要需要解决的问题：

-  如何记录空闲块
- 如何选择内存块来放置新分配的块
- 放置好新分配的内存块后，如何处理剩余部分
- 如何合并一个刚释放的块

##### 3、解决方法

- 利用隐式空闲链表，连接起来，就可以间接地相当于遍历了整个空闲块；
- 开发一种适当的技术来记录现存的空闲的连续页框块的大小，这样知道大小了，就可以尽量避免为满足小块的请求而分割大的空闲块；
- 当找到哪个空间放置空闲块，就需要考虑分割的问题了。一般是按需分割，剩下的就是一个新的空闲块；
- 边界标记合并技术，在每个块的结尾加一个脚部，脚部是头部的一个副本，这样做就可以通过检查脚来判断前一个块的起始位置和状态，可实现常数时间内的碎片合并。

##### 4、边界标记合并技术

   可能存在的情况四种情况：

- 前面的块和后面的块都是已分配的。

- 前面的块是已分配的，后面的块是空闲的。

- 前面的块是空闲的，而后面的块是已分配的。

- 前面的和后面的块都是空闲的。

  

  在情况1 中，两个邻接的块都是已分配的，因此不可能进行合并。所以当前块的状态只是简单地从已分配变成空闲。

  在情况2 中，当前块与后面的块合并。用当前块和后面块的大小的和来更新当前块的头部和后面块的脚部。

  在情况3 中，前面的块和当前块合并。用两个块大小的和来更新前面块的头部和当前块的脚部。

  在情况4 中，要合并所有的三个块形成一个单独的空闲块，用三个块大小的和来更新前面块的头部和后面块的脚部。在每种情况中，合并都是在常数时间内完成的。

  

#### 2.5、malloc、realloc、calloc的区别

##### 1、malloc

```c++
void* malloc(unsigned int num_size);
int *p = malloc(20*sizeof(int));//申请20个int类型的空间,申请的空间的值是随机初始化的
```

##### 2、realloc

```c++
void realloc(void *p, size_t new_size);//给动态分配的空间分配额外的空间，用于扩充容量
```

​    extern void *realloc(void *mem_address, unsigned int newsize);改变men_address所指内存区域的大小为newsize长度。如果重新分配成功则返回指向被分配内存的指针，否则返回空指针NULL。需要注意的是，这边原始内存中的数据还是保持不变的。

 **需要注意的是：**

1）有足够空间用于扩大mean_address指向的内存块，则分配额外内存，并返回mean_address，realloc是从堆中分配内存的，当扩大一块内存空间时，realloc会试图直接从堆上现存的数据后面的那些字节中获得附加的字节，得到的是一块连续的内存。

 2）若是原先内存大小后面没有足够的空闲空间来分配，那么就需要从堆中另外找一块newsize大小的内存，并把原来大小内存空间中的内容复制到newsize中，返回新的mean_address指针（数据被移动了），老的内存被放回到堆上。**所以，realloc 并不保证调整后的内存空间和原来的内存空间保持同一内存地址。相反，realloc 返回的指针很可能指向一个新的地址。所以在代码中，我们必须将realloc返回的值，重新赋值**。

3）特殊情况：mean_address为NULL，则realloc和malloc类似；如果newsize大小为0，那么释放mean_address指向的内存，并返回NULL**指针被释放后没有置空，会变成野指针**；如果没有足够可用的内存用来完成重新分配（扩大原来的内存块或者分配新的内存块），则返回null，原来的内存块保持不变。

##### 3、calloc

```c++
void* calloc(size_t n,size_t size);
int *p = calloc(20, sizeof(int));
```



#### 2.6、memcpy、strcpy与memset

##### 1、内存重叠问题

​     strcpy和memcpy都没有对内存重叠做处理，使用这两个函数只能程序员自己保证源地址和目的地址不重叠。

​     memcpy()和memmove()都是c语言的库函数(头文件保护#include <string.h>)，作用是拷贝一定长度内存的内容。它们唯一的区别是当内存发生局部重叠时，memmove可以保证拷贝正确，memcpy拷贝的结果是未定义的（取决于编译平台内部对memcpy的优化处理）。

**实现内存重叠代码**

​		str = {"abcdefgh"};memcpy(str+2,str,5); //应该得到abcde

​		所以内存覆盖的时候，应该从后往前复制，才不会把最开始的src覆盖掉，才能得到正确的结果

```C++
//memcpy需要指定长度
void *memcpy(void *dest, const void *src, size_t n){//数据从低地址向高地址复制
        assert(dest != NULL && src != NULL);
        char *d = (char *)dest;
        char *s = (char *)src;
        if (d > s && d < s + n){ // 从后往前复制，有内存重叠问题
              d += n - 1;
              s += n - 1;
              while (n--){
                  *d-- = *s--;
              }
        }
        else{ // 从前往后复制
             while (n--){
                    *d++ = *s++;
             }
        }
        return dest;
}

// strcpy原型实现（类似memcpy），strcpy不需要指定长度，遇到字符串结束符（\0）结束
char *strcpy(char *dest, const char *src){
        assert(dest != NULL && src != NULL);
        char *pdst = dest;
        size_t n = strlen(src);
        if (dest > src && dest < src + n){//内存重叠
            src += n - 1;
            pdst += n;
           *pdst-- = '\0';//指定字符结束符
           while (n--){
               *pdst-- = *src--;
           }
         }
        else{
           while ((*pdst++ = *src++) != '\0');
        }
        return dest;
}

// memset原型实现 
void *memset(void *src, int c, size_t n){
      assert(src != NULL);
char *psrc = (char *)src;
while (n--)
{
*psrc++ = (char)c;
}
return src;
}
```

##### 2、区别

- 复制的内容不同：strcpy只能复制字符串，而memcpy可以复制任意内容，例如字符数组、整型、结构体、类等。
- 复制的方法不同：strcpy不需要指定长度，它遇到被复制字符的串结束符"\0"才结束，所以容易溢出。memcpy则是根据其第3个参数决定复制的长度。
- 用途不同：通常在复制字符串时用strcpy，而需要复制其他类型数据时则一般用memcpy
- 实现功能不同：strcpy主要是实现字符串变量间的拷贝，memcpy主要是内存块间的拷贝。
- 效率不同：memcpy > strcpy



#### 2.7、内存泄露和内存溢出

##### 1、内存溢出和内存泄露的概念

​		**内存泄漏：**程序在申请内存后，无法释放已申请的内存空间，导致系统无法及时回收内存并分配给其他进程使用。若是内存比较少，会导致内存不够用，最终导致内存溢出。**（没释放）**

​       **内存溢出：**指程序申请内存时，没有足够的内存供申请者使用，导致数据无法正常存储到内存中。也就是说给你个int类型的存储数据大小的空间，但是却存储一个long类型的数据，这样就会导致内存溢出。**（多了）**

##### 2、内存溢出和内存泄露关系和区别

 		**关系：**内存泄漏最终会导致内存溢出，由于系统中的内存是有限的，如果过度占用资源而不及时释放，最后会导致内存不足，无法给所需要存储的数据提供足够的内存，从而导致内存溢出。导致内存溢出也可能是由于在给数据分配大小时没有根据实际要求分配，最后导致分配的内存无法满足数据的需求，从而导致内存溢出。

​      **区别：**内存泄漏是因为内存没有对可以回收的数据进行及时回收，导致内存的浪费。内存溢出则是由于数据需要的内存无法得到满足，导致数据无法正常存储到内存中。内存泄漏的多次表现会导致内存溢出。



#### 2.8、内存泄露

##### 1、什么是内存泄露？

​		**动态分配的内存未释放或者无法释放，但是原本指向这块内存的指针却失去了对这块内存的控制，导致内存的浪费**。

​		内存泄漏是指由于疏忽或错误造成了程序未能释放掉不再使用的内存的情况。内存泄漏并非指内存在物理上消失，而是应用程序分配某段内存后，由于设计错误，失去了对该段内存的控制；

##### 2、内存泄露的后果

​		只发生一次小的内存泄漏可能不被注意，但泄漏大量内存的程序将会出现各种证照：性能下降到内存逐渐用完，导致另一个程序失败；

##### 3、如何排除？

- 使用工具软件BoundsChecker，BoundsChecker是一个运行时错误检测工具，它主要定位程序运行时期发生的各种错误；

- 调试运行DEBUG版程序，运用以下技术：CRT(C run-time libraries)、运行时函数调用堆栈、内存泄漏时提示的内存分配序号(集成开发环境OUTPUT窗口)，综合分析内存泄漏的原因，排除内存泄漏。

##### 4、解决方法：智能指针

​		智能指针：**智能指针可以解决内存泄露的问题，因为用完后会自动释放，智能指针通过一个引用计数器去记录变量被引用的情况。当最后一个引用被销毁时，系统自动释放该指针**

​		智能指针的作用是管理一个指针，因为存在以下这种情况：申请的空间在函数结束时忘记释放，造成内存泄漏。使用智能指针可以很大程度上的避免这个问题，因为智能指针就是一个类，当超出了类的作用域是，类会自动调用析构函数，析构函数会自动释放资源。所以智能指针的作用原理就是在函数结束时自动释放内存空间，不需要手动释放内存空间。

​		原文链接：https://blog.csdn.net/weixin_42067304/article/details/108451031

##### 5、检查、定位内存泄露

###### 1）检查方法：

​		在main函数最后面一行，加上一句**_CrtDumpMemoryLeaks()**。调试程序，自然关闭程序让其退出，查看输出：

```c++
输出这样的格式{453}normal block at 0x02432CA8,868 bytes long
```

​		被{}包围的453就是我们需要的内存泄漏定位值，868 bytes long就是说这个地方有868比特内存没有释放。

###### 2）定位代码位置：

​		在main函数第一行加上**_CrtSetBreakAlloc(453)**

​		意思就是在申请453这块内存的位置中断。然后调试程序，程序中断了，查看调用堆栈。加上头文件#include <crtdbg.h>



#### 2.9、内存池

​		内存池（Memory Pool） 是一种**内存分配**方式。通常我们习惯直接使用new、malloc 等申请内存，这样做的缺点在于：由于所申请内存块的大小不定，当频繁使用时会造成大量的内存碎片并进而降低性能。内存池则是在真正使用内存之前，先申请分配一定数量的、大小相等(一般情况下)的内存块留作备用。当有新的内存需求时，就从内存池中分出一部分内存块， 若内存块不够再继续申请新的内存。这样做的一个显著优点是尽量避免了内存碎片，使得内存分配效率得到提升。

​		这里**简单描述一下《STL源码剖析》中的内存池实现机制**：

​		**allocate** **包装** **malloc**，**deallocate**包装**free**：

​		一般是一次20*2个的申请，先用一半，留着一半，为什么也没个说法，侯捷在STL那边书里说好像是C++委员会成员认为20是个比较好的数字，既不大也不小。

- 首先客户端会调用malloc()配置一定数量的区块（固定大小的内存块，通常为8的倍数），假设40个32bytes的区块，其中20个区块（一半）给程序实际使用，1个区块交出，另外19个处于维护状态。剩余20个（一半）留给内存池，此时一共有（20*32byte）

- 客户端之后有有内存需求，想申请（20*64bytes）的空间，这时内存池只有（20*32bytes），就先将（10*64bytes)个区块返回，1个区块交出，另外9个处于维护状态，此时内存池空空如也.

- 接下来如果客户端还有内存需求，就必须再调用malloc()配置空间，此时新申请的区块数量会增加一个随着配置次数越来越大的附加量，同样一半提供程序使用，另一半留给内存池。申请内存的时候用永远是先看内存池有无剩余，有的话就用上，然后挂在0-15号某一条链表上，要不然就重新申请。

- 如果整个堆的空间都不够了，就会在原先已经分配区块中寻找能满足当前需求的区块数量，能满足就返回，不能满足就向客户端报bad_alloc异常

allocator就是用来分配内存的，最重要的两个函数是allocate和deallocate，就是用来申请内存和回收内存的，外部（一般指容器）调用的时候只需要知道这些就够了。内部实现，目前的所有编译器都是直接调用的::operator new()和::operator delete()，说白了就是和直接使用new运算符的效果是一样的，所以说它们都没做任何特殊处理。



#### 2.10、不同的new类型

在C++中，new有三种典型的使用方法：plain new、nothrow new、placement new

##### 1、plain new

​		plain new 也就是普通的new，在空间分配失败的情况下，抛出异常**bad_alloc**而不是返回NULL，因此通过判断返回值是否为NULL是徒劳的。

```c++
void* operator new(std::size_t) throw(std::bad_alloc);
void operator delete(void *) throw();
```

##### 2、nothrow new

​		nothrow new 在空间分配失败的情况下是不抛出异常的，而是**返回NULL**。

```c++
void * operator new(std::size_t,const std::nothrow_t&) throw();
void operator delete(void*) throw();
```

##### 3、placement new

​		placement new 允许在一块已经分配成功的内存上**重新构造对象或对象数组**。placement new不用担心内存分配失败，因为它根本**不分配内存**，它做的唯一一件事情就是**调用对象的构造函数**。

```c++
void* operator new(size_t,void*);
void operator delete(void*,void*);
```

**使用placement new 需要注意以下两点：**

- palcement new的主要用途就是反复使用一块较大的动态分配的内存来构造不同类型的对象或者他们的数组
- placement new构造起来的对象数组，要显式的调用他们的析构函数来销毁（析构函数并不释放对象的内存），千万不要使用delete，这是因为placement new构造起来的对象或数组大小并不一定等于原来分配的内存大小，使用delete会造成内存泄漏或者之后释放内存时出现运行时错误。



### 3、C++11新特性

#### 3.1、RAII 和 NRV

##### 1、RAII

​		RAII（Resource Acquisition Is Initialization ，资源获得即初始化），是一种利用对象生命周期来控制程序资源的简单技术。在对象构造时获得资源，接着控制对资源的访问在对象的生命周期内始终有效，最后在对象析构时释放资源。因为C++的语言机制保证了，当一个对象创建的时候，自动调用构造函数，当对象超出作用域的时候会自动调用析构函数。所以，在RAII的指导下，我们应该使用类来管理资源，将资源和对象的生命周期绑定。这样的好处在于：

- 不需要显示的释放资源
- 对象所管理的资源在其生命周期内始终有效

##### 2、NRV

​		

#### 3.2、智能指针

​		智能指针包含在头文件 < memory >中，标准命名std空间下，有auto_ptr（已经被弃用）、shared_ptr、weak_ptr、unique_ptr。智能指针就是模拟指针动作的类，一般智能指针都会重载 **-> **和 *** **，主要作用时管理动态内存的释放。

​		智能指针是一个**类**，用来存储指向动态分配对象的指针，负责自动释放动态分配的对象，防止堆内存泄漏。动态分配的资源，交给一个类对象去管理，当类对象声明周期结束时，自动调用析构函数释放资源。

​       **智能指针的本质是基于RAII原理，即当程序运行超过某个作用域("{ }"包含的区域)时，在该作用域内声明定义的对象会自动调用自己的析构函数析构。当智能指针对象析构时，会将它所指向的对象的资源释放掉，从而不用用户自己手动的调用delete释放。**

##### 1、智能指针解决的问题

- 处理资源泄漏；有指针的时候，忘记释放已经不使用的内存，从而导致内存泄漏；


- 处理空悬指针；虽然释放了申请的内存，但是ptr会变成空悬指针（野指针），会指向垃圾内存，因此需要将内存释放后的指针置空（ptr = nullptr;) 
- 比较隐晦的由异常造成的资源泄漏；new创建对象后因为发生异常而忘记调用delete。

##### 2、shared_ptr

​		多个指针指向相同的对象，采用**引用计数**的方式解决赋值与拷贝问题，**每个shared_ptr的拷贝都指向同一块内存**，每次拷贝内部引用计数+1，每次析构内部引用计数-1，为0时自动删除所指向的堆内存。其内部的**引用计数是线程安全的，但是对象读取时需要加锁**。

​		智能指针对象中引用计数是多个智能指针对象共享的，两个线程中的引用计数同时++或者--，这个操作不是原子的，举个例子，应用计数原来是1，++了两次，可能还是2。这样引用计数就错乱了，会导致资源未释放或者程序崩溃的问题，所以其实智能指针是加锁了的，也就是说引用计数的操作是线程安全的。

​        循环引用问题：循环引用简单来说就是：两个对象互相使用一个`shared_ptr`成员变量指向对方，这会造成循环引用。导致引用计数失效，[内存](https://so.csdn.net/so/search?q=内存&spm=1001.2101.3001.7020)无法释放。

​		声明： template  < class T >  class shared_ptr;

###### 1）注意事项：

- 不能将指针直接赋值给一个智能指针，一个是类，一个是指针，不能直接shared_ptr < int > p = new int;
- 避免循环引用，会导致内存泄漏，会在weak_ptr得到完善；
- 管理数组指针时，需要指定Delete以使用delete[] 操作符销毁内存，shared_ptr并没有针对数组的特化版本；
- 不能把一个原生指针交给两个智能指针对象管理，其他智能指针也是这样。

###### 2）实现

- 智能指针将一个计数器与类指向的对象相关联，引用计数器跟踪共有多少个类对象共享同一指针。
- 每次创建类的新对象时，初始化指针并将引用计数置为1。
- 当对象作为另一对象的副本而创建时，拷贝构造函数拷贝指针并增加与之相应的引用计数。
- **对一个对象进行赋值时，赋值操作符减少左操作数所指对象的引用计数（如果引用计数为减至0，则删除对象），并增加右操作数所指对象的引用计数**。
- 调用析构函数时，构造函数减少引用计数（如果引用计数减至0，则删除基础对象）

###### 3）代码

```C++
template <typename T>
class sharedPointer
{
private:
    class Implement
    {
    public:
        Implement(T* p) : mPointer(p), mRefs(1) {}
        ~Implement() { delete mPointer; }

        T* mPointer;
        size_t mRefs;
    };
    Implement* mImplPtr;
public:
    explicit sharedPointer(T *p) : mImplPtr (new Implement(p)) {} //explicit不能发生隐式类型转换，就是参数类型不匹配，就会进行隐式转换
    ~sharedPointer() { decrease(); } //计数递减
    sharedPointer(const sharedPointer& other) : mImplPtr(other.mImplPtr) { increase(); } //计数递增

    sharedPointer operator = (const sharedPointer& other)
    {
        if (mImplPtr != other.mImplPtr) //避免自赋值
        {
            decrease();
            mImplPtr = other.mImplPtr;
            increase();
        }
        return *this;
    }

    T* operator -> () const
    {
        return mImplPtr->mPointer;
    }

    T* operator *() const
    {
        return *(mImplPtr->mPointer);
    }

private:
    void decrease()
    {
        if (--mImplPtr->mRefs) == 0) 
            delete mImplPtr;
    }
    void increase()
    {
        ++(mImplPtr->mRefs);
    }
};
```

##### 3、make_shared

​		**make_shared:**是一种安全分配和使用动态内存的方法，主要功能是在动态内存中分配一个对象并且使用它，返回此对象的shared_ptr。

**make_shared生成shared_ptr的优点和缺点:**

1）效率更高，原始的 new 表达式分配对象, 然后传递给 shared_ptr (也就是使用 shared_ptr 的构造函数) 的话, shared_ptr 的实现没有办法选择, 而只能单独的分配控制块，但是make_shared内存分配，可以一次性完成，减少了内存分配的次数，所以效率高；

```C++
auto p = new widget();
shared_ptr sp1{ p }, sp2{ sp1 };

auto sp1 = make_shared(), sp2{ sp1 };
```

2）异常安全。比如说可能连续构造两个对象，然后再分配shared_ptr,那我构造一个对象发生可能异常，这个对象就泄漏了，就是说有可能造成shared_ptr 没有立即获得裸指针。这种情况就推荐使用make_shared来代替。

```C++
void F(const std::shared_ptr<Lhs>& lhs, const std::shared_ptr<Rhs>& rhs) { /* ... */ }
F(std::shared_ptr<Lhs>(new Lhs("foo")),std::shared_ptr<Rhs>(new Rhs("bar")));

F(std::make_shared<Lhs>("foo"), std::make_shared<Rhs>("bar"));
```

3）构造函数是保护或者私有的，不能使用make_shared

4）make_shared对象的内存可能没有办法及时回收。

##### 4、weak_ptr 

​		weak_ptr 能访问资源，但不控制其生命周期的指针

​		weak_ptr是为了配合shared_ptr而引用的一种智能指针，专门用于解决shared_ptr**循环引用**（class A和class B分别被对方的智能指针所管理[循环引用会导致内存无法正确释放，从而内存泄漏]）的问题，**没有重载operater *和->**，最大作用在于协助shared_ptr工作，像旁观者那样观测资源的使用情况。它是为了配合shared_ptr而引入的一种智能指针，它指向一个由shared_ptr管理的对象而不影响所指对象的生命周期，也就是说，它只引用，不计数。

​		如果一块内存被shared_ptr和weak_ptr同时引用，当所有shared_ptr析构了之后，不管还有没有weak_ptr引用该内存，内存也会被释放。所以weak_ptr不保证它指向的内存一定是有效的，在使用之前使用函数**lock()**检查weak_ptr是否为空指针。weak_ptr可以从一个shared_ptr或者另一个weak_ptr对象构造，从而获得资源的观测权。但是weak_ptr没有共享资源，它的构造不会引起指针引用计数的增加。它通过**lock()**，从被观测的shared_ptr获得一个可用的shared_ptr对象，从而操作资源。

###### 1）函数接口

```c++
weak-ptr<T> w;//空weak_ptr可以指向类型为T的对象
weak_ptr<T> w(sp);//与shared_ptr sp指向相同对象的weak_ptr。T必须能够转换为sp指向的类型
w = p;//p可以是一个shared_ptr或一个weak_ptr。赋值后w与p共享对象

w.reset();//将w置空
w.use_count();//与w共享对象的shared_ptr的数量
w.expired();//若w.use_count()为0,返回true，否则返回false
w.lock();//如果w.expired()为true，返回一个空shared_ptr，否则返回一个指向w的对象的shared_ptr
```

​		**weak_ptr提供了expired()与lock()成员函数，前者用于判断weak_ptr指向的对象是否已被销毁，后者返回其所指对象的shared_ptr智能指针(对象销毁时返回”空”shared_ptr)。**

###### 2）代码

```C++
template<class _Ty>
class weak_ptr: public _Ptr_base<_Ty>
{    // class for pointer to reference counted resource
    typedef typename _Ptr_base<_Ty>::_Elem _Elem;

public:
    weak_ptr()
    {    // construct empty weak_ptr object
    }

    template<class _Ty2>
    weak_ptr(const shared_ptr<_Ty2>& _Other,
        typename enable_if<is_convertible<_Ty2 *, _Ty *>::value,
        void *>::type * = 0)
    {    // construct weak_ptr object for resource owned by _Other
        this->_Resetw(_Other);
    }

    weak_ptr(const weak_ptr& _Other)
    {    // construct weak_ptr object for resource pointed to by _Other
        this->_Resetw(_Other);
    }

    template<class _Ty2>
    weak_ptr(const weak_ptr<_Ty2>& _Other,
        typename enable_if<is_convertible<_Ty2 *, _Ty *>::value,
        void *>::type * = 0)
    {    // construct weak_ptr object for resource pointed to by _Other
        this->_Resetw(_Other);
    }

    ~weak_ptr()
    {    // release resource
        this->_Decwref();
    }

    weak_ptr& operator=(const weak_ptr& _Right)
    {    // assign from _Right
        this->_Resetw(_Right);
        return (*this);
    }

    template<class _Ty2>
    weak_ptr& operator=(const weak_ptr<_Ty2>& _Right)
    {    // assign from _Right
        this->_Resetw(_Right);
        return (*this);
    }

    template<class _Ty2>
    weak_ptr& operator=(shared_ptr<_Ty2>& _Right)
    {    // assign from _Right
        this->_Resetw(_Right);
        return (*this);
    }

    void reset()
    {    // release resource, convert to null weak_ptr object
        this->_Resetw();
    }

    void swap(weak_ptr& _Other)
    {    // swap pointers
        this->_Swap(_Other);
    }

    bool expired() const
    {    // return true if resource no longer exists
        return (this->_Expired());
    }

    shared_ptr<_Ty> lock() const
    {    // convert to shared_ptr
        return (shared_ptr<_Elem>(*this, false));
    }
};
```

​    weak_ptr可以观测被销毁的指针，就直接为NULL就好。不会报错的。

##### 5、auto_ptr

​		主要是为了解决“**有异常抛出时发生内存泄漏**”的问题 。因为发生异常而无法正常释放内存。auto_ptr有拷贝语义，拷贝后源对象变得无效，这可能引发很严重的问题；而unique_ptr则无拷贝语义，但提供了移动语义，这样的错误不再可能发生，因为很明显必须使用std::move()进行转移。auto_ptr不支持拷贝和赋值操作，不能用在STL标准容器中。STL容器中的元素经常要支持拷贝、赋值操作，在这过程中auto_ptr会传递所有权，所以不能在STL中使用。

##### 6、unique_ptr

​		unique_ptr ：独占资源所有权指针

​		unique_ptr采用的是独享所有权语义，一个非空的unique_ptr总是拥有它所指向的资源。转移一个unique_ptr将会把所有权全部从源指针转移给目标指针(move移动)，源指针被置空；所以unique_ptr不支持普通的拷贝和赋值操作，不能用在STL标准容器中；局部变量的返回值除外（因为编译器知道要返回的对象将要被销毁）；如果你拷贝一个unique_ptr，那么拷贝结束后，这两个unique_ptr都会指向相同的资源，造成在结束时对同一内存指针多次释放而导致程序崩溃。

简单实现如下：

```c++
template<typename T>
class UniquePtr {
// ...
private:
    T *ptr;
};
//构造函数
UniquePtr(T *ptr = nullptr) : ptr(ptr) {}
//析构
~UniquePtr() {
    if (ptr) {
        delete ptr;
        ptr = nullptr;
    }
}
//禁用拷贝构造和赋值运算符
//由于UniquePtr对象托管的指针是独享的，
//拷贝构造和赋值操作会有歧义，因此使用如下方式禁用。
UniquePtr(const UniquePtr &p) = delete;//=delete表示禁止生成默认的构造函数
UniquePtr &operator=(const UniquePtr &p) = delete;
//只移动构造函数
UniquePtr(UniquePtr &&p) noexcept: ptr(p.ptr) {
    p.ptr = nullptr;
}

```



##### 7、智能指针的设计和实现

​      需要一个计数器与类指向的对象相关联，需要跟踪该类有多少个对象共享同一指针。每次创建类的新对象是，初始化指针并且将引用计数置为1，当对象作为另一对象的副本而创建时，拷贝构造函数拷贝指针并增加对应的引用计数。对一个对象进行赋值时，赋值操作需要将左边的对象引用计数-1(减为0的时候，就会删除对象)，并且增加右操作数所指的对象的引用。调用析构函数时，构造函数减少引用计数。

##### 8、手写智能指针需要实现的函数

​     智能指针是一个数据类型，一般用模板实现，模拟指针行为的同时还提供自动垃圾回收机制。它会自动记录SmartPointer<T*>对象的引用计数，一旦T类型对象的引用计数为0，就释放该对象。除了指针对象外，我们还需要一个引用计数的指针设定对象的值，并将引用计数计为1，需要一个构造函数。新增对象还需要一个构造函数，析构函数负责引用计数减少和释放内存。通过覆写赋值运算符，才能将一个旧的智能指针赋值给另一个指针，同时旧的引用计数减1，新的引用计数加1。同时还需要：一个构造函数、拷贝构造函数、复制构造函数、析构函数、移动函数；

##### 9、share_ptr底层实现

share_ptr的简单实现

```c++
#include <iostream>
using namespace std;
template <typename T>
class myshared_ptr
{
public:
	myshared_ptr(T*value) //:ptr(value), count(new int(1))
	{
		ptr = value;
		count = new int(1);
	}
	myshared_ptr(const myshared_ptr&m)
	{
		ptr = m.ptr;
		count = m.count;
		(*count)++;
	}
	myshared_ptr&operator=(const myshared_ptr&m)
	{
		if (this != &m)
		{
			ptr = m.ptr;
			count = m.count;
			(*count)++;
		}
		return *this;
	}
	T&operator->()
	{
		return this->ptr;
	}
	~myshared_ptr()
	{
		(*count)--;
		if (*(this->count) == 0)
		{
			delete ptr;
			delete count;
			//ptr = nullptr;
			//count = nullptr;
			cout << "释放内存空间" << endl;
		}
	}
public:
	T*ptr;
	int*count;
};

```

​		最高层的shared_ptr就是用户直接使用的类，它提供shared_ptr的构造、复制、重置(reset函数）、解引用、比较、隐式转换为bool等功能。它包含一个指向被管理对象的指针，用来实现解引用操作，并且组合了一个shared_count对象，用来操作引用计数。

​		但shared_count类还不是引用计数类，它只是包含了一个指向引用计数类sp_counted_base的指针，功能上是对sp_counted_base操作的封装。shared_count对象的创建、复制和删除等操作，包含着对sp_counted_base的增加和减小引用计数的操作。

​		最后sp_counted_base类才保存了引用计数，并且对引用计数字段提供无锁保护。它也包含了一个指向被管理对象的指针，是用来删除被管理的对象的。sp_counted_base有三个派生类，分别处理用户指定Deleter和Allocator的情况：

1. sp_counted_impl_p：用户没有指定Deleter和Allocator

2. sp_counted_impl_pd：用户指定了Deleter，没有指定Allocator

3. sp_counted_impl_pda：用户指定了Deleter和 Allocator

​		创建指针P的第一个shared_ptr对象的时候，子对象shared_count同时被建立， shared_count根据用户提供的参数选择创建一个特定的sp_counted_base派生类对象X。之后创建的所有管理P的shared_ptr对象都指向了这个独一无二的X。

​		然后再看虚线框内的weak_ptr就清楚了。weak_ptr和shared_ptr基本上类似，只不过weak_ptr包含的是weak_count子对象，但weak_count和shared_count也都指向了sp_counted_base。

```c++
shared_ptr<SomeObject> SP1(new SomeObject());
shared_ptr<SomeObject> SP2=SP1;
weak_ptr<SomeObject> WP1=SP1;
```

​		原文链接：https://blog.csdn.net/jiangfuqiang/article/details/8292906

##### 10、shared_ptr是否是线程安全的？

###### 1）boost官方文档

​		boost官方文档对shared_ptr线程安全性的正式表述是：shared_ptr对象提供与内置类型相同级别的线程安全性。

1. 同一个shared_ptr对象可以被多线程同时读取；
2. 不同的shared_ptr对象可以被多线程同时修改（即使这些shared_ptr对象管理着同一个对象的指针）
3.  同一个shared_ptr对象不能被多线程直接修改，但可以通过原子函数完成。

​		第一种情况是对对象的**并发读**，是线程**安全**的；第二种情况下，如果两个shared_ptr对象A和B管理的是不同对象的指针，则这两个对象完全不相关，支持并发写也容易理解。但如果A和B管理的是同一个对象P的指针，则A和B需要维护一块共享的内存区域，该区域记录P指针当前的引用计数。对A和B的**并发写**必然涉及对该**引用计数内存区的并发修改**，需要做额外的工作。

​		原文链接：https://blog.csdn.net/jiangfuqiang/article/details/8292906

###### 2）知乎

​		应该说控制块是线程安全的，指针拷贝不是，c++20有原子智能指针。

​		线程是否安全是指的对象在内存本身被多个线程更改是否安全！所有要看对象在内存中的结构，会不会被自身的函数成员在不同线程下造成错误修改。

​		shared_ptr只有两个指针数据成员，sizeof(std::shared_ptr)=16，一个是Ptr裸指针在x64上是8字节，另外一个是_Ref_count_base对象的指针是8字节。两个加起来16字节。该对象有两个成员_Uses和_Weaks。这个对象是在std::make_shared时候创建的，可以在源码中查看到。所以算是考虑shared_ptr和_Ref_count_base两个对象在内存中是否线程安全。

​		其中__Ptr是不会被改写的，__Uses和__Weaks都是**原子操作**！所以shared_ptr是线程安全的。但是你解引用指向的对象的线程安全，是不能保证的！

​		原文链接：https://www.zhihu.com/question/56836057/answer/1472597928


#### 3.3、原子操作的底层原理？

​		**处理器使用基于对缓存加锁或总线加锁的方式来实现多处理器之间的原子操作。**首先处理器会自动保证基本的内存操作的原子性。处理器保证从系统内存中读取或者写入一个字节是原子的，意思是当一个处理器读取一个字节时，其他处理器不能访问这个字节的内存地址。Pentium 6和最新的处理器能自动保证单处理器对同一个缓存行里进行16/32/64位的操作是原子的，但是复杂的内存操作处理器是不能自动保证其原子性的，比如跨总线宽度、跨多个缓存行和跨页表的访问。但是，处理器提供总线锁定和缓存锁定两个机制来保证复杂内存操作的原子性。

##### 1、使用总线锁保证原子性

​		第一个机制是通过总线锁保证原子性。如果多个处理器同时对共享变量进行读改写操作（i++就是经典的读改写操作），那么共享变量就会被多个处理器同时进行操作，这样读改写操作就不是原子的，操作完之后共享变量的值会和期望的不一致。举个例子，如果i=1，我们进行两次i++操作，我们期望的结果是3，但是有可能结果是2，如图下图所示。

| CPU1  | CPU2  |
| ----- | ----- |
| i = 1 | i = 1 |
| i + 1 | i + 1 |
| i = 2 | i = 2 |

​		原因可能是多个处理器同时从各自的缓存中读取变量i，分别进行加1操作，然后分别写入系统内存中。那么，想要保证读改写共享变量的操作是原子的，就必须保证CPU1读改写共享变量的时候，CPU2不能操作缓存了该共享变量内存地址的缓存。处理器使用总线锁就是来解决这个问题的。**所谓总线锁就是使用处理器提供的一个LOCK＃信号，当一个处理器在总线上输出此信号时，其他处理器的请求将被阻塞住，那么该处理器可以独占共享内存。**

##### 2、使用缓存锁保证原子性

​		第二个机制是通过缓存锁定来保证原子性。在同一时刻，我们只需保证对某个内存地址的操作是原子性即可，但**总线锁定把CPU和内存之间的通信锁住了**，这使得锁定期间，其他处理器不能操作其他内存地址的数据，所以总线锁定的开销比较大，目前处理器在某些场合下使用缓存锁定代替总线锁定来进行优化。

​		频繁使用的内存会缓存在处理器的L1、L2和L3高速缓存里，那么原子操作就可以直接在处理器内部缓存中进行，并不需要声明总线锁，在Pentium 6和目前的处理器中可以使用“缓存锁定”的方式来实现复杂的原子性。

​		**相比总线锁，缓存锁即降低了锁的力度。核心机制是基于缓存一致性协议来实现的。常见的是MESI协议。**

​      所谓“缓存锁定”是指内存区域如果被缓存在处理器的缓存行中，并且在Lock操作期间被锁定，那么当它执行锁操作回写到内存时，处理器不在总线上声言LOCK＃信号，而是修改内部的内存地址，并允许它的缓存一致性机制来保证操作的原子性，因为**缓存一致性机制会阻止同时修改由两个以上处理器缓存的内存区域数据，当其他处理器回写已被锁定的缓存行的数据时，会使缓存行无效，在如上图所示的例子中，当CPU1修改缓存行中的时使用了缓存锁定，那么CPU2就不能使用同时缓存 i 的缓存行**。



原文链接：https://blog.csdn.net/f110300641/article/details/83510081

##### 3、处理器不会使用缓存锁定的情况

- 第一种情况是：当操作的数据不能被缓存在处理器内部，或操作的数据跨多个缓存行（cache line）时，则处理器会调用总线锁定。
- 第二种情况是：有些处理器不支持缓存锁定。对于Intel 486和Pentium处理器，就算锁定的内存区域在处理器的缓存行中也会调用总线锁定。



#### 3.4、lambda表达式

​		1、利用lambda表达式可以编写内嵌的匿名函数，用以替换独立函数或者函数对象；

​		2、每当你定义一个lambda表达式后，编译器会自动生成一个匿名类（这个类当然重载了()运算符），我们称为闭包类型（closure type）。那么在运行时，这个lambda表达式就会返回一个匿名的闭包实例，其实一个右值。所以，我们上面的lambda表达式的结果就是一个个闭包。闭包的一个强大之处是其可以通过传值或者引用的方式捕捉其封装作用域内的变量，前面的方括号就是用来定义捕捉模式以及变量，我们又将其称为lambda捕捉块。

​		3、lambda表达式的语法定义如下：

```c++
[capture] （parameters） mutable ->return-type {statement};
```

​		4、lambda必须使用尾置返回来指定返回类型，可以忽略参数列表和返回值，但必须永远包含捕获列表和函数体；

##### 1、捕获列表说明

​		capture是捕获列表；params是参数表；opt是函数选项（可以是mutable说明lambda表达式体内的代码可以修改被捕获的变量、exception说明lambda表达式是否抛出异常以及何种异常、attribute声明属性）；ret是返回值类型;body是函数体

​		捕获列表：lambda表达式的捕获列表精细控制了lambda表达式能够访问的外部变量，以及如何访问这些变量。

- [] 不捕获任何变量。
- [&] 捕获外部作用域中所有变量，并作为引用在函数体中使用（按引用捕获）。
- [=] 捕获外部作用域中所有变量，并作为副本在函数体中使用(按值捕获)。注意值捕获的**前提**是变量可以**拷贝**，且**被捕获的变量在lambda表达式被创建时拷贝，而非调用时才拷贝。**
- [=,&foo] 按值捕获外部作用域中所有变量，并按引用捕获foo变量。
- [bar] 按值捕获bar变量，同时不捕获其他变量。
- [this] 捕获当前类中的this指针，让lambda表达式拥有和当前类成员函数同样的访问权限。如果已经使用了&或者=，就默认添加此选项。**捕获this的目的是可以在lamda中使用当前类的成员函数和成员变量**。

##### 2、注意事项

```c++
class A
{
 public:
     int i_ = 0;

     void func(int x,int y){
         auto x1 = [] { return i_; };                   //error,没有捕获外部变量
         auto x2 = [=] { return i_ + x + y; };          //OK
         auto x3 = [&] { return i_ + x + y; };          //OK
         auto x4 = [this] { return i_; };               //OK
         auto x5 = [this] { return i_ + x + y; };       //error,没有捕获x,y
         auto x6 = [this, x, y] { return i_ + x + y; }; //OK
         auto x7 = [this] { return i_++; };             //OK
};

int a=0 , b=1;
auto f1 = [] { return a; };                         //error,没有捕获外部变量    
auto f2 = [&] { return a++ };                       //OK
auto f3 = [=] { return a; };                        //OK
auto f4 = [=] {return a++; };                       //error,a是以复制方式捕获的，无法修改
auto f5 = [a] { return a+b; };                      //error,没有捕获变量b
auto f6 = [a, &b] { return a + (b++); };            //OK
auto f7 = [=, &b] { return a + (b++); };            //OK
```

​		注意f4，虽然按值捕获的变量值均复制一份存储在lambda表达式变量中，修改他们也并不会真正影响到外部，但我们却仍然无法修改它们。如果希望**去修改按值捕获的外部变量**，需要显示指明lambda表达式为**mutable**。被mutable修饰的lambda表达式就算没有参数也要写明参数列表。

​		原因：lambda表达式可以说是就地定义仿函数闭包的“语法糖”。它的捕获列表捕获的任何外部变量，最终会变为**闭包类型**的成员变量。按照C++标准，**lambda表达式的operator()默认是const的**，一个const成员函数是无法修改成员变量的值的。而mutable的作用，就在于取消operator()的const。

```c++
int a = 0;
auto f1 = [=] { return a++; };                //error
auto f2 = [=] () mutable { return a++; };     //OK
```

##### 3、lambda原理

​		lambda表达式的大致原理：每当你定义一个lambda表达式后，编译器会**自动生成一个匿名类**（这个类重载了**()**运算符），我们称为**闭包类型**（closure type）。那么在运行时，这个lambda表达式就会返回一个匿名的闭包实例，是一个**右值**。所以，我们上面的lambda表达式的结果就是一个个闭包。对于复制传值捕捉方式，类中会相应添加对应类型的非静态数据成员。在运行时，会用复制的值初始化这些成员变量，从而生成闭包。对于引用捕获方式，无论是否标记mutable，都可以在lambda表达式中修改捕获的值。至于闭包类中是否有对应成员，C++标准中给出的答案是：不清楚的，与具体实现有关。

##### 4、lambda不能被赋值

```c++
auto a = [] { cout << "A" << endl; };
auto b = [] { cout << "B" << endl; };

a = b;   // 非法，lambda无法赋值
auto c = a;   // 合法，生成一个副本
```

​		闭包类型禁用了赋值操作符，但是没有禁用复制构造函数，所以你仍然可以用一个lambda表达式去初始化另外一个lambda表达式而产生副本。

​		在多种捕获方式中，最好不要使用[=]和[&]默认捕获所有变量。

​		默认引用捕获所有变量，你有很大可能会出现悬挂引用（Dangling references），因为引用捕获不会延长引用的变量的生命周期.

​		原文链接：https://blog.csdn.net/jiange_zh/article/details/79356417

#### 3.5、auto、decltype、decltype(auto)

##### 1、auto

​		C++11新标准引入了auto类型说明符，用它就能让编译器替我们去分析表达式所属的类型。和原来那些只对应某种特定的类型说明符(例如 int)不同，**auto 让编译器通过初始值来进行类型推演。从而获得定义变量的类型，所以说auto定义的变量必须有初始值。**

##### 2、decltype

​		decltype 关键字是为了解决 auto 关键字只能对变量进行类型推导的缺陷而出现的。它的用法和 sizeof 很相似。		

​		有的时候我们还会遇到这种情况，**我们希望从表达式中推断出要定义变量的类型，但却不想用表达式的值去初始化变量。**还有可能是函数的返回类型为某表达式的值类型。在这些时候auto显得就无力了，所以C++11又引入了第二种类型说明符decltype，**它的作用是选择并返回操作数的数据类型。在此过程中，编译器只是分析表达式并得到它的类型，却不进行实际的计算表达式的值。**

##### 3、decltype（auto）

​		decltype(auto)是C++14新增的类型指示符，可以用来声明变量以及指示函数返回类型。在使用时，会将“=”号左边的表达式替换掉auto，再根据decltype的语法规则来确定类型。



#### 3.6、初始化列表

​		C++11 提供了统一的语法来初始化任意的对象。C++11 还把初始化列表的概念绑定到了类型上，并将其称之为 std::initializer_list，允许构造函数或其他函数像参数一样使用初始化列表，这就为类对象的初始化与普通数组和 POD 的初始化方法提供了统一的桥梁。

#### 3.7、左值和右值

##### 1、左值、右值

###### 1）左值

​		左值往往有对应的**内存地址**，右值就是一个**数据**值。就是左值的生命周期不止于这句话，右值用完这句话就挂了。

​		左值：表示的是可以**获取地址的表达式**，它能出现在赋值语句的左边，对该表达式进行赋值。但是修饰符const的出现使得可以声明如下的标识符，它可以取得地址，但是没办法对其进行赋值。

```c++
const int& a = 10;
```

###### 2）右值

​		右值：表示无法获取地址的对象，有常量值、函数返回值、lambda表达式等。无法获取地址，但不表示其不可改变，当定义了右值的右值引用时就可以更改右值。

###### 3）总结

​		在C++11之前，只有左值才可以被引用，C++11后右值也可以被引用（&&）。右值引用的意义就是为临时变量续命，就是为右值续命，因为以前右值在表达式结束后就消亡了，如果想继续使用右值，就会动用昂贵的拷贝函数。右值引用是用来支持**转移语义**的，转移语义可以将资源从一个对象转移到另一个对象，这样的好处就是减少不必要的临时对象的创建、拷贝及销毁，能够大幅度提高C++应用程序的性能，就是通过转移语义，临时对象中的资源能够转移到其他对象中。

​		std::move，将左值强行转化为右值使用。执行一个无条件的转化到右值。它本身并不移动任何东西。

​		std::forword 完美转发，将一组实参“完美”地传递给形参，完美指的是参数的const属性与左右值属性不变。就是说，函数模板在向其他函数传递自身形参时，如果相应实参是左值，它就应该被转发为左值；如果相应实参是右值，它就应该被转发为右值。

​		总的来说， C++11正是通过引入右值引用来优化性能，具体来说是通过移动语义来避免无谓拷贝的问题，通过move语义来将临时生成的左值中的资源无代价的转移到另外一个对象中去，通过完美转发来解决不能按照参数实际类型来转发的问题（同时，完美转发获得的一个好处是可以实现移动语义）。

##### 2、左值引用、右值引用

###### 1）左值引用

​		左值引用：传统的C++中引用被称为左值引用。

​		左值引用就是对一个左值进行引用的类型。右值引用就是对一个右值进行引用的类型，事实上，由于右值通常不具有名字，我们也只能通过引用的方式找到它的存在。右值引用和左值引用都是属于引用类型。无论是声明一个左值引用还是右值引用，都必须立即进行初始化。而其原因可以理解为是引用类型本身自己并不拥有所绑定对象的内存，只是该对象的一个别名。左值引用是具名变量值的别名，而右值引用则是不具名（匿名）变量的别名。左值引用通常也不能绑定到右值，但常量左值引用是个“万能”的引用类型。它可以接受非常量左值、常量左值、右值对其进行初始化。不过常量左值所引用的右值在它的“余生”中只能是只读的。相对地，非常量左值只能接受非常量左值对其进行初始化。

###### 2）右值引用

​		右值引用：C++11中增加了右值引用，右值引用关联到右值时，右值被存储到特定位置，右值引用指向该特定位置，也就是说，右值虽然无法获取地址，但是右值引用是可以获取地址的，该地址表示临时对象的存储位置。

​		右值引用用通常不能绑定到任何的左值，要想绑定一个左值到右值引用，通常需要std::**move()**将左值强制转换为右值。

###### 3）右值引用特点

- 通过右值引用的声明，右值又“重获新生”，其生命周期与右值引用类型变量的生命周期一样长，只要该变量还活着，该右值临时变量将会一直存活下去；
- 右值引用独立于左值和右值，即右值引用类型的变量可能是左值也可能是右值；
- T&& t 在发生自动类型推断的时候，它是左值还是右值取决于它的初始化。

###### 4）右值引用的作用

-   实现移动语义；
-   给中间变量临时变量取别名；
-   实现完美转发

###### 5）使用场景

1、返回值

返回值一般是右值，一般情况返回对象时，必须创建一个临时对象，临时对象创建好之后，tmp就会被销毁，最后使用返回的临时变量去构造新对象ret。构造好新对象ret之后，临时对象也被销毁了。 其**实临时对象tmp和ret的空间大小一样，内容也一样**。

![image-20220425222405656](F:/%E6%88%91%E7%9A%84%E6%96%87%E4%BB%B6_%E5%BC%A0%E5%85%B5/%E6%89%BE%E5%B7%A5%E4%BD%9C/%E5%9B%BE%E7%89%87/image-20220425222405656.png)

2、函数参数

![image-20220425222505333](F:/%E6%88%91%E7%9A%84%E6%96%87%E4%BB%B6_%E5%BC%A0%E5%85%B5/%E6%89%BE%E5%B7%A5%E4%BD%9C/image-20220425222505333.png)

有了C++11之后，就可以根据你传参是左值还是右值调用合适的移动构造函数。上图的例子就是vector中push_back(string),根据string对象是左值还是右值，调用push_back()的重载函数（emplace_back是这样实现）。移动构造减少一次拷贝的消耗。STL中vector的emplcae_back 接收一个右值引用，调用其移动构造函数，将对象移动到容器中，而之前的push_back 是调用一次对象的拷贝构造函数， 容器中存储的是拷贝后的副本。

#### 3.8、move函数。

- 我们用对象a初始化对象b，后对象a我们就不在使用了，但是对象a的空间还在呀（在析构之前），既然拷贝构造函数，实际上就是把a对象的内容复制一份到b中，那么为什么我们不能直接使用a的空间呢？这样就避免了新的空间的分配，大大降低了构造的成本。这就是移动构造函数设计的初衷；
- 拷贝构造函数中，对于指针，我们一定要采用深层复制，而移动构造函数中，对于指针，我们采用浅层复制。浅层复制之所以危险，是因为两个指针共同指向一片内存空间，若第一个指针将其释放，另一个指针的指向就不合法了。所以我们只要避免第一个指针释放空间就可以了。避免的方法就是将第一个指针（比如a->value）置为NULL，这样在调用析构函数的时候，由于有判断是否为NULL的语句，所以析构a的时候并不会回收a->value指向的空间；
- 移动构造函数的参数和拷贝构造函数不同，拷贝构造函数的参数是一个左值引用，但是移动构造函数的初值是一个右值引用。意味着，移动构造函数的参数是一个右值或者将亡值的引用。也就是说，只用用一个右值，或者将亡值初始化另一个对象的时候，才会调用移动构造函数。而那个**move语句**，就是**将一个左值变成一个将亡值**。

#### 3.9、完美转发与万能引用

##### 1、完美转发

##### 2、万能引用

​		T&&，T是被推导的类型，那这个变量或者参数就是一个万能引用

#### 3.10、nullptr

​		在C语言中，NULL被定义为：#define NULL  ((void*)0)，就是说NULL实际上时一个空指针，在进行赋值给类似于int或者char型的指针时，会发生隐式类型转换，把void转换成相应类型的指针。

​      在C++中，C++时强类型语言，void*不能隐式转换成其他类型的指针，NULL实际上是0，编译器提供的头文件做了相应的处理，C++中NULL是0，但是在代码中用NULL替代0表示空指针在函数重载时会发生二义性（就是说用NULL输入到函数中，进行重载，会选择Int这个形参，跟我们想要使用的空指针不一样），为了解决这个二义性，采用nullptr来代表空指针。



### 4、虚函数相关问题

#### 4.1、面向对象三大特性

​		   面向对象的三大特性：封装、继承、多态。具有相同性质的对象，可以抽象为类。封装就是指将属性（变量）和行为（函数）作为一个整体，表现一个对象。继承，是指类与类之间的特殊关系，下级成员除了拥有上级成员的共性，还有自己的特点，减少重复的代码。多态，就是指多种形态，主要分为静态多态和动态多态，静态多态就是指重载（函数重载和运算符重载）也就是编译多态，动态多态是指继承关系的派生类、子类重写父类中的虚函数实现的运行多态。

##### 1、封装

###### 1）封装的概念

​		**封装就是把数据和代码捆绑在一起，避免外界干扰和不确定性访问，也就是客观事物封装成抽象的类**，并且类可以把自己的数据和方法只让可信的类或者对象操作，对不可信的进行信息隐藏。例如：将公共的数据或方法使用public修饰，而不希望被访问的数据或方法采用private修饰。

###### 2）实现方式

- 数据封装：保护数据成员，不让类外的程序直接访问或修改，只能通过提供的公共的接口访问；
- 方法封装：方法的细节是对用户隐藏的，只要接口不变，内容的修改不会影响到外部的调用者；
- 对象的方法可以接收对象外的消息；
- 对象外面不能直接访问对象的属性，只能通过和该属性对应的方法访问；
- 当对象含有完整的属性和与之对应的方法时称之为封装。

##### 2、继承

###### 1）继承的概念

​		**继承就是让某种类型对象获得另一个类型对象的属性和方法。**

​		继承方式一共有三种：公共继承、保护继承、私有继承（公共就是公共访问，保护就是子类访问，私有就是自己才能访问）C++中默认继承方式是private。

​		私有权限，子类永远不可以访问；保护继承，则子类都是保护属性；公共继承，则子类属性不变，除了不可访问私有。先私有继承之后，再进行公共继承，依然不可以访问，因为第一次私有继承之后所有成员属性都变为私有。

- public：该数据成员、成员函数是对所有用户开放的，所有用户都可以进行调用；
- protected:对于子女、朋友来说，就是public的，可以自由使用，没有任何限制，而对于其他的外部class，protected就变成private；
- private:私有，除了class自己之外，其他都不可以直接使用；

###### 2）常见的继承方式

- 实现继承：指使用基类的属性和方法而无需额外编码的能力
- 接口继承：指仅使用属性和方法的名称、但是子类必须提供实现的能力
- 可视继承：指子窗体（类）使用基窗体（类）的外观和实现代码的能力（C++里好像不怎么用）

##### 3、多态

​		多态：同一事物表现出不同事物的能力，即向不同对象发送同一消息，不同的对象在接收时会产生不同的行为**（重载实现编译时多态，虚函数实现运行时多态）**。 多态一般分为：静态多态、动态多态，还有一个模板template。

- 静态多态通过**重载**实现，函数重载（重载参数个数不同，重载参数类型不同或者参数类型顺序不同），运算符重载（operator)。在**编译**阶段就可以确定函数入口地址。
- 动态多态通过**虚函数**实现。地址晚绑定，是在**运行**阶段确定的。
  - 在基类的函数前面+virtual，在派生类中重写该函数，运行时将会根据所指对象的实际类型来调用相应函数。派生类--派生类，基类--基类。虚函数具有虚函数表和虚函数指针：
    - 虚函数表：类中含有virtual关键字修饰的方法，编译器会自动生成虚函数表。
    - 虚表指针：在含有虚函数的类实例化对象时，对象地址的前四个字节存储的指向虚函数表的指针。

###### 1）多态的底层原理

- 编译器在发现基类中有虚函数时，会自动为每个含有虚函数的类生成一份虚表，该表是一个一维数组，虚表里保存了虚函数的入口地址；
- 编译器会在每个对象的前四个字节中保存一个虚表指针（vptr）,指向对象所属类的虚表。在构造时，根据对象类型去初始化虚表指针vptr，从而让vptr指向正确的虚表，从而在调用虚函数时，能找到正确的函数； 
- 在派生类定义对象时，程序运行会自动调用构造函数，在构造函数中创建虚表并对虚表初始化。在构造子类对象时，先调用父类的构造函数，此时，编译器只看到父类，并为父类对象初始化虚表指针，令其指向父类的虚表；当调用子类的构造函数时，为子类对象初始化虚表指针，令其指向子类的虚表；
- 当派生类对基类的虚函数没有重写时，派生类的虚表指针指向基类的虚表；当派生类对基类的虚函数重写时，派生类的虚表指针指向自身的虚表；当派生类中有自己的虚函数时，在自己的虚表中将此虚函数地址添加在后面。

###### 2）静态绑定与动态绑定

- 静态类型：对象在声明时采用的类型，在编译期既已确定

- 动态类型：通常是指一个指针或引用目前所指对象的类型，是在运行期决定的；

- 静态绑定：绑定的是静态类型，所对应的函数或属性依赖于对象的静态类型，发生在编译期；

- 动态绑定：绑定的是动态类型，所对应的函数或属性依赖于对象的动态类型，发生在运行期；

  **非虚函数一般都是静态绑定，而虚函数都是动态绑定**。

###### 3）区别

- 静态绑定发生在编译期，动态绑定发生在运行期；
- 对象的动态类型可以更改，但是静态类型无法更改；
- 要想实现动态，必须使用动态绑定；
- 在继承体系中只有虚函数使用的是动态绑定，其他的全部是静态绑定；

###### 4）建议

​		绝对不要重新定义继承而来的非虚(non-virtual)函数（《Effective C++ 第三版》条款36），因为这样导致函数调用由对象声明时的静态类型确定了，而和对象本身脱离了关系，没有多态，也这将给程序留下不可预知的隐患和莫名其妙的BUG；另外，在动态绑定也即在virtual函数中，要注意默认参数的使用。当缺省参数和virtual函数一起使用的时候一定要谨慎，不然出了问题怕是很难排查。

###### 5）引用能否实现动态绑定?

​		可以。引用在创建的时候**必须初始化**，在访问虚函数时，编译器会根据其所绑定的对象类型决定要调用哪个函数。注意只能调用虚函数。

###### 6）A类有B类的对象，B类有A类对象怎么释放

​		主函数中只实例化A a。会发现先调用B的构造函数，然后构造A的构造函数，之后再调用A的析构函数，最后是B的析构函数。（还是根据实例化对象来的，因为实例化了A，A中有B，所以要先构造B才行，释放了A，那B也没用了，所以B后析构）



#### **4.2、**虚函数表

##### 1、实现

​		假设有一个基类ClassA，一个继承了该基类的派生类ClassB，并且基类中有虚函数，派生类实现了基类的虚函数。
我们在代码中运用多态这个特性时，通常以两种方式起手：

- ClassA *a = new ClassB();
- ClassB b; ClassA *a = &b;

以上两种方式都是用基类指针去指向一个派生类实例，区别在于第1个用了new关键字而分配在堆上，第2个分配在栈上。

![这里写图片描述](https://img-blog.csdn.net/20180820143644168?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM2MzU5MDIy/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)

​		以左图为例，ClassA *a是一个栈上的指针。该指针指向一个在堆上实例化的子类对象。基类如果存在虚函数，那么在子类对象中，除了成员函数与成员变量外，编译器会自动生成一个指向**该类的虚函数表(这里是类ClassB)**的指针，叫作虚函数表指针。通过虚函数表指针，父类指针即可调用该虚函数表中所有的虚函数。

##### 2、类的虚函数表与类实例的虚函数指针

​		首先不考虑继承的情况。如果一个类中有虚函数，那么该类就有一个虚函数表。
​		这个虚函数表是属于类的，所有该类的实例化对象中都会有一个虚函数表指针去指向该类的虚函数表。
​		从第一部分的图中我们也能看到，一个类的实例要么在堆上，要么在栈上。**也就是说一个类可以有很多很多个实例。但是！一个类只能有一个虚函数表**。在编译时，一个类的虚函数表就确定了，这也是为什么它放在了只读数据段中。

![这里写图片描述](https://img-blog.csdn.net/20180821095203702?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM2MzU5MDIy/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)

​		原文链接：https://blog.csdn.net/qq_36359022/article/details/81870219

###### 1）虚函数表指针的创建时机

​		虚函数指针跟着对象走，所以对象什么时候创建出来，vptr就什么时候创建出来，就是**运行**的时候才决定。当程序在编译期间，编译器会为构造函数中增加为vptr赋值的代码(这是编译器的行为)，当程序在运行时，遇到创建对象的代码，执行对象的构造函数，那么这个构造函数里有为这个对象的vptr赋值的语句。

###### 2）虚函数表创建的时机

​		虚函数表创建时机是在**编译期**间。编译期间编译器就为每个类确定好了对应的虚函数表里的内容。所以在程序运行时，编译器会把虚函数表的首地址赋值给虚函数表指针，所以，这个虚函数表指针就有值了。



##### 3、虚继承

​		由于C++支持多继承，除了public、protected和private三种继承方式外，还支持虚拟（virtual）继承。

```c++
class A{}
class B : virtual public A{};
class C : virtual public A{};
class D : public B, public C{};
int main()
{
    cout << "sizeof(A)：" << sizeof A <<endl; // 1，空对象，只有一个占位
    cout << "sizeof(B)：" << sizeof B <<endl; // 4，一个bptr指针，省去占位,不需要对齐
    cout << "sizeof(C)：" << sizeof C <<endl; // 4，一个bptr指针，省去占位,不需要对齐
    cout << "sizeof(D)：" << sizeof D <<endl; // 8，两个bptr，省去占位,不需要对齐
}
```

​		上述代码所体现的关系是，B和C虚拟继承A，D又公有继承B和C，这种方式是一种**菱形继承或者钻石继承**，可以用如下图来表示：

![image-20210914160237047](总结面试题.assets/image-20210914160237047.png)

​		**虚拟继承的情况下，无论基类被继承多少次，只会存在一个实体。**虚拟继承基类的子类中，子类会增加某种形式的指针，或者指向虚基类子对象，或者指向一个相关的表格；表格中存放的不是虚基类子对象的地址，就是其偏移量，此类指针被称为bptr，如上图所示。如果既存在vptr又存在bptr，某些编译器会将其优化，合并为一个指针。

##### 4、多继承的优缺点

- C++允许为一个派生类指定多个基类，这样的继承结构被称做多重继承。
-  多重继承的优点很明显，就是对象可以调用多个基类中的接口；
- 如果派生类所继承的多个基类有相同的基类，而派生类对象需要调用这个祖先类的接口方法，就会容易出现二义性
- 加上全局符确定调用哪一份拷贝。比如pa.Author::eat()调用属于Author的拷贝。
- **使用虚拟继承，使得多重继承类Programmer_Author只拥有Person类的一份拷贝。**

##### 5、纯虚函数

​		包含纯虚函数的类称为抽象类。由于抽象类包含了没有定义的纯虚函数，所以不能定义抽象类的对象。

```c++
class <类名> { virtual <类型><函数名>(<参数表>)=0; … };
```

​		在许多情况下，在基类中不能对虚函数给出有意义的实现，而把它声明为纯虚函数，它的实现留给该基类的派生类去做。这就是纯虚函数的作用。 纯虚函数可以让类先具有一个操作名称，而没有操作内容，让派生类在继承时再去具体地给出定义。凡是含有纯虚函数的类叫做**抽象类**。这种**类不能声明对象，只是作为基类为派生类服务**。除非在派生类中完全实现基类中所有的的纯虚函数，否则，派生类也变成了抽象类，不能实例化对象。

###### 纯虚函数引入原因

- 为了方便使用多态特性，我们常常需要在基类中定义虚拟函数。
- 在很多情况下，基类本身生成对象是不合情理的。例如，动物作为一个基类可以派生出老虎、孔雀等子类，但动物本身生成对象明显不合常理。

​		为了解决上述问题，引入了纯虚函数的概念，将函数定义为纯虚函数（方法：virtual ReturnType Function()= 0;）。若要使派生类为非抽象类，则编译器要求在派生类中，必须**对纯虚函数予以重载以实现多态性**。同时含有纯虚函数的类称为抽象类，它不能生成对象。这样就很好地解决了上述两个问题。例如，绘画程序中，shape作为一个基类可以派生出圆形、矩形、正方形、梯形等， 如果我要求面积总和的话，那么会可以使用一个 shape * 的数组，只要依次调用派生类的area()函数了。如果不用接口就没法定义成数组，因为既可以是circle ,也可以是square ,而且以后还可能加上rectangle，等等. 

##### 6、抽象类

​		抽象类是一种特殊的类，它是为了抽象和设计的目的为建立的，它处于继承层次结构的较上层。

###### 1）抽象类的定义

​		称带有纯虚函数的类为抽象类。

###### 2）抽象类的作用

​		抽象类的主要作用是将有关的操作作为结果接口组织在一个继承层次结构中，由它来为派生类提供一个公共的根，派生类将具体实现在其基类中作为**接口**的操作。所以派生类实际上刻画了一组子类的操作接口的通用语义，这些语义也传给子类，子类可以具体实现这些语义，也可以再将这些语义传给自己的子类。

###### 3）抽象类的使用

​		抽象类只能作为基类来使用，其纯虚函数的实现由派生类给出。如果派生类中没有重新定义纯虚函数，而只是继承基类的纯虚函数，则这个派生类仍然还是一个抽象类。如果派生类中给出了基类纯虚函数的实现，则该派生类就不再是抽象类了，它是一个可以建立对象的具体的类。抽象类是不能定义对象的。一个纯虚函数不需要（但是可以）被定义。

##### 7、虚函数的代价

- 带有虚函数的类，每一个类会产生一个虚函数表，用来存储指向虚成员函数的指针，**增大类**；
- 带有虚函数的类的每一个对象，都会有有一个指向虚表的指针，会**增加对象的空间大小**；
- **不能再是内敛的函数**，因为内敛函数在编译阶段进行替代，而虚函数表示等待，在运行阶段才能确定到低是采用哪种函数，虚函数不能是内敛函数。

##### 8、哪些函数不能为虚函数？

- **构造函数**，构造函数初始化对象，派生类必须知道基类函数干了什么，才能进行构造；当有虚函数时，每一个类有一个虚表，每一个对象有一个虚表指针，虚表指针在构造函数中初始化；
- **内联函数**，内联函数表示在编译阶段进行函数体的替换操作，而虚函数意味着在运行期间进行类型确定，所以内联函数不能是虚函数；
- **静态函数**，静态函数不属于对象属于类，静态成员函数没有this指针，因此静态函数设置为虚函数没有任何意义。
- **友元函数**，友元函数不属于类的成员函数，不能被继承。对于没有继承特性的函数没有虚函数的说法。
- **普通函数**，普通函数不属于类的成员函数，不具有继承特性，因此普通函数没有虚函数。

##### 9、虚函数与纯虚函数的区别

- **虚函数是为了实现动态编联**产生的，目的是通过基类类型的指针指向不同对象时，自动调用相应的、和基类同名的函数（使用同一种调用形式，既能调用派生类又能调用基类的同名函数）。虚函数需要在基类中加上virtual修饰符修饰，因为virtual会被隐式继承，所以子类中相同函数都是虚函数。当一个成员函数被声明为虚函数之后，其派生类中同名函数自动成为虚函数，在派生类中重新定义此函数时要求函数名、返回值类型、参数个数和类型全部与基类函数相同。

- **纯虚函数只是相当于一个接口**名，但含有纯虚函数的类**不能够实例化**。纯虚函数首先是虚函数，其次它没有函数体，取而代之的是用“=0”。既然是虚函数，它的函数指针会被存在虚函数表中，由于纯虚函数并没有具体的函数体，因此它在虚函数表中的值就为0，而具有函数体的虚函数则是函数的具体地址。一个类中如果有纯虚函数的话，称其为抽象类。抽象类不能用于实例化对象，否则会报错。抽象类一般用于定义一些公有的方法。子类继承抽象类也必须实现其中的纯虚函数才能实例化对象。

##### 10、虚函数可能带来的安全问题？

- 父类指针调用子类函数，父类指针在析构的时候，不会调用子类中的析构函数，要是子类中有堆区属性，就会出现内存泄漏；
- 通过父类指针访问子类自己的虚函数。任何妄图使用父类指针调用子类中的未覆盖父类的成员函数的行为都会被编译器视为非法，但是，在运行时，我们可以通过指针的方式访问虚函数表来达到违法C++语言的行为；
- 访问non-public的虚函数。父类的虚函数是private或者是protected，这些非public的虚函数同样也会存在于虚函数表中，所以，我们同样可以使用访问虚函数表的方法来访问这些non-public的虚函数。



#### 4.3、相关构造函数

##### 1、四种构造函数

######      1）无参构造函数

​		创建一个类，没有写任何构造函数，系统会自动生成无参构造函数，函数为空。如果希望有这样一个无参构造函数，需要自己显式地写出来。

######    2）一般构造函数

​		一个类可以有多个一般构造函数，类似于重载函数，创建对象时根据传入参数的不同调用不同的构造函数；

######   3）拷贝构造函数

​		参数为对象本身的应用，根据一个已经存在的对象复制出来一个新的该类的对象。若没有写拷贝构造函数，系统会默认一个拷贝构造函数，当类中有指针成员的时候，系统默认创建的构造函数会造成浅拷贝的问题。

######    4）转换构造函数

​		转换构造函数的作用是将一个其他类型的数据转化成一个类的对象。转换构造函数只能有一个参数。若是不行让转换构造函数生效，拒绝其他类型通过转换构造转换为本类型，在转换构造函数前面加上explicit。

```c++
class Complex
{
public:
    double m_real;
    double m_img;
    Complex(void)  //无参构造
    {
        m_real = 0.0;
        m_img = 0.0;
    }
    Complex(double real, double img)//一般构造
    {
        m_real = real;
        m_img = img;
    }
    Complex(const Complex& c) //拷贝构造
    {
        m_real = c.m_real;
        m_img = c.m_img;
    }
    Complex(int i)
    {
        m_real = i;
        m_img = 0.0;
    }
};

int main()
{
    Complex c1(7, 8);//普通构造函数
    c1 = 9; //转换构造
    Complex c2 = 10;  //转换构造
    cout << c1.m_real << " " << c1.m_img << endl; //输出9 0 
    cout << c2.m_real << " " << c2.m_img << endl; //输出10 0 
}
```



##### 2、构造函数的执行顺序

- 在派生类构造函数中，所有的虚基类及上一层基类的构造函数调用；
- 对象的vptr被初始化；
- 如果有成员初始化列表，将在构造函数体内扩展开来，这必须在vptr被设定之后才做；
- 执行程序员所提供的代码；

##### 3、一个类中的全部构造函数的扩展过程

- 记录在成员初始化列表中的数据成员初始化操作会被放在构造函数的函数体内，并与成员的声明顺序为顺序；
- 如果一个成员并没有出现在成员初始化列表中，但它有一个默认构造函数，那么默认构造函数必须被调用；
- 如果class有虚表，那么它必须被设定初值；
- 所有上一层的基类构造函数必须被调用；
- 所有虚基类的构造函数必须被调用。

##### 4、为什么拷贝构造函数必须传引用？

###### 1）拷贝构造作用

​		拷贝构造函数的作用就是用来**复制对象**的，在使用这个对象的实例来初始化这个对象的一个新的实例。

###### 2）参数传递过程到底发生了什么？

​		将地址传递和值传递统一起来，归根结底还是传递的是"值"(地址也是值，只不过通过它可以找到另一个值)！

###### 3）值传递

- 对于内置数据类型的传递时，直接赋值拷贝给形参(注意形参是函数内局部变量)；

- 对于类类型的传递时，需要首先调用该类的拷贝构造函数来初始化形参(局部对象)； 

  如void foo(class_type obj_local){}, 如果调用foo(obj); 首先class_type obj_local(obj) ,这样就定义了局部变量obj_local供函数内部使用

###### 4）引用传递

​		无论对内置类型还是类类型，传递引用或指针最终都是传递的**地址值**！而地址总是指针类型(属于简单类型), 显然参数传递时，按简单类型的**赋值拷贝**，而不会有拷贝构造函数的调用(对于类类型).

​		上述1) 2)回答了为什么拷贝构造函数使用值传递会产生无限递归调用，内存溢出。

​		拷贝构造函数用来初始化一个非引用类类型对象，如果用传值的方式进行传参数，那么构造实参需要调用拷贝构造函数，而拷贝构造函数需要传递实参，所以会一直递归。

##### 5、什么情况下调用拷贝构造函数？

- 用类的一个实例化对象去初始化另一个对象的时候

- 函数的参数是类的对象时（非引用传递）

- 函数的返回值是函数体内局部对象的类的对象时 ,此时虽然发生（Named return Value优化）NRV优化，但是由于返回方式是值传递，所以会在返回值的地方调用拷贝构造函数

  **第三种情况在Linux g++下则不会发生拷贝构造函数，不仅如此即使返回局部对象的引用，依然不会发生拷贝构造函数**

**==总结==：即使发生NRV优化的情况下，Linux+ g++的环境是不管值返回方式还是引用方式返回的方式都不会发生拷贝构造函数，而Windows + VS2019在值返回的情况下发生拷贝构造函数，引用返回方式则不发生拷贝构造函数**。 在c++编译器发生NRV优化，如果是引用返回的形式则不会调用拷贝构造函数，如果是值传递的方式依然会发生拷贝构造函数。

##### 6、如何禁止程序自动生产拷贝构造函数？

- 为了阻止编译器默认生成拷贝构造函数和拷贝赋值函数，我们需要手动去重写这两个函数，某些情况下，为了避免调用拷贝构造函数和拷贝赋值函数，我们需要将他们设置成**private**，防止被调用。
- 类的成员函数和friend函数还是可以调用private函数，如果这个private函数只声明不定义，则会产生一个连接错误；
- 针对上述两种情况，我们可以定一个base类，在base类中将拷贝构造函数和拷贝赋值函数设置成private,那么派生类中编译器将不会自动生成这两个函数，且由于base类中该函数是私有的，因此，派生类将阻止编译器执行相关的操作。

##### 7、构造函数、拷贝构造函数、赋值运算符区别

###### 1）构造函数

​		对象不存在，没用别的对象初始化，在创建一个新的对象时调用构造函数。

###### 2）拷贝构造函数

​		对象不存在，但是使用别的已经存在的对象来进行初始化。

###### 3）赋值运算符

​		对象存在，用别的对象给它赋值，这属于重载“=”号运算符的范畴，“=”号两侧的对象都是已存在的。

###### 4）拷贝构造与赋值运算符区别

- 拷贝构造函数是**函数**，赋值运算符是运算符**重载**。
- 拷贝构造函数会生成新的**类对象**，赋值运算符不能。
- 拷贝构造函数是直接构造一个新的类对象，所以在初始化对象前不需要检查源对象和新建对象是否相同；赋值运算符需要上述操作并提供两套不同的复制策略，另外赋值运算符中如果原来的对象有内存分配则需要先把内存释放掉。
- 形参传递是调用拷贝构造函数（调用的被赋值对象的拷贝构造函数），但并不是所有出现"="的地方都是使用赋值运算符

##### 8、什么情况自动调用默认构造函数？

- 带有默认构造函数的类成员对象，如果一个类没有任何构造函数，但它含有一个成员对象，而后者有默认构造函数，那么编译器就为该类合成出一个默认构造函数。不过这个合成操作只有在构造函数真正被需要的时候才会发生；如果一个类A含有多个成员类对象的话，那么类A的每一个构造函数必须调用每一个成员对象的默认构造函数而且必须按照类对象在类A中的声明顺序进行；
- 带有默认构造函数的基类，如果一个没有任务构造函数的派生类派生自一个带有默认构造函数基类，那么该派生类会合成一个构造函数调用上一层基类的默认构造函数；
- 带有一个虚函数的类
- 带有一个虚基类的类
- 合成的默认构造函数中，只有基类子对象和成员类对象会被初始化。所有其他的非静态数据成员都不会被初始化。

##### 9、移动构造函数

​		有时候我们会遇到这样一种情况，我们用对象a初始化对象b后对象a我们就不在使用了，但是对象a的空间还在呀（在析构之前），既然拷贝构造函数，实际上就是把a对象的内容复制一份到b中，那么为什么我们不能直接使用a的空间呢？这样就避免了新的空间的分配，大大降低了构造的成本。这就是移动构造函数设计的初衷；

​		拷贝构造函数中，对于指针，我们一定要采用深层复制，而移动构造函数中，对于指针，我们采用浅层复制；

​		C++引入了移动构造函数，专门处理这种，用a初始化b后，就将a析构的情况；

​		与拷贝类似，移动也使用一个对象的值设置另一个对象的值。但是，又与拷贝不同的是，移动实现的是对象值真实的转移（源对象到目的对象）：源对象将丢失其内容，其内容将被目的对象占有。移动操作的发生的时候，是当移动值的对象是未命名的对象的时候。这里未命名的对象就是那些临时变量，甚至都不会有名称。典型的未命名对象就是函数的返回值或者类型转换的对象。使用临时对象的值初始化另一个对象值，不会要求对对象的复制：因为临时对象不会有其它使用，因而，它的值可以被移动到目的对象。做到这些，就要使用移动构造函数和移动赋值：当使用一个临时变量对象进行构造初始化的时候，调用移动构造函数。类似的，使用未命名的变量的值赋给一个对象时，调用移动赋值操作。



#### 4.4、构造函数和析构函数相关问题

##### 1、析构函数的作用

- 构造函数只是起初始化值的作用，但实例化一个对象的时候，可以通过实例去传递参数，从主函数传递到其他的函数里面，这样就使其他的函数里面有值了。规则，只要你一实例化对象，系统自动回调用一个构造函数就是你不写，编译器也自动调用一次。
- 析构函数与构造函数的作用相反，用于撤销对象的一些特殊任务处理，可以是释放对象分配的内存空间；特点：析构函数与构造函数同名，但该函数前面加~。析构函数没有参数，也没有返回值，而且不能重载，在一个类中只能有一个析构函数。 当撤销对象时，编译器也会自动调用析构函数。每一个类必须有一个析构函数，用户可以自定义析构函数，也可以是编译器自动生成默认的析构函数。一般析构函数定义为类的公有成员。

##### 2、什么时候析构函数不会被调用？

###### 1）exit（）调用线程

​		来自显而易见的事物，即exit（），kill signal，power failure等。

```c++
#include <stdio.h>

class EmbeddedObject {
   private:
      char *pBytes;
   public:
      EmbeddedObject() {
         pBytes = new char[1000];
      }
     ~EmbeddedObject() {
         printf("EmbeddedObject::~EmbeddedObject()\n");
         delete [] pBytes;
      }
};

class Base {
  public:
    ~Base(){
       printf("Base::~Base()\n");
  }
};

class Derived : public Base {
   private:
      EmbeddedObject emb;
   public:
      ~Derived() {
         printf("Derived::~Derived()\n");
      }
};


int main (int argc, const char * argv[])
{
  Derived *pd = new Derived();
  // later for some good reason, point to it using Base pointer
  Base* pb = pd;
  delete pb; 
}
```

​		`~Base()`将被调用，但`~Derived()`不会。这意味着`~Derived()`中的代码不会执行。它可能需要做一些重要的事情。同样它的`EmbeddedObject`的析构函数应该被自动调用但不是。因此，`EmbeddedObject`没有机会释放其动态分配的数据。这会导致内存泄漏。

​	解决方案：在Base virtual中创建析构函数

```c++
class Base {
  public:
    virtual ~Base() {
    }   
};
```

###### 2）未处理的例外并退出

​		不会为无限循环范围之外的对象调用析构函数。

###### 3）TerminateProcess（）

​		如果使用[placement new](http://www.parashift.com/c++-faq-lite/dtors.html#faq-11.10)创建对象，则不会自动调用此对象的析构函数。

###### 4）常见的编程错误

- 使用创建动态对象数组 `object* x = new object[n]`，但使用`delete x`而非`delete[] x;`释放
- 而不是在对象上调用 delete（）而不是调用 free（）。虽然通常释放内存，但不会调用析构函数。
- 假设您有一个应该声明虚拟析构函数的对象层次结构，但由于某种原因不是。如果其中一个子类实例被转换为层次结构中的不同类型然后被删除，则它可能不会调用所有析构函数。
- 在由于抛出异常而被调用的另一个析构函数中抛出异常。

​		原文链接：https://www.thinbug.com/q/8733894

##### 3、构造函数、析构函数、虚函数是否可以声明为 inline 函数

​		首先，将这些函数声明为内联函数，在语法上没有错误。因为inline同register一样，只是个建议，编译器并不一定真正的内联。

​		register关键字：这个关键字请求编译器尽可能的将变量存在CPU内部寄存器中，而不是通过内存寻址访问，以提高效率。

**构造函数和析构函数声明为内联函数是没有意义的**

​		《Effective C++》中所阐述的是：**将构造函数和析构函数声明为inline是没有什么意义的，即编译器并不真正对声明为inline的构造和析构函数进行内联操作，因为编译器会在构造和析构函数中添加额外的操作（申请/释放内存，构造/析构对象等），致使构造函数/析构函数并不像看上去的那么精简**。其次，class中的函数默认是inline型的，编译器也只是有选择性的inline，将构造函数和析构函数声明为内联函数是没有什么意义的。

​		将虚函数声明为inline，要分情况讨论。

​		有的人认为虚函数被声明为inline，但是编译器并没有对其内联，他们给出的理由是inline是编译期决定的，而虚函数是运行期决定的，即在不知道将要调用哪个函数的情况下，如何将函数内联呢？上述观点看似正确，其实不然，如果虚函数在编译器就能够决定将要调用哪个函数时，就能够内联，那么什么情况下编译器可以确定要调用哪个函数呢，答案是当用对象调用虚函数（此时不具有多态性）时，就内联展开。

​		**综上**，当是指向派生类的指针（多态性）调用声明为inline的虚函数时，不会内联展开；当是对象本身调用虚函数时，会内联展开，当然前提依然是函数并不复杂的情况下。

##### 4、构造函数为什么不能为虚函数？析构函数呢？

###### 1）从存储空间角度

​		虚函数相应一个指向vtable虚函数表的指针，这大家都知道，但是这个**指向vtable的指针**事实上是**存储在对象的内存空间**的。问题出来了，假设构造函数是虚的，就须要通过 vtable来调用，但是对象还没有实例化，也就是内存空间还没有，怎么找vtable呢？所以构造函数不能是虚函数。

###### 2）从使用角度

​		虚函数主要用于在信息不全的情况下，能使重载的函数得到相应的调用。**构造函数本身就是要初始化实例**，那使用虚函数也没有实际意义呀。所以构造函数没有必要是虚函数。虚函数的作用在于通过父类的指针或者引用来调用它的时候可以变成调用子类的那个成员函数。而构造函数是在创建对象时自己主动调用的，不可能通过父类的指针或者引用去调用，因此也就规定构造函数不能是虚函数。

###### 3）从实现上看

​		vbtl在构造函数调用后才建立，因而构造函数不可能成为虚函数从实际含义上看，在调用构造函数时还不能确定对象的真实类型（由于子类会调父类的构造函数）；并且构造函数的作用是提供初始化，在对象生命期仅仅运行一次，不是对象的动态行为，也没有必要成为虚函数。

###### 4）从构造函数角度

​		**构造函数不须要是虚函数，也不同意是虚函数**，因为创建一个对象时我们总是要明白指定对象的类型，虽然我们可能通过实验室的基类的指针或引用去訪问它但析构却不一定，我们往往通过基类的指针来销毁对象。这时候假设析构函数不是虚函数，就不能正确识别对象类型从而不能正确调用析构函数。

​		**当一个构造函数被调用时，它做的首要的事情之中的一个是初始化它的VPTR**，因此，它仅仅能知道它是“当前”类的，而全然忽视这个对象后面是否还有继承者。当编译器为这个构造函数产生代码时，它是为这个类的构造函数产生代码——既不是为基类，也不是为它的派生类（由于类不知道谁继承它）。所以它使用的VPTR必须是对于这个类的VTABLE。

​		并且，仅仅要它是最后的构造函数调用，那么在这个对象的生命期内，VPTR将保持被初始化为指向这个VTABLE, 但假设接着另一个更晚派生的构造函数被调用，这个构造函数又将设置VPTR指向它的VTABLE，直到最后的构造函数结束。

​		**VPTR的状态是由被最后调用的构造函数确定的**。这就是为什么构造函数调用是从基类到更加派生类顺序的还有一个理由。可是，当这一系列构造函数调用正发生时，每一个构造函数都已经设置VPTR指向它自己的VTABLE。假设函数调用使用虚机制，它将仅仅产生通过它自己的VTABLE的调用，而不是最后的VTABLE（全部构造函数被调用后才会有最后的VTABLE）。因为构造函数本来就是为了明确初始化对象成员才产生的，然而virtual function主要是为了再不完全了解细节的情况下也能正确处理对象。另外，virtual函数是在不同类型的对象产生不同的动作，现在对象还没有产生，如何使用virtual函数来完成你想完成的动作

###### 5）从析构函数角度

​		C++中基类采用virtual虚析构函数是**为了防止内存泄漏。**具体地说，如果派生类中申请了内存空间，并在其析构函数中对这些内存空间进行释放。假设基类中采用的是非虚析构函数，当删除基类指针指向的派生类对象时就不会触发动态绑定，因而只会调用基类的析构函数，而不会调用派生类的析构函数。那么在这种情况下，派生类中申请的空间就得不到释放从而产生内存泄漏。

​		所以，为了防止这种情况的发生，C++中基类的析构函数应采用virtual虚析构函数。

##### 5、构造函数、析构函数的执行顺序？

###### 1）构造函数顺序

- 基类构造函数。如果有多个基类，则构造函数的调用顺序是某类在类派生表中出现的顺序，而不是它们在成员初始化表中的顺序。
- 成员类对象构造函数。如果有多个成员类对象则构造函数的调用顺序是对象在类中被声明的顺序，而不是它们出现在成员初始化表中的顺序。
- 派生类构造函数。

###### 2）析构函数顺序

- 调用派生类的析构函数；
- 调用成员类对象的析构函数；
- 调用基类的析构函数。

##### 6、虚析构函数的作用，父类的析构函数是否要设置为虚函数？

1）C++中基类采用virtual虚析构函数是为了**防止内存泄漏**。

​		具体地说，如果派生类中申请了内存空间，并在其析构函数中对这些内存空间进行释放。假设基类中采用的是非虚析构函数，当删除基类指针指向的派生类对象时就不会触发动态绑定，因而只会调用基类的析构函数，而不会调用派生类的析构函数。那么在这种情况下，派生类中申请的空间就得不到释放从而产生内存泄漏。

​		所以，为了防止这种情况的发生，C++中基类的析构函数应采用virtual虚析构函数。

2）纯虚析构函数一定得定义，因为每一个派生类析构函数会被编译器加以扩张，以静态调用的方式调用其每一个虚基类以及上一层基类的析构函数。因此，缺乏任何一个基类析构函数的定义，就会导致链接失败，**最好不要把虚析构函数定义为纯虚析构函数**。

##### 7、虚析构和纯虚析构

​		因为虚函数是父类指针指向子类对象。因此，父类指针在析构的时候，不会调用子类中的析构函数，要是子类中有堆区属性，就会出现内存泄漏。因此需要把父类中的析构函数改成虚析构。虚析构、纯虚析构需要声明也需要实现。纯虚析构（=0），该类属于抽象类，无法实例化对象。  纯虚析构需要声明也需要实现，因为父类中也有可能有堆区开辟的属性，所以无论时纯虚析构还是虚析构必须有代码实现。**解决父类指针释放子类对象不干净的问题**。

​		所以，父类中用了虚析构，子类就不用虚析构。因为C++规定，当一个成员函数被声明为虚函数后，其派生类的同名函数都自动成为虚函数。所以基类的析构函数要使用虚函数。

##### 8、构造函数析构函数可否抛出异常？

- C++只会析构已经完成的对象，对象只有在其构造函数执行完毕才算是完全构造妥当。在构造函数中发生异常，控制权转出构造函数之外。因此，在对象b的构造函数中发生异常，对象b的析构函数不会被调用。因此会造成内存泄漏。
- 用auto_ptr对象来取代指针类成员，便对构造函数做了强化，免除了抛出异常时发生资源泄漏的危机，不再需要在析构函数中手动释放资源；
- 如果控制权基于异常的因素离开析构函数，而此时正有另一个异常处于作用状态，C++会调用terminate函数让程序结束；
- 如果异常从析构函数抛出，而且没有在当地进行捕捉，那个析构函数便是执行不全的。如果析构函数执行不全，就是没有完成他应该执行的每一件事情。

##### 9、类什么时候析构？

- 对象生命周期结束，被销毁时；
- delete指向对象的指针时，或delete指向对象的基类类型指针，而其基类虚构函数是虚函数时；
- 对象i是对象o的成员，o的析构函数被调用时，对象i的析构函数也被调用。

##### 10、构造函数或析构函数中可以调用虚函数吗？

​		简要结论：从语法上讲，调用完全没有问题。但是从效果上看，往往不能达到需要的目的。

​		《Effective C++》的解释是：派生类对象构造期间进入基类的构造函数时，对象类型变成了基类类型，而不是派生类类型。 同样，进入基类析构函数时，对象也是基类类型。



#### 4.5、成员初始化列表

##### 1、类成员初始化方式

###### 1）赋值初始化

​		通过在函数体内进行赋值初始化

###### 2）列表初始化

​		在冒号后使用初始化列表进行初始化。

###### 3）主要区别

​		对于在函数体中初始化,是在所有的数据成员被分配内存空间后才进行的。列表初始化是给数据成员分配内存空间时就进行初始化,就是说分配一个数据成员只要冒号后有此数据成员的赋值表达式(此表达式必须是括号赋值表达式),那么分配了内存空间后在进入函数体之前给数据成员赋值，就是说初始化这个数据成员此时函数体还未执行。

##### 2、为什么用成员初始化列表更快？

​		赋值初始化是在构造函数当中做赋值的操作，而列表初始化是做纯粹的初始化操作。我们都知道，C++的赋值操作是会产生**临时对象**的。临时对象的出现会降低程序的效率。用初始化列表会快一些的原因是，对于类型，它**少了一次调用构造函数的过程**，而在函数体中赋值则会多一次调用。而对于内置数据类型则没有差别。

​		由于对象成员变量的初始化动作发生在进入构造函数之前，对于内置类型没什么影响，但**如果有些成员是类**，那么在进入构造函数之前，会先调用一次默认构造函数，进入构造函数后所做的事其实是一次赋值操作(对象已存在)，所以**如果是在构造函数体内进行赋值的话，等于是一次默认构造加一次赋值，而初始化列表只做一次赋值操作。**

##### 3、哪些情况必须用成员列表初始化？作用是什么？

###### 1）必须使用成员初始化的四种情况

- 当初始化一个引用成员时；
- 当初始化一个常量成员时；
- 当调用一个基类的构造函数，而它拥有一组参数时；
- 当调用一个成员类的构造函数，而它拥有一组参数时；

###### 2）作用

- 编译器会一一操作初始化列表，以适当的顺序在构造函数之内安插初始化操作，并且在任何显示用户代码之前；
- list中的项目顺序是由类中的成员声明顺序决定的，不是由初始化列表的顺序决定的；

##### 4、如何阻止一个类被实例化？

- 将类定义为抽象基类或者将构造函数声明为private；
- 不允许类外部创建类对象，只能在类内部创建对象。



### 5、STL模板库

#### 5.1、STL六大部件

 		STL的六代组件，分别是：**容器、算法、迭代器、仿函数、适配器（配接器）、空间配置器**

- 容器：各种数据结构，如vector、list、deque、set、map等，用来存放数据
- 算法：各种常用算法，如sort、find、copy、for_each等
- 迭代器：扮演了容器与算法之间的胶合剂
- 仿函数：行为类似函数，可作为算法的某种策略  （bool类型重载() ，经常在sort里面用到，C++11有lambda)
- 适配器：一种用来修饰容器或者仿函数或迭代器接口的东西
- 空间配置器：负责空间的配置与管理

##### 1、什么是STL?

​		C++ STL从广义来讲包括了三类：算法，容器和迭代器。

- 算法包括排序，复制等常用算法，以及不同容器特定的算法。
- 容器就是数据的存放形式，包括序列式容器和关联式容器，序列式容器就是list，vector等，关联式容器就是set，map等。
- 迭代器就是在不暴露容器内部结构的情况下对容器的遍历。

##### 2、trivial destructor

​		“trivial destructor”一般是指**用户没有自定义析构函数**，而由系统生成的，这种析构函数在《STL源码解析》中成为“无关痛痒”的析构函数。反之，用户自定义了析构函数，则称之为“non-trivial destructor”，这种析构函数**如果申请了新的空间一定要显式的释放，否则会造成内存泄露**。

​		对于trivial destructor，如果每次都进行调用，显然对效率是一种伤害，如何进行判断呢？

​		《STL源码解析》中给出的说明是：首先利用value_type()获取所指对象的型别，再利用type_traits判断该型别的析构函数是否trivial，若是(true_type)，则什么也不做，若为(false_type)，则去调用destory()函数。也就是说，在实际的应用当中，STL库提供了相关的判断方法__type_traits，感兴趣的读者可以自行查阅使用方式。

​		除了trivial destructor，还有trivial construct、trivial copy construct等，如果能够对是否trivial进行区分，可以采用内存处理函数memcpy()、malloc()等更加高效的完成相关操作，提升效率。

##### 3、traits技巧

​		traits技法利用“内嵌型别“的编程技巧与**编译器的****template****参数推导功能**，增强C++未能提供的关于型别认证方面的能力。常用的有iterator_traits和type_traits。

###### 1）iterator_traits

​		被称为**特性萃取机**，能够方面的让外界获取以下5中型别：

- value_type：迭代器所指对象的型别
- difference_type：两个迭代器之间的距离
- pointer：迭代器所指向的型别
- reference：迭代器所引用的型别
- iterator_category：三两句说不清楚，建议看书

###### 2）type_traits

​		关注的是型别的**特性**，例如这个型别是否具备non-trivial defalt ctor（默认构造函数）、non-trivial copy ctor（拷贝构造函数）、non-trivial assignment operator（赋值运算符） 和non-trivial dtor（析构函数），如果答案是否定的，可以采取直接操作内存的方式提高效率，一般来说，type_traits支持以下5中类型的判断：

```c++
__type_traits<T>::has_trivial_default_constructor
__type_traits<T>::has_trivial_copy_constructor
__type_traits<T>::has_trivial_assignment_operator
__type_traits<T>::has_trivial_destructor
__type_traits<T>::is_POD_type
```

​		由于编译器只针对class object形式的参数进行参数推到，因此上式的返回结果不应该是个bool值，实际上使用的是一种空的结构体：

```c++
struct __true_type{};struct __false_type{};
```

​		这两个结构体没有任何成员，不会带来其他的负担，又能满足需求，可谓一举两得当然，如果我们自行定义了一个Shape类型，也可以针对这个Shape设计type_traits的特化版本：

```c++
template<> struct __type_traits<Shape>{
    typedef __true_type has_trivial_default_constructor;
    typedef __false_type has_trivial_copy_constructor;
    typedef __false_type has_trivial_assignment_operator;
    typedef __false_type has_trivial_destructor;
    typedef __false_type is_POD_type;
};
```



#### 5.2、vector

##### 1、底层实现

​		相当于一个数组，在内存空间中分配一段连续的内存空间进行存储，支持不指定大小。STL在实现的时候，首先分配一个非常大的内存空间进行存储，即capacity()返回容量的大小，扩容方式是动态扩容。 

​		**vector底层实现：** Vector容器是使用三个指针来表示的，_Myfirst指向的是vector容器对象的起始字节位置， _Mylast指向的是当前最后一个元素的末尾字节， _Myend指向整个vector容器所占内存空间的末尾字节。所以vector会有size和capacity。

##### 2、优缺点

- 优点： 不指定一块内存大小的数组的连续，可以像数组一样操作，更可以使用push_back()、pop_back()等动态操作；随机访问方便，支持[]操作符和vector.at();节省空间。
- 缺点：在内部进行插入删除操作效率低；只能在最后进行push和pop；当动态添加的数据超过默认分配的大小时要进行整体的重新分配、拷贝与释放。

##### 3、vector扩容原理

​		vector扩容一般会经历三个步骤：**重新配置空间、移动数据、释放原空间**，vector的扩容倍数与平台有关系，Win + VS 是**1.5**倍，Linux + GCC 是**2**倍。vector通过一段连续的数组存放元素，集合满了，就分配一块更大的内存，将原来的数据拷贝过来，释放之前的内存，插入新增元素。对vector的操作，一旦引起空间重新配置，指向原vector的所有迭代器就都失效了。不同的编译器实现的扩容方式不一样。但是并没有规定push_back()用哪个增长因子， 一般使用2倍或1.5倍的增长，但是用2倍的方式扩容，下一次申请的内存必然大于之前分配内存的总和，导致之前分配的内存不能再被使用，所以增长因子最好设置为(1,2)之间。

```c++
const size_type len = old_size + max(old_size, n);//以原大小的两倍配置另外一块较大的空间（旧长度 + 新增元素的个数）
```

​		**以成倍的方式增加：**假设有n个元素，然后倍增因子是m，完成这n个元素往vector中push_back，需要重新分配内存的次数是logm(n)，当第i次重新分配会导致复制m的i次方个旧空间中的元素，n次push_back操作所花费的时间复杂度为O(n)，那就相当于m的i次方从i=1累加到logm(n)约等于（nM）/(m-1)，那其实对于m/(m-1)来说，这是个常量，用均摊分析法可知，成倍的扩容方法时间复杂度为常量时间。

​		**一次增加固定大小：**假设有n个元素，每次增加K个。同理，可以推导得出增加固定大小的时间复杂度为O(N)。

##### 4、push_back 和 emplace_back

​		**对象复用**：本质是一种设计模式（Flyweight享元模式），通过将对象存储到“对象池”中实现对象的重复利用，这样可以避免多次创建重复对象的开销，节约系统资源。

​		**零拷贝**：是一种避免CPU将数据从一块存储拷贝到另外一块存储的技术。零拷贝技术可以减少数据拷贝和共享总线操作的次数。（具体实现原理见操作系统第9章）

​		在C++中，vector的一个成员函数**emplace_back()**很好地体现了**零拷贝**技术，它跟push_back()函数一样可以将一个元素插入容器尾部，区别在于：**使用push_back()函数需要调用拷贝构造函数和转移构造函数，而使用emplace_back()插入的元素原地构造，不需要触发拷贝构造和转移构造**，效率更高。

- push_back

  push_back会对传递进来的参数进行一次拷贝，并将其添加到vector中，只是浅拷贝，会导致delete两次，有问题。

- emplace_back

  emplace_back对传递的参数进行原地构造，实现零拷贝技术。

##### 5、resize和reserve预留空间

- vector中有capacity和size,capacity指的是容量（容器能够容纳的最大的元素个数），size是容器中实际的元素个数；
- resize（重新分配大小）既分配了空间，也创建了对象，既修改了capacity的大小，也修改了size的大小；
- reverse（预留空间）是预留空间，还没有创建对象，只是修改了capacity的大小 ；   
- resize和reverse接口的共同点都是保证了vector容器的capacity达到了它的参数所指定的大小。

##### 6、为什么预留空间用reverse？

​		当resize（n)大于原来的vector的容量，会引起自动的内存分配，所以用reserve 减少vector在动态扩展容量时的扩展次数，若是数据量较大，可以一开始就用reserve预留空间，v.reserve(100000);

##### 7、如何释放vector空间？

​		由于vector的内存占用空间只增不减，比如你首先分配了10,000个字节，然后erase掉后面9,999个，留下一个有效元素，但是内存占用仍为10,000个。所有内存空间是在vector析构时候才能被系统回收。empty()用来检测容器是否为空的，clear()可以清空所有元素。但是即使clear()，vector所占用的内存空间依然如故，无法保证内存的回收。如果需要空间动态缩小，可以考虑使用deque。如果vector，可以用**swap()**来帮助你释放内存。

```c++
vector(Vec).swap(Vec); //将Vec的内存清除；
vector().swap(Vec); //清空Vec的内存；
```



#### 5.3、list 和 slist

##### 1、list

###### 1）底层实现

​		相比于vector的连续线型空间，list显得复杂许多，但是它的好处在于插入或删除都只作用于一个元素空间，因此list对空间的运用是十分精准的，对任何位置元素的**插入和删除**都是常数**O(1)**时间。list不能保证节点在存储空间中连续存储，也拥有迭代器，迭代器的“++”、“--”操作对于的是指针的操作，list提供的迭代器类型是**双向迭代器**：Bidirectional iterators。双向链表，每个节点都包含data、前驱指针pre、后继指针Post，使用的**非连续**的内存空间进行存储。

```c++
//list节点的结构：
template <class T>
struct __list_node{
    typedef void* void_pointer;
    void_pointer prev;
    void_pointer next;
    T data; 
}
```

​		从源码可看出list显然是一个双向链表。list与vector的另一个区别是，在插入和接合操作之后，都不会造成原迭代器失效，而vector可能因为空间重新配置导致迭代器失效。此外list也是一个环形链表，因此只要一个指针便能完整表现整个链表。list中node节点指针始终指向尾端的一个空白节点，因此是一种“前闭后开”的区间结构list的空间管理默认采用alloc作为空间配置器，为了方便的以节点大小为配置单位，还定义一个list_node_allocator函数可一次性配置多个节点空间。由于list的双向特性，其支持在头部（front)和尾部（back)两个方向进行push和pop操作，当然还支持erase，splice，sort，merge，reverse，sort等操作。

###### 2）优缺点

- 优点：使用非连续内存完成动态操作；在内部可以很方便的进行插入和删除；可以在两端进行push和pop。
- 缺点：不能进行内部的随机访问，不支持[]操作符;相对于vector占用内存多

###### 3）vector和list的区别

- vector数据结构 
  - vector和数组类似，拥有一段连续的内存空间，并且起始地址不变。因此能高效的进行随机存取，时间复杂度为o(1);但因为内存空间是连续的，所以在进行插入和删除操作时，会造成内存块的拷贝，时间复杂度为o(n)。另外，当数组中内存空间不够时，会重新申请一块内存空间并进行内存拷贝。连续存储结构：vector是可以实现动态增长的对象数组，支持对数组高效率的访问和在数组尾端的删除和插入操作，在中间和头部删除和插入相对不易，需要挪动大量的数据。它与数组最大的区别就是vector不需程序员自己去考虑容量问题，库里面本身已经实现了容量的动态增长，而数组需要程序员手动写入扩容函数进形扩容。
- list数据结构
  - list是由双向链表实现的，因此内存空间是不连续的。只能通过指针访问数据，所以list的随机存取非常没有效率，时间复杂度为o(n);但由于链表的特点，能高效地进行插入和删除。非连续存储结构：list是一个双链表结构，支持对链表的双向遍历。每个节点包括三个信息：元素本身，指向前一个元素的节点（prev）和指向下一个元素的节点（next）。因此list可以高效率的对数据元素任意位置进行访问和插入删除等操作。由于涉及对额外指针的维护，所以开销比较大。

- 区别

  - vector的随机访问效率高，但在插入和删除时（不包括尾部）需要挪动数据，不易操作。list的访问要遍历整个链表，它的随机访问效率低。但对数据的插入和删除操作等都比较方便，改变指针的指向即可。list是单向的，vector是双向的。vector中的迭代器在使用后就失效了，而list的迭代器在使用之后还可以继续使用。

  - ```c++
    int mySize = vec.size();vec.at(mySize -2);
    ```

    list不提供随机访问，所以不能用下标直接访问到某个位置的元素，要访问list里的元素只能遍历，不过你要是只需要访问list的最后N个元素的话，可以用反向迭代器来遍历：

##### 2、slist

​		![image-20220413105426709](F:/%E6%88%91%E7%9A%84%E6%96%87%E4%BB%B6_%E5%BC%A0%E5%85%B5/%E6%89%BE%E5%B7%A5%E4%BD%9C/image-20220413105426709.png)

​     list是双向链表，而slist（single linked list）是单向链表，它们的主要区别在于：前者的迭代器是双向的Bidirectional iterator，后者的迭代器属于单向的Forward iterator。虽然slist的很多功能不如list灵活，但是其所耗用的空间更小，操作更快。**根据STL的习惯，插入操作会将新元素插入到指定位置之前，而非之后，然而slist是不能回头的，只能往后走，因此在slist的其他位置插入或者移除元素是十分不明智的，但是在slist开头却是可取的，slist特别提供了insert_after()和erase_after供灵活应用。考虑到效率问题，slist只提供push_front()操作，元素插入到slist后，存储的次序和输入的次序是相反的。**



#### 5.4、deque、stack、queue、priority_queue

##### 1、deque

###### 1）底层实现

​		deque 容器存储数据的空间是由一段一段等长的连续空间构成，各段空间之间并不一定是连续的，可以位于在内存的不同区域。那为了管理这些不连续的空间，就会需要用一个数组来存储各个小段连续空间的首地址。所以说deque在头部或尾部增加存储空间时，就会新申请一段连续的空间，并且在存储地址的数组中添加指向该空间的指针。

![image-20220413111644323](F:/%E6%88%91%E7%9A%84%E6%96%87%E4%BB%B6_%E5%BC%A0%E5%85%B5/%E6%89%BE%E5%B7%A5%E4%BD%9C/image-20220413111644323.png)

​		双端队列，其实是在功能上合并了vector和list。也是连续存储结构，不同之处在于，deque提供了两级数组结构，第一级完全类似于vector,代表实际容器；另一级维护容器的首位地址，就可以支持高效的首尾插入和删除的操作。

###### 2）deque数据结构

```c++
class deque
{
 ...
protected:
    typedef pointer* map_pointer;//指向map指针的指针
 	map_pointer map;//指向map
 	size_type map_size;//map的大小
public:
 ...
 	iterator begin();
 	itertator end();
 ...
}
```

​		deque采用了一块所谓的map(不是STL中的map容器)作为主控，这里所谓的map是一小块连续空间，其中的每个元素称为一个节点，node，每个node都是一个指针，指向另一段较大的连续空间，称为缓冲区，这里就是deque中实际存放数据的区域，缓冲区默认大小512bytes。map大小初始值为8。deque开始的位置保持在map的中间，可使头尾两端的扩充能量一样大。整体结构如下图所示：

![image-20220413111823721](F:/%E6%88%91%E7%9A%84%E6%96%87%E4%BB%B6_%E5%BC%A0%E5%85%B5/%E6%89%BE%E5%B7%A5%E4%BD%9C/image-20220413111823721.png)

```c++
//deque的迭代器数据结构
struct __deque_iterator
{
 ...
 	T* cur;//迭代器所指缓冲区当前的元素
 	T* first;//迭代器所指缓冲区第一个元素
 	T* last;//迭代器所指缓冲区最后一个元素
 	map_pointer node;//指向map中的node
 ...
}
```

​		deque迭代器的“++”、“--”操作是远比vector迭代器繁琐，其主要工作在于缓冲区边界，如何从当前缓冲区跳到另一个缓冲区，当然deque内部在插入元素时，如果map中node数量全部使用完，且node指向的缓冲区也没有多余的空间，这时会配置新的map（2倍于当前+2的数量）来容纳更多的node，也就是可以指向更多的缓冲区。在deque删除元素时，也提供了元素的析构和空闲缓冲区空间的释放等机制。

![image-20220413111850412](F:/%E6%88%91%E7%9A%84%E6%96%87%E4%BB%B6_%E5%BC%A0%E5%85%B5/%E6%89%BE%E5%B7%A5%E4%BD%9C/image-20220413111850412.png)

###### 3）优缺点

- 优点：随机访问方便，支持[]操作符；在内部可以很方便的进行插入和删除操作；可以在两端进行push、pop
- 缺点：占用内存多

###### 4）与vector的区别

- vector是单向开口（尾部）的连续线性空间，deque是一种双开口的连续线性空间；
- deque运行在常数时间内对头端进行元素操作；
- deque没有容量的概念，是动态地以分段连续空间组合而成，可以随时增加一段新的空间链接起来；
- deque的随机访问复杂

##### 2、stack

​		stack（栈）是一种先进后出（First In Last Out）的数据结构，只有一个入口和出口，那就是栈顶，除了获取栈顶元素外，没有其他方法可以获取到内部的其他元素，其结构图如下：

![image-20220413111558034](F:/%E6%88%91%E7%9A%84%E6%96%87%E4%BB%B6_%E5%BC%A0%E5%85%B5/%E6%89%BE%E5%B7%A5%E4%BD%9C/image-20220413111558034.png)

​		stack这种单向开口的数据结构很容易由**双向开口的deque和list**形成，只需要根据stack的性质对应移除某些接口即可实现，stack的源码如下：

```c++
template <class T, class Sequence = deque<T> >
class stack
{
 ...
protected:
 	Sequence c;
public:
 	bool empty(){return c.empty();}
 	size_type size() const{return c.size();}
 	reference top() const {return c.back();}
 	const_reference top() const{return c.back();}
 	void push(const value_type& x){c.push_back(x);}
 	void pop(){c.pop_back();}
};
```

​		从stack的数据结构可以看出，其所有操作都是围绕Sequence完成，而Sequence默认是deque数据结构。**deque是stack默认的底部数据结构**。stack这种“修改某种接口，形成另一种风貌”的行为，成为adapter(配接器)。常将其归类为container adapter而非container stack除了默认使用deque作为其底层容器之外，也可以使用双向开口的list，只需要在初始化stack时，将list作为第二个参数即可。由于stack只能操作顶端的元素，因此其内部元素无法被访问，也不提供迭代器。

​		**由于stack系以底部容器完成其所有工作**，因此称为配接器。stack没有迭代器。

##### 3、queue	

​		queue（队列）是一种先进先出（First In First Out）的数据结构，只有一个入口和一个出口，分别位于最底端和最顶端，出口元素外，没有其他方法可以获取到内部的其他元素。

​		类似的，queue这种“先进先出”的数据结构很容易由双向开口的deque和list形成，只需要根据queue的性质对应移除某些接口即可实现，queue的源码如下：

```c++
template <class T, class Sequence = deque<T> >
class queue
{
 ...
protected:
 	Sequence c;
public:
 	bool empty(){return c.empty();}
 	size_type size() const{return c.size();}
 	reference front() const {return c.front();}
 	const_reference front() const{return c.front();}
 	void push(const value_type& x){c.push_back(x);}
 	void pop(){c.pop_front();}
};
```

​		从queue的数据结构可以看出，其所有操作都也都是是围绕Sequence完成，**Sequence默认也是deque数据结构**。queue也是一类container adapter。同样，queue也可以使用list作为底层容器，不具有遍历功能，没有迭代器。queue也是由底部容器完成其所有工作的，为配接器。

##### 4、priority_queue

​		priority_queue，优先队列，是一个拥有权值观念的queue，它跟queue一样是顶部入口，底部出口，在插入元素时，元素并非按照插入次序排列，它会自动根据权值（通常是元素的实值）排列，权值最高，排在最前面，如下图所示。

![image-20220413165237404](F:/%E6%88%91%E7%9A%84%E6%96%87%E4%BB%B6_%E5%BC%A0%E5%85%B5/%E6%89%BE%E5%B7%A5%E4%BD%9C/image-20220413165237404.png)

​		默认情况下，priority_queue使用一个max-heap完成，底层容器使用的是一般为vector为底层容器，堆heap为处理规则来管理底层容器实现 。priority_queue的这种实现机制导致其不被归为容器，而是一种容器配接器。关键的源码如下：

```c++
template <class T, class Squence = vector<T>, 
class Compare = less<typename Sequence::value_tyoe> >
class priority_queue{
 ...
protected:
 	Sequence c; // 底层容器
 	Compare comp; // 元素大小比较标准
public:
 	bool empty() const {return c.empty();}
 	size_type size() const {return c.size();}
 	const_reference top() const {return c.front()}
 void push(const value_type& x)
 {
 	c.push_heap(x);
	push_heap(c.begin(), c.end(),comp);
 }
 void pop()
 {
 	pop_heap(c.begin(), c.end(),comp);
 	c.pop_back();
 }
};
```

​		priority_queue的所有元素，进出都有一定的规则，只有queue顶端的元素（权值最高者），才有机会被外界取用，它没有遍历功能，也不提供迭代器。

**综上：vector、list、deque的使用情况**

-    需要高效的存取，不在乎插入和删除的效率，应该使用vector;
-    需要大量的插入和删除，不关心随机存取，应该使用list；
-    既想要随机存取，又关心两端数据的插入和删除应该使用deque



#### 5.5、heap

##### 1、底层原理

​		heap（堆）并不是STL的容器组件，是priority queue（优先队列）的底层实现机制，因为binary max heap（大根堆）总是最大值位于堆的根部，优先级最高。binary heap本质是一种complete binary tree（完全二叉树），整棵binary tree除了最底层的叶节点之外，都是填满的，但是叶节点从左到右不会出现空隙，如下图所示就是一颗完全二叉树。

​		完全二叉树内没有任何节点漏洞，是非常紧凑的，这样的一个好处是可以使用array来存储所有的节点，因为当其中某个节点位于$i$处，其左节点必定位于 **2i** 处，右节点位于**2i+1 **处，父节点位于**i/2** （向下取整）处。这种以array表示tree的方式称为隐式表述法。因此我们可以使用一个array和一组heap算法来实现max heap（每个节点的值大于等于其子节点的值）和min heap（每个节点的值小于等于其子节点的值）。由于array不能动态的改变空间大小，用vector代替array是一个不错的选择。那heap算法有哪些？常见有的插入、弹出、排序和构造算法，下面一一进行描述。

##### 2、push_heap算法

​		由于完全二叉树的性质，新插入的元素一定是位于树的最底层作为叶子节点，并填补由左至右的第一个空格。事实上，在刚执行插入操作时，新元素位于底层vector的end()处，之后是一个称为percolate up（上溯）的过程，举个例子如下图：

![image-20220413164827945](F:/%E6%88%91%E7%9A%84%E6%96%87%E4%BB%B6_%E5%BC%A0%E5%85%B5/%E6%89%BE%E5%B7%A5%E4%BD%9C/image-20220413164827945.png)

​		新元素50在插入堆中后，先放在vector的end()存着，之后执行上溯过程，调整其根结点的位置，以便满足max heap的性质，如果了解大根堆的话，这个原理跟大根堆的调整过程是一样的。

##### 3、pop_heap算法

​		heap的pop操作实际弹出的是根节点吗，但在heap内部执行pop_heap时，只是将其移动到vector的最后位置，然后再为这个被挤走的元素找到一个合适的安放位置，使整颗树满足完全二叉树的条件。这个被挤掉的元素首先会与根结点的两个子节点比较，并与较大的子节点更换位置，如此一直往下，直到这个被挤掉的元素大于左右两个子节点，或者下放到叶节点为止，这个过程称为percolate down（下溯）。举个例子：

![image-20220413165023752](F:/%E6%88%91%E7%9A%84%E6%96%87%E4%BB%B6_%E5%BC%A0%E5%85%B5/%E6%89%BE%E5%B7%A5%E4%BD%9C/image-20220413165023752.png)

​		根节点68被pop之后，移到了vector的最底部，将24挤出，24被迫从根节点开始与其子节点进行比较，直到找到合适的位置安身，需要注意的是pop之后元素并没有被移走，如果要将其移走，可以使用pop_back()。

##### 4、sort算法

​		一言以蔽之，因为pop_heap可以将当前heap中的最大值置于底层容器vector的末尾，heap范围减1，那么不断的执行pop_heap直到树为空，即可得到一个递增序列。

##### 5、构建heap算法

```c++
//构建大顶堆算法
//swap函数(可以直接异或) a = a ^ b; b = a ^ b; a = a ^ b;
//例a = 1, b = 2;(a = 1 ^ 2; b = 1 ^ 2 ^ 2 = 1; a = 1 ^ 2 ^ 1 = 2;)
static void swap(vector<int>& arr, int a, int b) {
	int temp;
	temp = arr[a];
	arr[a] = arr[b];
	arr[b] = temp;
}
//构建大顶堆
static void heapSort(vector<int>& arr) {
	// 构建初始大顶堆
	buildMaxHeap(arr);
	for (int i = arr.size() - 1; i > 0; i--) {
		// 将最大值交换到数组最后
		swap(arr, 0, i);
		// 调整剩余数组，使其满足大顶堆
		maxHeapify(arr, 0, i);
	}
}
// 构建初始大顶堆
static void buildMaxHeap(vector<int>& arr) {
	// 从最后一个非叶子结点开始调整大顶堆，最后一个非叶子结点的下标就是 arr.length / 2-1
	for (int i = arr.size() / 2 - 1; i >= 0; i--) {
		maxHeapify(arr, i, arr.size());
	}
}
// 调整大顶堆，第三个参数表示剩余未排序的数字的数量，也就是剩余堆的大小
static void maxHeapify(vector<int>& arr, int i, int heapSize) {
	// 左子结点下标
	int l = 2 * i + 1;
	// 右子结点下标
	int r = l + 1;
	// 记录根结点、左子树结点、右子树结点三者中的最大值下标
	int largest = i;
	// 与左子树结点比较
	if (l < heapSize && arr[l] > arr[largest]) {
		largest = l;
	}
	// 与右子树结点比较
	if (r < heapSize && arr[r] > arr[largest]) {
		largest = r;
	}
	if (largest != i) {
		// 将最大值交换为根结点
		swap(arr, i, largest);
		// 再次调整交换数字后的大顶堆
		maxHeapify(arr, largest, heapSize);
	}
}
```



#### 5.6、map、set、multimap、multiset

##### 1、map

​		key-value形式（键值唯一），底层是红黑树，适合进行记录的存储和查询。map访问不存在的键值，不会崩溃，会插入这个键值，值为默认值。

​		map的特性是所有元素会根据键值进行**自动排序**。**map中所有的元素都是pair，**拥有键值(key)和实值(value)两个部分，并且不允许元素有相同的key，**一旦map的key确定了，那么是无法修改的，但是可以修改这个key对应的value**，因此map的迭代器既不是constant iterator，也不是mutable iterator标准STL map的底层机制是RB-tree（红黑树），另一种以hash table为底层机制实现的称为hash_map。map的操作行为，红黑树都已提供，map只要转调用即可。map的架构如下图所示：

![image-20210918112607092](总结面试题.assets/image-20210918112607092.png)

##### 2、set

​     单值形式，键值和值相等。所以不能通过set的迭代器修改set的元素值，并且值不重复。

STL中的容器可分为序列式容器（sequence）和关联式容器（associative），set属于关联式容器。set的特性是，所有元素都会根据元素的值自动被排序（默认升序），set元素的键值就是实值，实值就是键值，set不允许有两个相同的键值set不允许迭代器修改元素的值，其迭代器是一种constance iterators标准的STL set以RB-tree（红黑树）作为底层机制，几乎所有的set操作行为都是转调用RB-tree的操作行为，这里补充一下红黑树的特性：

- 每个节点不是红色就是黑色
- 根结点为黑色
- 如果节点为红色，其子节点必为黑
- 任一节点至（NULL）树尾端的任何路径，所含的黑节点数量必相同

##### 3、区别

- set只提供一种数据类型的接口，但是会将这一个元素分配到key和value上，而且它的compare_function用的是 identity()函数，这个函数是输入什么输出什么，这样就实现了set机制，set的key和value其实是一样的了。其实他保存的是两份元素，而不是只保存一份元素map则提供两种数据类型的接口，分别放在key和value的位置上，他的比较function采用的是红黑树的comparefunction（），保存的确实是两份元素。他们两个的insert都是采用红黑树的**insert_unique()** 独一无二的插入 。
- multimap和map的唯一区别就是：multimap调用的是红黑树的**insert_equal()**,可以重复插入而map调用的则是独一无二的插入insert_unique()，multiset和set也一样，底层实现都是一样的，只是在插入的时候调用的方法不一样。

##### 4、应用及场景

​		map支持键值的自动排序，底层机制是红黑树，红黑树的查询和维护时间复杂度均为**O(logn)**，但是空间占用比较大，因为每个节点要保持父节点、孩子节点及颜色的信息。unordered_map是C++ 11新添加的容器，底层机制是哈希表，通过hash函数计算元素位置，其查询时间复杂度为O(1)，维护时间与bucket桶所维护的list长度有关，但是建立hash表耗时较大从两者的底层机制和特点可以看出：map适用于**有序数据**的应用场景，unordered_map适用于**高效查询**的应用场景。

#### 5.7、hash 和 hashtable

#### C++11 用unordered_set 与unordered_map 代替hash_set 与hash_map*

##### 1、hash

##### 2、hash table

​		STL中的hash table使用的是**开链法**解决hash冲突问题，如下图所示：

![image-20220413200223984](F:/%E6%88%91%E7%9A%84%E6%96%87%E4%BB%B6_%E5%BC%A0%E5%85%B5/%E6%89%BE%E5%B7%A5%E4%BD%9C/image-20220413200223984.png)

​		hash table中的bucket所维护的list既不是list也不是slist，而是其自己定义的由hash table_node数据结构组成的linked-list，而bucket聚合体本身使用vector进行存储。hash table的迭代器只提供前进操作，不提供后退操作。

​		在hash table设计bucket的数量上，其内置了**28**个质数[53, 97, 193,...,429496729]，在创建hash table时，会根据存入的元素个数选择大于等于元素个数的质数作为hash table的容量（vector的长度），其中每个bucket所维护的linked-list长度也等于hash table的容量。**如果插入hash table的元素个数超过了bucket的容量，就要进行重建table操作，即找出下一个质数，创建新的buckets vector，重新计算元素在新hash table的位置。**

##### 3、hash_map扩容

- hash table表格内的元素称为桶（bucket),而由桶所链接的元素称为节点（node),其中存入桶元素的容器为STL本身很重要的一种序列式容器——vector容器。之所以选择vector为存放桶元素的基础容器，主要是因为vector容器本身具有动态扩容能力，无需人工干预。
- 向前操作：首先尝试从目前所指的节点出发，前进一个位置（节点），由于节点被安置于list内，所以利用节点的next指针即可轻易完成前进操作，如果目前正巧是list的尾端，就跳至下一个bucket身上，那正是指向下一个list的头部节点。

##### 4、解决hash冲突的方法

-  线性探测
  - 使用hash函数计算出的位置如果已经有元素占用了，则向后依次寻找，找到表尾则回到表头，直到找到一个空位
- 开链法
  -  每个表格维护一个list，如果hash函数计算出的格子相同，则按顺序存在这个list中
- 再散列
  -  发生冲突时使用另一种hash函数再计算一个地址，直到不冲突
- 二次探测
  - 使用hash函数计算出的位置如果已经有元素占用了，按照$1^2$、$2^2$、$3^2$...的步长依次寻找，如果步长是随机数序列，则称之为伪随机探测
- 公共溢出
  -  一旦hash函数计算的结果相同，就放入公共溢出区



#### 5.8、迭代器

##### 1、迭代器定义

​		迭代器简单来说就是提供了一种方法，在不需要保留某个容器内部表现形式的情况下，使之能依次访问该容器中的各个元素，这样就可以通过迭代器把容器和算法粘合在一起，只要对算法给不同的迭代器 ，就可以对不同容器进行相同的操作了。 **迭代器最重要的编程工作就是对operator*和operator->进行重载工作。**

​		有些容器例如vector可以通过脚标索引的方式访问容器里面的数据，但是大部分的容器不能使用这种方式，例如list、map、set。STL中每种容器在实现的时候设计了一个内嵌的iterator类，不同的容器有自己专属的迭代器，使用迭代器来访问容器中的数据。除此之外，通过迭代器，可以将容器和通用算法结合在一起，只要给予算法不同的迭代器，就可以对不同容器执行相同的操作，例如find查找函数。**迭代器对指针的一些基本操作如*、->、++、==、!=、=进行了重载，使其具有了遍历复杂数据结构的能力，其遍历机制取决于所遍历的数据结构，所以迭代的使用和指针的使用非常相似。**

​		迭代器的begin和end：通过begin，end函数获取容器的头部和尾部迭代器，end 迭代器不包含在容器之内，当begin和end返回的迭代器相同时表示容器为空。就是说，v.begin()指向为v.begin()指向元素的第一个，v.end()指向元素最后一个的下一个。这样做的原因是：要表示空容器，v.begin() == v.end()就表示空容器。为什么要使用迭代器：迭代器相当于媒介的作用，可以很大程度上隔离容器的底层实现，使用时只需要依赖迭代器相对统一的方法和接口。

##### 2、迭代器失效

​		容器的插入insert 和 erase 都有可能导致迭代器失效，特别是对于erase多做不要使用操作之前的迭代器，因为那个迭代器一定失效的，要返回操作之后的迭代器。

​		每个容器迭代器失效的情况不一样

| STL     | 插入                             | 删除                           |
| ------- | -------------------------------- | ------------------------------ |
| list    | 迭代器不失效                     | 有且仅有被删除节点的迭代器失效 |
| vector  | vector发生扩容的时候迭代器会失效 | 被删除节点之后的迭代器全部失效 |
| set map | 迭代器不失效                     | 有且仅有被删除节点的迭代器失效 |

```C++
int arr[5] = {1,2,3,4,5};
vector<int> V(arr,arr+5);
//迭代器失效
//    for (vector<int>::iterator it = iVec.begin(); it != iVec.end();) {
//        iVec.erase(it);
//    }
    //返回erase操作之后的迭代器
    for (vector<int>::iterator it = iVec.begin();it != iVec.end();) {
        it = iVec.erase(it);
    }
```

#####   3、迭代器的实现

​		猜想：vector和list都继承于一个集合抽象类，然后list和vector的iterator都继承于iterator抽象基类。通过虚函数实现，虚函数有一个很大的弊端是必须要在运行时才绑定对象，这样会损失性能。或者可以使用类模板（typename），就是建立一个通用类，数据成员、成员函数的返回值类型和形参类型不具体指定，使用一个虚拟的类型来代表，使用类模板定义对象时，系统会根据实参的类型来取代模板中虚拟类型从而实现不同的功能。对于不同类型的迭代器，可能还会使用一个tag来标识迭代器。

```C++
//对于List和vector容器，其实使用迭代器进行输出的时候都是一样的代码，只是容器类型不一样
vector<int> vi{ 1, 3, 5, 7, 9 }; 
for(auto it = vi.begin(); it != vi.end(); ++it) 
{    cout<<*it<<endl; }

list<int> li{ 1, 3, 5, 7, 9 };
for(auto it = li.begin(); it != li.end(); ++it) {
    cout<<*it<<endl;
}
```

​		所以用了迭代器标识、并且利用模板重载，typename等实现了迭代器类型的编译器决策。

##### 4、迭代器与指针

​		迭代器不是指针，应该说用类模板来描述可能更准确。只是模拟了指针的一些功能，表现的像指针。迭代器返回的是对象的一个引用，迭代器只能指向容器。**并且迭代器在使用后就释放了，不会再继续使用，但是指针是可以的。**

##### 5、迭代器：++it 、it++的区别

- ++it 返回一个引用，it++返回一个对象
- ++it 不会产生临时对象，it++必须产生临时对象，临时对象会导致效率降低

```c++
//++it
int& operator++() //返回引用
{
    *this += 1;
    return *this;
}
//it++
int operator++(int) //返回对象
{
    int temp = *this; //会产生临时对象
    ++*this;
    return temp;
}
```



#### 5.9、空间配置器

##### 1、为什么需要两级空间配置器？

​		我们知道动态开辟内存时，要在堆上申请，但若是我们需要频繁的在堆开辟释放内存，则就会**在堆上造成很多外部碎片**，浪费了内存空间；每次都要进行调用**malloc、free**函数等操作，使空间就会增加一些附加信息，降低了空间利用率；随着外部碎片增多，内存分配器在找不到合适内存情况下需要合并空闲块，浪费了时间，大大降低了效率。

​		于是就设置了二级空间配置器，**当开辟内存<=128bytes时，即视为开辟小块内存，则调用二级空间配置器。**

​		关于STL中一级空间配置器和二级空间配置器的选择上，一般默认**选择的为二级空间配置器**。 如果大于128字节再转去一级配置器器。

##### 2、STL两级空间配置器

###### 1）一级配置器

​		**一级空间配置器**中重要的函数就是allocate、deallocate、reallocate 。 一级空间配置器是以malloc()，free()，realloc()等C函数执行实际的内存配置 。大致过程是：

- 直接allocate分配内存，其实就是malloc来分配内存，成功则直接返回，失败就调用处理函数；
- 如果用户自定义了内存分配失败的处理函数就调用，没有的话就返回异常；
- 如果自定义了处理函数就进行处理，完事再继续分配试试。

![image-20210915171134985](总结面试题.assets/image-20210915171134985.png)

###### 2）二级配置器

![image-20210915171207691](总结面试题.assets/image-20210915171207691.png)

- 维护16条链表，分别是0-15号链表，最小8字节，以8字节逐渐递增，最大128字节，你传入一个字节参数，表示你需要多大的内存，会自动帮你校对到第几号链表（如需要13bytes空间，我们会给它分配16bytes大小），在找到第n个链表后查看链表是否为空，如果不为空直接从对应的free_list中拔出，将已经拨出的指针向后移动一位。
- 对应的free_list为空，先看其内存池是不是空时，如果内存池不为空：
  - 先检验它剩余空间是否够20个节点大小（即所需内存大小(提升后) * 20），若足够则直接从内存池中拿出20个节点大小空间，将其中一个分配给用户使用，另外19个当作自由链表中的区块挂在相应的free_list下，这样下次再有相同大小的内存需求时，可直接拨出。
  - 如果不够20个节点大小，则看它是否能满足1个节点大小，如果够的话则直接拿出一个分配给用户，然后从剩余的空间中分配尽可能多的节点挂在相应的free_list中。
  - 如果连一个节点内存都不能满足的话，则将内存池中剩余的空间挂在相应的free_list中（找到相应的free_list），然后再给内存池申请内存，转到3。 

- 内存池为空，申请内存。

  - 此时二级空间配置器会使用malloc()从heap上申请内存，（一次所申请的内存大小为2 * 所需节点内存大小（提升后）* 20 + 一段额外空间），申请40块，一半拿来用，一半放内存池中。

- malloc没有成功。

  - 在第三种情况下，如果malloc()失败了，说明heap上没有足够空间分配给我们了，这时，二级空间配置器会从比所需节点空间大的free_list中一一搜索，从比它所需节点空间大的free_list中拔除一个节点来使用。如果这也没找到，说明比其大的free_list中都没有自由区块了，那就要调用一级适配器了。

  释放时调用deallocate()函数，若释放的n>128，则调用一级空间配置器，否则就直接将内存块挂上自由链表的合适位置。

###### 3）缺点

- 因为自由链表的管理问题，它会把我们需求的内存块自动提升为8的倍数，这时若你需要1个字节，它会给你8个字节，即浪费了7个字节，所以它又引入了内部碎片的问题，若相似情况出现很多次，就会造成很多**内部碎片**；
- 二级空间配置器是在堆上申请大块的狭义内存池，然后用自由链表管理，供现在使用，在程序执行过程中，它将申请的内存一块一块都挂在自由链表上，即不会还给操作系统，并且它的实现中所有成员全是**静态**的，所以它申请的所有内存只有在进程结束才会释放内存，还给操作系统，由此带来的问题有：
  - 即我不断的开辟小块内存，最后整个堆上的空间都被挂在自由链表上，若我想开辟大块内存就会失败；
  - 若自由链表上挂很多内存块没有被使用，当前进程又占着内存不释放，这时别的进程在堆上申请不到空间，也不可以使用当前进程的空闲内存，由此就会引发多种问题。

##### 3、allocate函数

​		如果要分配的内存大于128字节，就转用第一级分配器，否则也就是小于128字节。那么首先判断落在第几号链表，定位到了，先判断链表是不是空，如果是空就需要充值，（调节到8的倍数，默认一次申请20个区块，当然了也要判断20个是不是能够申请到，如果只申请到一个那就直接返回好了，不止一个的话，把第2到第n个挨个挂到当前链表上，第一个返回回去给容器用,n是不大于20的，当然了如果不在1-20之间，那就是内存碎片了，那就先把碎片挂到某一条链表上，然后再重新malloc了，malloc 2*20个块）去内存池去拿或者重新分配。

##### 4、allocator 和 deallocator

- 第一级配置器直接使用malloc()、free()和relloc()，第二级配置器视情况采用不同的策略：当配置区块超过128bytes时，视之为足够大，便调用第一级配置器；当配置器区块小于128bytes时，为了降低额外负担，使用复杂的内存池整理方式，而不再用一级配置器；
- 第二级配置器主动将任何小额区块的内存需求量上调至8的倍数，并维护16个free-list，各自管理大小为8~128bytes的小额区块；
- 空间配置函数allocate()，首先判断区块大小，大于128就直接调用第一级配置器，小于128时就检查对应的free-list。如果free-list之内有可用区块，就直接拿来用，如果没有可用区块，就将区块大小调整至8的倍数，然后调用refill()，为free-list重新分配空间；
- 空间释放函数deallocate()，该函数首先判断区块大小，大于128bytes时，直接调用一级配置器，小于128bytes就找到对应的free-list然后释放内存。



### 6、关键字

#### 6.1、static和const

##### 1、static

​		**静态变量，存储在全局数据区，其他文件不能使用extern引用static全局变量**

###### 1）隐藏性

​		当编译多个文件时，所有未加static的全局变量和函数都具有全局可见性。

###### 2）保持变量内容的持久：   

​		（**static变量中的记忆功能和全局生存期**）**存储在静态数据区的变量会在程序刚开始就初始化（唯一一次）。共有两种变量存储在静态区：全局变量和静态变量（static变量），static变量可以控制变量的可见范围--隐藏性。

###### 3 ）默认初始化为0

​		static变量和全局变量都具备默认初始化为0。

###### 4）C++中类成员声明static

- **函数体内static局部变量的作用范围为该函数体,不同于auto变量,该变量的内存只被分配一次,因此其值在下次调用时仍维持上次的值;**    
- 在模块内的static全局变量可以被模块内所用函数访问,但不能被模块外其它函数访问;  
- 在模块内的 static函数只可被这一模块内的其它函数调用,这个函数的使用范围被限制在声明它的模块内;  
- 在类中的 static成员变量属于整个类所拥有,对类的所有对象只有一份拷贝;    
- 在类中的static成员函数属于整个类所拥有,这个函数不接收this指针,因而只能访问类的 static成员变量         

**类内：**

- static类对象必须要在类外进行初始化 static修饰的变量先于对象存在,所以 static修饰的变量要在类外初始化; 
- 由于static修饰的类成员属于类,不属于对象,因此 static类成员函数是没有this指针的,this指针是指向本对象的指针。正因为没有this指针,所以 static类成员函数不能访问非static的类成员,只能访问static修饰的类成员; 
- static成员函数不能被virtual修饰, static成员不属于任何对象或实例,所以加上 virtual没有任何实际意义;静态成员函数没有this指针,虚函数的实现是为每一个对象分配一个vptr指针,而vptr是通过this指针调用的,所以不能为 virtual;虚函数的调用关系,this-vptr-vtable--virtual function   

###### 5） static变量初始化问题

​     只能初始化一次，但可多次赋值，在程序执行之前，编译器就已经分配好内存。C++引入对象后，要进行初始化必须执行相应构造函数和析构函数，要在首次使用时才能进行构造，并通过atexit()来管理。在程序结束后，按照相反的方向析构。

###### 6）深究问题

​		原文链接：https://blog.csdn.net/ypshowm/article/details/89030194

###### 7）static的不同形式

- **static局部变量**，数据存储于进程的全局数据区（可以理解为位于函数体内部的全局变量，效果是差不多的，即使函数返回，它的值也会保持不变）

- **static全局变量**，静态全局变量，限制此变量作用域就在一个源文件内，其他文件不能用extern来引用这个文件内的static全局变量。在定义不需要与其他文件共享的全局变量时，加上static关键字可以有效的降低程序模块之间的耦合，避免不同文件同名变量的冲突，并且还不会误用；
- **static函数**，与static全局变量类似，静态函数只能在声明它的文件中可见，其他文件不能引用该函数
- **static数据成员**，在类内数据成员的声明前面加上static关键字，其特点：
  - 静态数据成员存储在全局数据区，静态数据成员在定义时分配存储空间，所以不能在类声明中定义；
  - 静态数据成员是类的成员，无论定义了多少个类的对象，静态数据成员的拷贝只有一个，且对该类的所有对象可见。也就是说对任一对象都可以对静态成员进行操作（一处变了处处就会变），但对于非静态成员，每个对象都有自己的一份拷贝；
  - 静态数据成员在全局数据区，所以它不属于任何对象，在没有任何对象的时候，就可以进行操作（不需要new一个对象）；
  - 静态数据成员也遵循public、protected、private访问规则

- **static成员函数**：静态成员函数不属于某个对象，而是整个类
  - 静态成员函数没有this指针，因为它无法访问属于类对象的非静态成员，也无法访问非静态成员函数，只能调用静态的成员或函数；
  - 非静态成员函数可以任意地访问静态成员函数或静态数据成员。

 **static成员变量与全局变量的区别**：

-  可以实现信息隐藏，通过private成员；
- 静态数据成员不存在与程序中其他全局变量名字冲突的可能性，因为它是类的成员

##### ==static总结==

###### 1）不考虑类的情况

- 隐藏。所有不加static的全局变量和函数具有全局可见性，可以在其他文件中使用，加了之后只能在该文件所在的编译模块中使用
- 默认初始化为0，包括未初始化的全局静态变量与局部静态变量，都存在全局未初始化区
- 静态变量在函数内定义，始终存在，且只进行一次初始化，具有记忆性，其作用范围与局部变量相同，函数退出后仍然存在，但不能使用

###### 2）考虑类的情况

- static成员变量：只与类关联，不与类的对象关联。定义时要分配空间，不能在类声明中初始化，必须在类定义体外部初始化，初始化时不需要标示为static；可以被非static成员函数任意访问。
- static成员函数：不具有this指针，无法访问类对象的非static成员变量和非static成员函数；**不能被声明为const、虚函数和volatile**；可以被非static成员函数任意访问

##### 2、const

###### 1）const指针

- char* const p;                     //指针本身是常量不可变 
- const char* p;                    //指针所指向的内容不可变
- const char* const p;          //两者都不可变

###### 2）const函数

- 传递过来的参数在函数内不可以修改 void func(const int a);//无意义，a本来就是形参
- 参数指针所指内容不可改变   void func(const char* p);
- 参数为引用，增加效率防止修改（引用不会创建副本） void func(const int& a);  //同值传递一模一样
- const修饰成员函数 void func()const;  只能访问const成员变量
- const放在函数前面，修饰的是返回值，表示返回值是一个常量

###### 3）const成员函数

 		任何不会修改数据成员的函数都应该被声明成const。因为const成员函数只能访问const成员遍历，访问了其他的非const，编译器会报错，这样操作可以提高程序的健壮性。

- const对象只能访问const成员函数,而非const对象可以访问任意的成员函数,包括const成员函数.
- const对象的成员是不可修改的（然而const对象通过指针维护的对象却是可以修改的）
- const成员函数不可以修改对象的数据,不管对象是否具有const性质.它在编译时,以是否修改成员数据为依据,进行检查.
- 然而加上mutable（可变的，专门为了突破const而设置的）修饰符的数据成员,对于任何情况下通过任何手段都可修改,自然此时的const成员函数是可以修改它的。这种情况可能是因为mutable修饰的成员变量与类本身并无多少关系，即使修改了也不会对类造成多少影响。（就是说，只是想修改某个成员变量，其他成员变量依然希望被const保护）

###### 4）顶层const和底层const

- **顶层**const：指的是const修饰的变量**本身**是一个常量，无法修改，指的是指针，就是 * 号的右边

- **底层**const：指的是const修饰的变量**所指向的对象**是一个常量，指的是所指变量，就是 * 号的左边

##### ==const总结==

###### 1）不考虑类的情况

- const常量在定义时必须初始化，之后无法更改

- const形参可以接收const和非const类型的实参，例如// i 可以是 int 型或者 const int 型void fun(const int& i){ //...}

###### 2）考虑类的情况

- const成员变量：不能在类定义外部初始化，只能通过构造函数初始化列表进行初始化，并且必须有构造函数；不同类对其const数据成员的值可以不同，所以不能在类中声明时初始化。
- const成员函数：const对象不可以调用非const成员函数；非const对象都可以调用；不可以改变非mutable（用该关键字声明的变量可以在const成员函数中被修改）数据的值。

##### 3、static和const的区别



#### 6.2、define、typedef、inline、const

##### 1、const与#define的区别：

- const定义的常量是变量带类型，而#define定义的只是个常数不带类型；
- define只在预处理阶段起作用，简单的文本替换，而const在编译、链接过程中起作用；
- define只是简单的字符串替换没有类型检查。而const是有数据类型的，是要进行判断的，可以避免一些低级错误；
- define预处理后，占用代码段空间，const占用数据段空间；
-  const不能重定义，而define可以通过#undef取消某个符号的定义，进行重定义；
- define独特功能，比如可以用来防止文件重复引用。

##### 2、#define和别名typedef的区别

- 执行时间不同，typedef在编译阶段有效，typedef有类型检查的功能；#define是宏定义，发生在预处理阶段，不进行类型检查；
- 功能差异，typedef用来定义类型的别名，定义与平台无关的数据类型，与struct的结合使用等。\#define不只是可以为类型取别名，还可以定义常量、变量、编译开关等。
- 作用域不同，#define没有作用域的限制，只要是之前预定义过的宏，在以后的程序中都可以使用。而typedef有自己的作用域。

##### 3、define与inline的区别

- #define是关键字，inline是函数；
- 宏定义在预处理阶段进行文本替换，inline函数在编译阶段进行替换；
- inline函数有类型检查，相比宏定义比较安全；



#### 6.3、struct和class

##### 1、相同点

- 两者都拥有成员函数、公有、私有部分
- 任何可以使用class完成的工作，同样可以使用struct完成

##### 2、不同点

- 两者中如果不对成员不指定公私有，struct默认是公有的，class则默认是私有的
- class默认是private继承，而struct模式是public继承

##### 3、总结

- 实例化一个class，将创建在堆（程序员）上，实例化一个struct，创建在栈上
- 默认的继承权限、访问权限：struct是公有继承（public），class是默认私有继承(private)；
- struct更适合看成是一个数据结构的实现体，class更适合看成一个对象的实现体；
- class是引用类型，struct是值类型，值类型用于存储数据的值，引用类型在于存储对实际数据的引用；则struct就可以直接当成值来使用，class则通过引用来对实际数据进行操作。
- struct在C++进行了扩充，也可以包含成员函数、能继承、能实现多态。其实跟class差不多，就是默认的访问权限问题， class默认是私有，struct默认是公有，这也是为啥默认继承权限是这样的原因。



#### 6.4、final和override

##### 1、final

​		当不希望某个类被继承，或不希望某个虚函数被重写，可以在类名和虚函数后添加final关键字，添加final关键字后被继承或重写，编译器会报错。即**当不希望某个类被继承or 不希望某个虚函数被重写，可以在类名和虚函数后+final**

```c++
class Base
{
    virtual void foo();
};
class A : public Base
{
    void foo() final; // foo 被override并且是最后一个override，在其子类中不可以重写
};
class B final : A // 指明B是不可以被继承的
{
    void foo() override; // Error: 在A中已经被final了
};
class C : B // Error: B is final
{
};
```

##### 2、override

​		当在父类中使用了虚函数时候，你可能需要在某个子类中对这个虚函数进行重写，以下方法都可以：

```c++
class A 
{
    virtual void foo();
};
class B : public A 
{
    void foo();          //OK
    virtual void foo();  // OK
    void foo() override; //OK
};
```

​		如果不使用override，当你手一抖，将**foo()**写成了**f00()**会怎么样呢？结果是编译器并不会报错，因为它并不知道你的目的是重写虚函数，而是把它当成了新的函数。如果这个虚函数很重要的话，那就会对整个程序不利。所以，override的作用就出来了，**它指定了子类的这个虚函数是重写的父类的**，如果你名字不小心打错了的话，编译器是不会编译通过的。

```c++
class A 
{
    virtual void foo();
};
class B : public A 
{
    virtual void f00(); //OK，这个函数是B新增的，不是继承的
    virtual void f0o() override; //Error, 加了override之后，这个函数一定是继承自A的，A找不到就报错
};
```

#### 6.5、overload、override、hide

##### 1、overload重载

- 重载是指在同一范围定义中的同名成员函数才存在重载关系。
- 其特点是函数名相同，参数类型和数目不同（参数类型和数目不能都相同），仅仅根据返回值类型来区分函数。

##### 2、override重写

- 重写是指在派生类中覆盖基类中的同名函数；     
- 重写就是重写函数体，要求基类函数必须是虚函数，且与基类虚函数有相同的参数个数、参数类型、返回值类型。

##### 3、hide隐藏

- 隐藏是指某些情况下，派生类中的函数屏蔽了基类中的同名函数；
- 两个函数参数相同，但基类不是虚函数---**跟重写的区别：基类是否是虚函数**；     
- 两个函数参数不同，无论基类函数是不是虚函数，都会被隐藏---**跟重载区别：两个函数是否在同一个类中**

##### 4、overload 与 override 区别

- 重载是不同函数之间的水平关系，重写是子类与父类的垂直关系；
- 重载要求参数列表不同（返回值没有要求），重写要求参数列表均相同；
- 重载根据调用时实参表与形参表的对应关系选择函数体，重写根据对象类型决定。



#### 6.6、volatile、mutable、explicit

##### 1、volatile

​		volatile 关键字是一种类型修饰符，**用它声明的类型变量表示可以被某些编译器未知的因素更改**，比如：操作系统、硬件或者其它线程等。遇到这个关键字声明的变量，编译器对访问该变量的代码就不再进行优化，从而可以提供对特殊地址的稳定访问。

```c++
//声明时语法
int volatile vInt；
```

​		当要求使用 volatile 声明的变量的值的时候，**系统总是重新从它所在的内存读取数据**，即使它前面的指令刚刚从该处读取过数据。而且读取的数据立刻被保存。

​		**volatile定义变量的值是易变的，每次用到这个变量的值的时候都要去重新读取这个变量的值，而不是读寄存器内的备份。多线程中被几个任务共享的变量需要定义为volatile类型。**

###### 1）volatile指针

​		volatile 指针和 const 修饰词类似，const 有常量指针和指针常量的说法，volatile 也有相应的概念。

- 修饰由指针指向的对象、数据是const或volatile的：

```c++
const char* c;
volatile char* v;
```

- 指针自身的值，即一个代表地址的整数变量是const或volatile的：

```c++
char* const pc;
char* volatile pv;
```

**==注==**

- 可以把一个非volatile int 赋给volatile int，但是不能把非volatile对象赋给一个volatile对象
- 除了基本类型外，对用户定义类型也可以用volatile类型进行修饰
- C++中一个有volatile标识符的类只能访问它接口的子集，一个由类的实现者控制的子集。用户只能用const_cast来获得对类型接口的完全访问。此外，volatile向const一样会从类传递到它的成员。

###### 2）多线程volatile

​		有些变量是用volatile关键字声明的。当两个线程都要用到某一个变量且该变量的值会被改变时，应该用volatile声明，**该关键字的作用是防止优化编译器把变量从内存装入CPU寄存器中**。如果变量被装入寄存器，那么两个线程有可能一个使用内存中的变量，一个使用寄存器中的变量，这会造成程序的错误执行。volatile的意思是让编译器每次操作该变量时一定要从**内存中真正取出**，而不是使用已经存在寄存器中的值。

###### 3）volatile用在如下的几个地方：

- 中断服务程序中修改的供其它程序检测的变量需要加volatile；
- 多任务环境下各任务间共享的标志应该加volatile；
- 存储器映射的硬件寄存器通常也要加volatile说明，因为每次对它的读写都可能由不同意义；

##### 2、mutable

​		mutable：可变的，易变的，跟const是反义词。在C++中，mutable也是为了突破const的限制而设置的。被mutable修饰的变量，将永远处于可变的状态，即使在一个const函数中。我们知道，如果类的成员函数不会改变对象的状态，那么这个成员函数一般会声明成const的。但是，有些时候，我们需要**在const函数里面修改一些跟类状态无关的数据成员，那么这个数据成员就应该被mutable**来修饰，并且放在函数后后面关键字位置。

##### 3、explicit

​		explict关键字用来修饰类的构造函数，**被修饰的构造函数的类，不能发生相应的隐式类型转换**，只能以显示的方式进行类型转换，但需要注意以下几点：

- explict只能用于类内部的构造函数声明上
- explicit作用与单个参数的构造函数
- 被explicit修饰的构造函数的类，不能发生相应的隐式类型转换



#### 6.7、strlen和sizeof

- sizeof是运算符，并不是函数，结果在编译时得到而非运行中获得；strlen是字符处理的库函数。
- sizeof参数可以是任何数据的类型或者数据（sizeof参数不退化）；strlen的参数只能是字符指针且结尾是'\0'的字符串。
- 因为sizeof值在编译时确定，所以不能用来得到动态分配（运行时分配）存储空间的大小。
- sizeof 是一个关键字，同时也是一个运算符，它是一个编译时**运算符**



#### 6.8、cout和printf

##### 1、cout和printf的不同

​		cout<<是一个函数，cout<<后可以跟不同的类型是因为cout<<已存在针对各种类型数据的重载，所以会自动识别数据的类型。输出过程会首先将输出字符放入缓冲区，然后输出到屏幕。

​		cout是有缓冲输出；flush立即强迫缓冲输出；printf是无缓冲输出。有输出时立即输出。

##### 2、printf 实现原理

​		在C/C++中，对函数参数的扫描是从后向前的。C/C++的函数参数是通过压入堆栈的方式来给函数传参数的（堆栈是一种先进后出的数据结构），最先压入的参数最后出来，在计算机的内存中，数据有2块，一块是堆，一块是栈（函数参数及局部变量在这里），而栈是从内存的高地址向低地址生长的，控制生长的就是堆栈指针了，最先压入的参数是在最上面，就是说在所有参数的最后面，最后压入的参数在最下面，结构上看起来是第一个，所以最后压入的参数总是能够被函数找到，因为它就在堆栈指针的上方。printf的第一个被找到的参数就是那个字符指针，就是被双引号括起来的那一部分，函数通过判断字符串里控制参数的个数来判断参数个数及数据类型，通过这些就可算出数据需要的堆栈指针的偏移量了。

#### 6.9、extern

​		extern表明变量或函数是定义在其他文件中的。   可以在**.c中定义变量，然后在.h中使用extern声明变量**，在之后的使用中包含此.h。注意：不要在.h中定义变量！！！！会报错

​		extern是声明，变量可以声明多次，但只可以定义一次。全局变量在外部使用声明时，extern声明是必须的。

- .h中定义一个变量，.c包含这个.h，若不使用extern会报错，未定义这个变量
- 在.c中定义一个变量，在另一个.c文件中引用，是可以输出同一个值的
- extern int a = 5; 与 int a= 5一样，都是定义，但是extern int a；是声明 （在.c中用extern int a = 5定义一个变量，在另一个用extern int a引用，可以是可以，但是会报错）
- 若是想调用另一个.c中的函数，在.c中的函数声明加extern，不加也可以，因为声明全局函数默认前面带有extern 
- **extern和include的区别**：include相当于把.h中所有定义的变量和函数都拷贝了一份放到了.c中,若是在.h中定义了变量，有多个.c包含此.h会出现重复定义的错

##### extern C

​    为了能够**正确的在C++代码中调用C语言**的代码：在程序中加上extern "C"后，相当于告诉编译器这部分代码是C语言写的，因此要按照C语言进行编译，而不是C++；

​    哪些情况下使用extern "C"：（1）C++代码中调用C语言代码；（2）在C++中的头文件中使用；

#### 6.10. enum、union、struct

##### 1、enum枚举    

​      enum枚举，就相当于助记符。枚举是一种单独的数据类型（就是枚举里面都是同类型的变量），默认是Int型，并且从0，1，2，3，...递增排序。可以说枚举是define的替代，一般来说枚举会和switch搭配使用。

 注意事项：

-  枚举量只能赋值给枚举量（Weekday = Sunday），或者枚举量赋值给非枚举量（int a=Monday）不能将其他值赋值给枚举量（Weekday = 10，不允许）；
-  枚举量没有算术运算符，这些操作可能会违反类型限制，就比如说Weekday增加到8，对于这个枚举来说7是无效的；    

##### 2、struct和enum的区别

​    结构体struct可以将有限个不同类型的属性变量组合在一起，enum只能是同种类型的。就是说，enum是枚举，就是某个变量的值是能够列举的，比如，星期的话就每周1到7，月的话就1到12、而struct的话是对于某个变量是有很多数据类型构成一个总体的，比如学生这个变量，他需要学号，姓名，年龄，性别等等，这个时候就需要定义结构体了。

##### 3、union联合

​     联合(Union) 使得同一段内存可以被按照不同的数据类型来访问，数据实际是存储在同一个位置的。它的大小取声明中最长元素的大小，uion中的元素都是指向同一段内存空间，也就是说，改变其中一个元素的值，将会影响所有其他元素的值。

```C++
union mix_t{
    long l;
    struct {
        short hi;
        short lo;
    } s;
    char c[4];
} mix;
```

​		以上例子中定义了3个名称：mix.l, mix.s 和 mix.c，可以通过这3个名字来访问同一段4 bytes长的内存空间。至于使用哪一个名字来访问，取决于想使用什么数据类型，是long, short 还是 char 。

#### 6.11、auto、decltype、decltype(auto)

##### 1、auto

​		C++11新标准引入了auto类型说明符，用它就能让编译器替我们去分析表达式所属的类型。和原来那些只对应某种特定的类型说明符(例如 int)不同，**auto 让编译器通过初始值来进行类型推演。从而获得定义变量的类型，所以说auto定义的变量必须有初始值。**

##### 2、decltype

​		decltype 关键字是为了解决 auto 关键字只能对变量进行类型推导的缺陷而出现的。它的用法和 sizeof 很相似。		

​		有的时候我们还会遇到这种情况，**我们希望从表达式中推断出要定义变量的类型，但却不想用表达式的值去初始化变量。**还有可能是函数的返回类型为某表达式的值类型。在这些时候auto显得就无力了，所以C++11又引入了第二种类型说明符decltype，**它的作用是选择并返回操作数的数据类型。在此过程中，编译器只是分析表达式并得到它的类型，却不进行实际的计算表达式的值。**

##### 3、decltype（auto）

​		decltype(auto)是C++14新增的类型指示符，可以用来声明变量以及指示函数返回类型。在使用时，会将“=”号左边的表达式替换掉auto，再根据decltype的语法规则来确定类型。

```c++
int e = 4;
const int* f = &e;  //f是底层const
decltype(auto) j = f; //j的类型时const int*，并且指向的是e
```

#### 6.12、memcpy、strcpy 和 strnpy 

##### 1、memcpy 和 strcpy区别

- 复制的**内容不同**。strcpy只能复制字符串，而memcpy可以复制任意内容，例如字符数组、整型、结构体、类等。
- 复制的**方法不同**。strcpy不需要指定长度，它遇到被复制字符的串结束符"\0"才结束，所以容易溢出。memcpy则是根据其第3个参数决定复制的长度。
- **用途不同**。通常在复制字符串时用strcpy，而需要复制其他类型数据时则一般用memcpy。

##### 2、strcpy 和 strnpy区别

###### 1）函数原型

```c++
char* strcpy(char* strDest, const char* strSrc)
char* strncpy(char* strDest, const char* strSrc, int pos)
```

###### 2）strcpy和strnpy的区别

- strcpy函数: 如果参数 dest 所指的内存空间不够大，可能会造成缓冲溢出(buffer Overflow)的错误情况，在编写程序时请特别留意，或者用strncpy()来取代。
- strncpy函数：用来复制源字符串的前n个字符，src 和 dest 所指的内存区域不能重叠，且 dest 必须有足够的空间放置n个字符。

###### 3）拷贝情况

- 如果目标长>指定长>源长，则将源长全部拷贝到目标长，自动加上’\0’ 
- 如果指定长<源长，则将源长中按指定长度拷贝到目标字符串，不包括’\0’ 
- 如果指定长>目标长，运行时错误 ；
- 

#### 6.13、default 和 delete(构造函数)

##### 1、default

​		default关键字可以显式要求编译器生成合成构造函数，防止在调用时相关构造函数类型没有定义而报错。

##### 2、delete

​		delete关键字可以删除构造函数、赋值运算符函数等，这样在使用的时候会得到友善的提示。

```c++
class MyString
{
 public:
    MyString() = default;
    MyString(const char* pstr) : _str(pstr){} //构造函数
    void* operator new() = delete; //不允许这样使用new关键字
    ~MyString(){} //析构函数
 private:
    string _str;
}
```

​		如果没有加语句1，语句2会报错，表示找不到参数为空的构造函数，将其设置为default可以解决这个问题。在执行语句1时，会提示new方法已经被删除，如果将new设置为私有方法，则会报惨不忍睹的错误，因此使用delete关键字可以更加人性化的删除一些默认方法.



### 7、this指针

#### 7.1、this指针概念、用处、使用

##### 1、什么是this指针？

- this指针是**类**的指针，指向对象的**首地址**。

- this指针只能在**成员函数**中使用，在全局函数、静态成员函数中都不能用this。

- this指针只有在成员函数中才有定义，且存储位置会因编译器不同有不同存储位置

##### 2、this指针用处

​		一个对象的this指针并不是对象本身的一部分，不会影响 sizeof(对象) 的结果。this作用域是在类内部，当在类的**非静态成员函数**中访问类的**非静态成员**的时候（全局函数，静态函数中不能使用this指针），编译器会自动将对象本身的地址作为一个隐含参数传递给函数。也就是说，即使你没有写上this指针，编译器在编译的时候也是加上this的，它作为非静态成员函数的隐含形参，对各成员的访问均通过this进行。

##### 3、this指针的使用

​		一种情况就是，在类的非静态成员函数中返回类对象本身的时候，直接使用 return *this；

​		另外一种情况是当形参数与成员变量名相同时用于区分，如this->n = n （不能写成n = n）

##### 4、类的this指针有以下特点

- **this**只能在成员函数中使用，全局函数、静态函数都不能使用this。实际上，**成员函数默认第一个参数**为**T * const this**

```c++
class A{public: int func(int p){}}; 
//func的原型在编译器看来应该是
//int func(A* const this, int p)
```

- 由此可见，**this**在成员函数的开始前构造，在成员函数的结束后清除。这个生命周期同任何一个函数的参数是一样的，没有任何区别。当调用一个类的成员函数时，编译器将类的指针作为函数的this参数传递进去。

```c++
A a;a.func(10);//此处，编译器将会编译成：A::func(&a,10);
```

​		看起来和静态函数没差别，对吗？不过，区别还是有的。编译器通常会对this指针做一些优化，因此，this指针的传递效率比较高，例如VC通常是通过ecx（计数寄存器）传递this参数的。



#### 7.2、this指针的创建、存储位置？

##### 1、this指针是什么时候创建的？

​		this在成员函数的开始执行前构造，在成员的执行结束后清除。

​		但是如果class或者struct里面没有方法的话，它们是没有构造函数的，只能当做C的struct使用。采用TYPE xx的方式定义的话，在栈里分配内存，这时候this指针的值就是这块内存的地址。采用new的方式创建对象的话，在堆里分配内存，new操作符通过eax（累加寄存器）返回分配的地址，然后设置给指针变量。之后去调用构造函数（如果有构造函数的话），这时将这个内存块的地址传给ecx，之后构造函数里面怎么处理请看7.3的回答。

##### 2、 this指针存放在何处？堆、栈、全局变量，还是其他？

​		this指针会因编译器不同而有不同的放置位置。可能是栈，也可能是寄存器，甚至全局变量。在汇编级别里面，一个值只会以3种形式出现：立即数、寄存器值和内存变量值。不是存放在寄存器就是存放在内存中，它们并不是和高级语言变量对应的。

##### 3、this指针调用成员变量时，堆栈会发生什么变化？

​		当在类的非静态成员函数访问类的非静态成员时，编译器会自动将对象的地址传给作为隐含参数传递给函数，这个隐含参数就是this指针。

​		即使你并没有写this指针，编译器在链接时也会加上this的，对各成员的访问都是通过this的。

​		例如你建立了类的多个对象时，在调用类的成员函数时，你并不知道具体是哪个对象在调用，此时你可以通过查看this指针来查看具体是哪个对象在调用。This指针首先入栈，然后成员函数的参数从右向左进行入栈，最后函数返回地址入栈。



#### 7.3、this指针在类中的使用

##### 1、this指针是如何传递类中的函数的？绑定？还是在函数参数的首参数就是this指针？那么，this指针又是如何找到“类实例后函数的？

​		大多数编译器通过ecx（寄数寄存器）寄存器传递this指针。事实上，这也是一个潜规则。一般来说，不同编译器都会遵从一致的传参规则，否则不同编译器产生的obj就无法匹配了。在call之前，编译器会把对应的对象地址放到eax中。this是通过函数参数的首参来传递的。this指针在调用之前生成，至于“类实例后函数”，没有这个说法。类在实例化时，只分配类中的变量空间，并没有为函数分配空间。自从类的函数定义完成后，它就在那儿，不会跑的。

##### 2、this指针是如何访问类中的变量的？

​		如果不是类，而是结构体的话，那么，如何通过结构指针来访问结构中的变量呢？如果你明白这一点的话，就很容易理解这个问题了。

​		在C++中，类和结构是只有一个区别的：类的成员默认是private，而结构是public。

​		this是类的指针，如果换成结构体，那this就是结构的指针了。

##### 3、我们只有获得一个对象后，才能通过对象使用this指针。如果我们知道一个对象this指针的位置，可以直接使用吗？

​		**this指针只有在成员函数中才有定义**。因此，你获得一个对象后，也不能通过对象使用this指针。所以，我们无法知道一个对象的this指针的位置（只有在成员函数里才有this指针的位置）。当然，在成员函数里，你是可以知道this指针的位置的（可以通过&this获得），也可以直接使用它。

##### 4、每个类编译后，是否创建一个类中函数表保存函数指针，以便用来调用函数？

​		普通的类函数（不论是成员函数，还是静态函数）都不会创建一个函数表来保存函数指针。只有虚函数才会被放到函数表中。但是，即使是虚函数，如果编译期就能明确知道调用的是哪个函数，编译器就不会通过函数表中的指针来间接调用，而是会直接调用该函数。正是由于this指针的存在，用来指向不同的对象，从而确保不同对象之间调用相同的函数可以互不干扰。



#### 7.4、delete this相关问题

##### 1、在成员函数中调用delete this会出现什么问题？对象还可以使用吗？

​		在类对象的内存空间中，只有数据成员和虚函数表指针，并不包含代码内容，类的成员函数单独放在代码段中。在调用成员函数时，隐含传递一个this指针，让成员函数知道当前是哪个对象在调用它。当调用delete this时，类对象的内存空间被释放。在delete this之后进行的其他任何函数调用，只要不涉及到this指针的内容，都能够正常运行。一旦涉及到this指针，如操作数据成员，调用虚函数等，就会出现不可预期的问题。

##### 2、为什么是不可预期的问题？

​		delete this之后不是释放了类对象的内存空间了么，那么这段内存应该已经还给系统，不再属于这个进程。照这个逻辑来看，应该发生指针错误，无访问权限之类的令系统崩溃的问题才对啊？这个问题牵涉到操作系统的内存管理策略。delete this释放了类对象的内存空间，但是内存空间却并不是马上被回收到系统中，可能是缓冲或者其他什么原因，导致这段内存空间暂时并没有被系统收回。此时这段内存是可以访问的，你可以加上100，加上200，但是其中的值却是不确定的。当你获取数据成员，可能得到的是一串很长的未初始化的随机数；访问虚函数表，指针无效的可能性非常高，造成系统崩溃。

##### 3、如果在类的析构函数中调用delete this 会发生什么？

​		会导致堆栈溢出。原因很简单，delete的本质是“为将被释放的内存调用一个或多个析构函数，然后，释放内存”。显然，delete this会去调用本对象的析构函数，而析构函数中又调用delete this，形成无限递归，造成堆栈溢出，系统崩溃。



### 8、模板相关问题

#### 8.1、为什么模板类一般都放在一个h文件中？

1、模板定义很特殊。由template<…>处理的任何东西都意味着编译器在当时不为它分配存储空间，它一直处于等待状态直到被一个模板实例告知。在编译器和连接器的某一处，有一机制能去掉指定模板的多重定义。

​		所以为了容易使用，几乎总是在头文件中放置全部的模板声明和定义。

2、在分离式编译的环境下，编译器编译某一个.cpp文件时并不知道另一个.cpp文件的存在，也不会去查找（当遇到未决符号时它会寄希望于连接器）。这种模式在没有模板的情况下运行良好，但遇到模板时就傻眼了，因为模板仅在需要的时候才会实例化出来。

​		所以，当编译器只看到模板的声明时，它不能实例化该模板，只能创建一个具有外部连接的符号并期待连接器能够将符号的地址决议出来。然而当实现该模板的.cpp文件中没有用到模板的实例时，编译器懒得去实例化，所以，整个工程的.obj中就找不到一行模板实例的二进制代码，于是连接器也黔驴技穷了。

#### 8.2、模板函数和模板类的特例化

##### 1、原因

​		编写单一的模板，它能适应多种类型的需求，使每种类型都具有相同的功能，但对于某种特定类型，如果要实现其特有的功能，单一模板就无法做到，这时就需要模板特例化。

##### 2、模板函数特例化

###### 1）定义

​		对单一模板提供的一个特殊实例，它将一个或多个模板参数绑定到特定的类型或值上。必须为原函数模板的每个模板参数都提供实参，且使用关键字template后跟一个空尖括号对<>，表明将原模板的所有模板参数提供实参。

```c++
template<typename T> //模板函数
int compare(const T &v1,const T &v2) {
    if(v1 > v2) return -1;
    if(v2 > v1) return 1;
    return 0;
}
//模板特例化,满足针对字符串特定的比较，要提供所有实参，这里只有一个T
template<>
int compare(const char* const &v1,const char* const &v2) {
    return strcmp(p1,p2);
}
```

###### 2）本质

​		特例化的本质是实例化一个模板，而非重载它。特例化不影响参数匹配。参数匹配都以最佳匹配为原则。例如，此处如果是compare(3,5)，则调用普通的模板，若为compare(“hi”,”haha”)则调用**特例化版本**（因为这个cosnt char*相对于T，更匹配实参类型），注意二者函数体的语句不一样了，实现不同功能。

###### 3）注意

​		模板及其特例化版本应该声明在同一个头文件.h中，且所有同名模板的声明应该放在前面，后面放特例化版本。

##### 3、类模板特例化

​		原理类似函数模板，**不过在类中，我们可以对模板进行特例化，也可以对类进行部分特例化。**对类进行特例化时，仍然用template<>表示是一个特例化版本。

```c++
template<>
class hash<sales_data> {
    size_t operator()(sales_data& s);
 //里面所有T都换成特例化类型版本sales_data
 //按照最佳匹配原则，若T != sales_data，就用普通类模板，否则，就使用含有特定功能的特例化版本。
};
```

##### 4、类模板部分特例化

​		不必为所有模板参数提供实参，可以**指定一部分而非所有模板参数**，一个类模板的部分特例化本身仍是一个模板，使用它时还必须为其特例化版本中未指定的模板参数提供实参(特例化时类名一定要和原来的模板相同，只是参数类型不同，按最佳匹配原则，哪个最匹配，就用相应的模板)。

​		**特例化类中的部分成员可以特例化类中的部分成员函数而不是整个类**。

#### 8.3、函数模板

##### 1、函数模板

​		建立一个通用函数，函数的返回值类型和形参类型不具体限制，用一个虚拟的类型来表示。 它的语法：**template < typename T>**  **template** 声明创建模板；**typename** 表明其后面的符号是一种数据类型，可用class代替；**T** 通用数据类型，名称可替换。使用就是自动类型推导，显式制定类型，就是使用一次函数模板就要在之前加一个template < typename T>声明一个模板，告诉编译器后面代码中紧跟着的T不要报错，T是一个通用数据类型。

​		**注意**：自动类型推导，必须推导出一致的数据类型T，才可以使用。

```c++
template<类型形式参数表>
类型 函数名（形式参数表）
{
    语句序列
}
```

- 函数模板定义由模板说明和函数定义组成
- 模板说明的类属参数必须在函数定义中至少出现一次
- 函数参数表中可以使用类属类型参数，也可以使用一般类型参数

###### 1）当函数模板遇到函数重载

- 函数模板与普通函数的区别：函数模板是不允许自动类型转换的，二欧通函数允许自动类型转换。
- 当函数模板和普通函数在一起时，调用规则如下：
  - 函数模板可以像普通函数一样被重载
  - C++编译器有限考虑普通函数
  - 如何函数模板可以产生一个更好的匹配，则选择模板
  - 可以通过空模板实参列表的语法，限定编译器只通过模板匹配

###### 2）函数模板与普通函数的区别

- 普通函数调用时可以发生自动类型转换（隐式类型转换）；（就是本来定义的时候是char型，但是函数的参数是int型，调用函数会发生类型转换，char变成Int）

- 函数模板调用时，如果利用自动类型推导，不会发送隐式类型转换；

- 如果利用显示指定类型的方式，可以发生隐式类型转换

  **建议使用函数模型时，显示指定类型eg: myAdd02<int>(a,c)**

##### 2、实现原理

​		编译器并不是把函数模板处理成能够处理任意类的函数；编译器从函数模板通过具体类型产生不同的函数；编译器会对函数模板进行**两次编译**：**在声明的地方对模板代码本身进行编译，在调用的地方对参数替换后的代码进行编译**。函数模板使用后，编译器并不会一开始就生成所有处理任何类型的函数，而是通过实际的函数调用来生成。比如调用函数时，需要处理int型数据，就生成处理int型数据的函数，而没有用double型数据，就不会生成处理double型数据的函数

​		这是因为函数模板要被**实例化**后才能成为真正的函数，在使用函数模板的源文件中包含函数模板的头文件，如果该头文件中只有声明，没有定义，那编译器无法实例化该模板，最终导致链接错误。

#### 8.4、类模板

​		类模板允许用户为类定义一种模式，使得类中的某些数据成员、成员函数的参数、  成员函数的返回值，可以取到任意类型。就比如说一个类中数据成员的数据类型不能确定，或者是某个成员函数的参数或返回值的类型不能确定，就必须将此类声明为模板，它的存在不是代表一个具体的、实际的类，就是代表着一类类。因为它的类型在调用的时候才确定，所以模板类中的成员函数在调用时才创建。

##### 1、类模板与继承

​		当子类继承的父类是一个类模板时，子类在声明的时候，要指定出父类中T的类型；如果想灵活指定出父类中T的类型，子类也需变为类模板。

​		template < class T > (复杂数据类型）和template < typename T >（基础数据类型），特例，当T是一个类而这个类又有子类时，应该使用typename，class会产生语法错误。

#####   2、类模板与函数模板的区别

- 类模板没有自动类型推导的使用方式，类模板只能用显示指定类型的方式实例化，故需要在<>中提供类型；

```c++
vector<int>v;
```



- 类模板在模板参数列表中可以有默认参数；

- 函数模板和类模板的区别，就是在template < typename T>后面添加的是函数还是类。

- 使用类模板时必须在类模板名后面的尖括号中提供额外信息——用来代替模板的实参列表

#### 8.5、模板什么时候实例化？

​		只有当代码中使用了模板的实列的名字，并且上下文环境要求必须存在模板的定义时，这个模板才会被实例化。其实就是可以确定模板的数据类型的时候，会导致实例化。比如：

- 声明一个类模板的指针和引用，不会引起实例化，因为还不知道类的定义；
- 定义一个类类型的对象时，会实例化，因为此时需要类的定义了；
- 在使用sizeof()的时候，因为是计算对象的大小，所以也会实例化；
- 引用类模板的成员也会导致实例化。





## 二、数据结构

### 1、二叉树

#### 1.1、平衡二叉树、搜索二叉树、完全二叉树

##### 1、定义

- 左右子树都是平衡二叉树（左子叶<根节点<右子叶），且左右子树的深度差的绝对值不大于1。（平衡二叉树本质是搜索二叉树）
- 树的深度为logn,查找、插入、删除的时间均为logn。
- 平衡因子BF为该节点左子树深度减去右子树深度，将距离结点最近的，且平衡因子的绝对值大于1的结点为根的子树，称为最小不平衡子树
- 因为输入值不够随机，或者因为经过某些插入和删除操作，二叉搜索树可能会失去平衡，造成搜寻效率低落的情况。

##### 2、插入新结点、平衡操作

- 最小不平衡子树的BF与它的子树的BF符号相同时：最小不平衡子树根节点的平衡因子大于1时（小于1时），右旋（左旋）
- 最小不平衡子树的BF与它的子树的BF符号相反时：先对子树结点进行一次旋转使得符号相同，然后再反向旋转一次完成平衡操作

##### 3、删除结点：

​     删除结点后，从根节点到该节点的路径上的平衡因子都有可能改变，所以删除操作最多需要进行logn次旋转。

##### 4、搜索二叉树

它的左子树不空，则左子树上所有结点的值均小于它的根结点的值；
若它的右子树不空，则右子树上所有结点的值均大于它的根结点的值；

##### 5、完全二叉树

若设二叉树的深度为h，除第 h 层外，其它各层 (1～h-1) 的结点数都达到最大个数，第 h 层所有的结点都连续集中在最左边。
经典应用：堆

#### 1.2、红黑树

​	红黑树是一个**二叉排序树**，继承二叉排序树的显性特性：

- 若左子树不空，则左子树上所有结点的值均小于或等于它的根结点的值。
- 若右子树不空，则右子树上所有结点的值均大于或等于它的根结点的值。
- 左、右子树也分别为二叉排序树

##### 1、红黑树需要满足的条件：

- 树的节点非红即黑；
- 根节点必须是黑色；
- 红节点的子节点必为黑（黑节点子节点可为黑）；
- 如果一个结点是红的，那么两个儿子都是黑的；
- 对于每个结点，从该结点到其子孙结点的所有路径上包含相同数目的黑节点（从根到nullptr的任何路径上的黑节点数目相同）。

##### 2、插入和删除操作

​		插入和删除操作都需要根据红黑树的性质，进行对应的**旋转和调整**。

插入：根据红黑树的性质 ，说明插入的结点初始色要为红色  ==不是很理解==

- 要是父节点（存在）是黑色的话，则插入成功，不需要改变；
- 要是父节点（存在）是红色的话，并且是祖父的左子结点，会违反性质

​        如果叔结点为红色，将祖父结点调整为红，父结点和叔结点调整为黑色，然后从祖父结点递归调整一下，直到根结点。如果碰巧将根节点染成了红色, 可以在最后强制 root->黑。

​         叔结点为黑色，且当前节点是右孩子，需要右旋

​         叔结点为黑色，且当前节点是左孩子，需要左右旋

- 如果父结点（存在）是红色的话，且是祖父的右子结点，此时说明性质4会违反      


​        叔结点为红色，将祖父结点调整为红，父结点和叔结点调整为黑色，然后从祖父结点递归调整一下，直到根结点。如果碰巧将根节点染成了红色, 可以在最后强制 root->黑。

​       叔结点为黑色，且当前节点是右孩子，需要左旋

​       叔结点为黑色，且当前节点是左孩子，需要右左旋

#### ==总结==红黑树比AVL（平衡二叉搜索树）的优势

第一种回答：

​		首先红黑树是不符合AVL树的平衡条件的，即每个节点的左子树和右子树的高度最多差1的二叉查找树。但是提出了为节点增加颜色，**红黑是用非严格的平衡来换取增删节点时候旋转次数的降低**，任何不平衡都会在**三次旋转**之内解决，而AVL是严格平衡树，因此在增加或者删除节点的时候，根据不同情况，旋转的次数比红黑树要多。所以红黑树的插入效率更高！！！

第二种回答：

​		红黑树的 查询性能略微逊色于AVL树，因为他比AVL树会稍微不平衡最多一层，也就是说红黑树的查询性能只比相同内容的AVL树最多多一次比较，但是，红黑树在插入和删除上完爆AVL树， AVL树每次插入删除会进行大量的平衡度计算，而红黑树为了维持红黑性质所做的红黑变换和旋转的开销，相较于AVL树为了维持平衡的**开销要小**得多。

第三种回答：

- 如果插入一个node引起了树的不平衡，AVL和RB-Tree都是最多只需要2次旋转操作，即两者都是O(1)；但是在删除node引起树的不平衡时，最坏情况下，AVL需要维护从被删node到root这条路径上所有node的平衡性，因此需要旋转的量级O(logN)，而RB-Tree最多只需3次旋转，只需要O(1)的复杂度。
- 其次，AVL的结构相较RB-Tree来说更为平衡，在插入和删除node更容易引起Tree的unbalance，因此在大量数据需要插入或者删除时，AVL需要rebalance的频率会更高。因此，RB-Tree在需要大量插入和删除node的场景下，效率更高。自然，由于AVL高度平衡，因此AVL的search效率更高。
- map的实现只是折衷了两者在search、insert以及delete下的效率。总体来说，RB-tree的统计性能是高于AVL的。

原文链接：https://blog.csdn.net/mmshixing/article/details/51692892

**==重点==第四种回答：**

- 红黑树不追求"完全平衡"，即不像AVL那样要求节点的 `|balFact| <= 1`，它只要求部分达到平衡，但是提出了为节点增加颜色，**红黑是用非严格的平衡来换取增删节点时候旋转次数的降低，任何不平衡都会在三次旋转之内解决**，而AVL是严格平衡树，因此在增加或者删除节点的时候，根据不同情况，旋转的次数比红黑树要多。

- 就插入节点导致树失衡的情况，AVL和RB-Tree都是最多两次树旋转来实现复衡rebalance，旋转的量级是O(1)；
  删除节点导致失衡，AVL需要维护从被删除节点到根节点root这条路径上所有节点的平衡，旋转的量级为O(logN)，而RB-Tree最多只需要旋转3次实现复衡，只需O(1)，所以说RB-Tree删除节点的rebalance的效率更高，开销更小！

- AVL的结构相较于RB-Tree更为平衡，插入和删除引起失衡，如2所述，RB-Tree复衡效率更高；当然，由于AVL高度平衡，因此AVL的Search效率更高啦。

- 针对插入和删除节点导致失衡后的rebalance操作，红黑树能够提供一个比较"便宜"的解决方案，降低开销，是对search，insert ，以及delete效率的折衷，总体来说，RB-Tree的统计性能高于AVL.

- 故引入RB-Tree是**功能、性能、空间开销的折中结果**。

  - AVL更平衡，结构上更加直观，时间效能针对读取而言更高；维护稍慢，空间开销较大。
  - 红黑树，读取略逊于AVL，维护强于AVL，空间开销与AVL类似，内容极多时略优于AVL，维护优于AVL。
  - **红黑树与 AVL 树相比，其通过牺牲查询效率来提升插入、删除效率。**
  - 红黑树在二叉查找树的基础上增加了着色和相关的性质使得红黑树相对平衡，从而保证了红黑树的查找、插入、删除的时间复杂度最坏为 O(log n)。

  基本上主要的几种平衡树看来，**红黑树有着良好的稳定性和完整的功能，性能表现也很不错，综合实力强**，在诸如STL的场景中需要稳定表现。
  
  

#### 1.3、B树

 		B树也是B-树，是多路平衡查找树，它每个节点最多有m-1个关键字，根节点最少可以只有1个关键字，非根节点至少有m/2个关键字，每个节点中的关键字都按照从小到大的顺序排列，每个关键字的左子树中的所有关键字都小于它，右子树中的所有关键字都大于它。根节点到每个叶子节点的长度都相同，每个节点都存有索引和数据（key和value）。

#### 1.4、B+树

​		B和B+树其实非常相似

​		**相同点**：根节点都是至少一个元素，非根节点元素范围：m/2 <= k <= m-1(K 节点数，m是阶数)。

​		但是B+树右两种类型的节点：内部节点和叶子结点，内部结点就是非叶子结点，内部结点不存储数据，只存储索引，数据都存储在叶子结点。内部结点中的key都按照从小到大的顺序排列，对于内部结点的Key，左树中的所有key都小于它，右树中的key都大于等于它，叶子结点中的记录也按照Key的大小排序。

​		在B+Tree中，所有数据节点都是按照键值大小存放在同一层的叶子结点上，而非叶子节点上只存储key值信息，这样可以大大加大每个节点存储的key值数量，降低B+Tree的高度。我们知道IO次数取决于B+数的高度h，假设当前数据表的数据为N，每个磁盘块的数据项的数量是m，则有h=㏒(m+1)N，当数据量N一定的情况下，m越大，h越小；而m = 磁盘块的大小 / 数据项的大小，磁盘块的大小也就是一个数据页的大小，是固定的，如果数据项占的空间越小，数据项的数量越多，树的高度越低

​        所以综上，B+树其实是改进了B树，让内节点只做为索引使用，去掉了其中指向data record的指针，使得每个结点中都能够存放更多的key，因此可以右更大的出度。这样就意味着，存放同样多的key，树的层高可以被进一步的压缩，让检索的时间更短。

​	**B树和B+树的不同：**

- 非叶子结点只存储键值信息；
- 所有叶子结点之间都有一个链指针；
- 数据记录都存放在叶子节点中。



#### ==总结==AVL、RB-tree、B、B+

- AVL：平衡二叉树，一般是用平衡因子差值决定并通过旋转来实现，左右子树树高差不超过1，那么和红黑树比较它是严格的平衡二叉树，平衡条件非常严格（树高差只有1），只要插入或删除不满足上面的条件就要通过旋转来保持平衡。由于旋转是非常耗费时间的。我们可以推出**AVL树适合用于插入删除次数比较少，但查找多的情况**。

- RB-tree：通过对任何一条从根到叶子的简单路径上各个节点的颜色进行约束，确保没有一条路径会比其他路径长2倍，因而是近似平衡的。所以相对于严格要求平衡的AVL树来说，它的旋转保持平衡次数较少。**用于搜索时，插入删除次数多**的情况下我们就用红黑树来取代AVL。

- B：它们特点是一样的，是**多路查找树**，一般用于数据库系统中，为什么，因为它们分支多层数少呗，都知道磁盘IO是非常耗时的，而像大量数据存储在磁盘中所以我们要有效的减少磁盘IO次数避免磁盘频繁的查找。

- B+：B+树是B树的变种树，有n棵子树的节点中含有n个关键字，每个关键字不保存数据，只用来**索引**，数据都保存在叶子节点。是为文件系统而生的。



#### 1.5、为什么MySQL索引要使用B+树，而不是B树或者红黑树？

​		我们在MySQL中的数据一般是放在磁盘中的，读取数据的时候肯定会有访问磁盘的操作，磁盘中有两个机械运动的部分，分别是盘片旋转和磁臂移动。盘片旋转就是我们市面上所提到的多少转每分钟，而磁盘移动则是在盘片旋转到指定位置以后，移动磁臂后开始进行数据的读写。那么这就存在一个定位到磁盘中的块的过程，而定位是磁盘的存取中花费时间比较大的一块，毕竟机械运动花费的时候要远远大于电子运动的时间。当大规模数据存储到磁盘中的时候，显然定位是一个非常花费时间的过程，但是我们可以通过**B树进行优化**，提高磁盘读取时定位的效率。

#### 1.6、为什么B类树可以进行优化呢？

​		我们可以根据B类树的特点，构造一个多阶的B类树，然后在尽量多的在结点上存储相关的信息，**保证层数（树的高度）尽量的少**，以便后面我们可以更快的找到信息，**磁盘的I/O操作也少一些**，而且B类树是平衡树，每个结点到叶子结点的高度都是相同，这也保证了每个查询是稳定的。

​		**特别地：**只有B-树和B+树，这里的B-树是叫B树，不是B减树，没有B减树的说法**

#### 1.7、为什么MySQL索引要使用B+树，而不是B树或者hash表？

- 利用Hash需要把数据全部**加载到内存中**，如果数据量大，是一件很**消耗内存**的事，而采用B+树，是基于**按照节点分段加载，由此减少内存消耗**。

- 和业务场景有段，**对于唯一查找**（查找一个值），Hash确实更快，**但数据库中经常查询多条数据**，这时候由于B+数据的有序性，与叶子节点又有链表相连，他的查询效率会比Hash快的多。
- B+树的**非叶子节点不保存数据**，**只保存子树的临界值**（最大或者最小），所以同样大小的节点，**B+树相对于b树能够有更多的分支，使得这棵树更加矮胖，查询时做的IO操作次数也更少**。*所以一般情况下，我们用到的B+树都不会超过4层*

#### 1.8、既然Hash比B+树更快，为什么MySQL用B+树来存储索引呢？

​		MySQL中存储索引用到的数据结构是B+树，B+树的查询时间跟树的高度有关，是log(n)，如果用hash存储，那么查询时间是O(1)。

​		采用Hash来存储确实要更快，但是采用B+树来存储索引的原因主要有以下几点：

- **从内存角度上说**，数据库中的索引一般是在磁盘上，数据量大的情况可能无法一次性装入内存，B+树的设计可以允许数据分批加载。
- **从业务场景上说**，如果只选择一个数据那确实是hash更快，但是数据库中经常会选中多条，这时候由于B+树索引有序，并且又有链表相连，它的查询效率比hash就快很多了。
- hash索引仅满足=、>、<和IN查询。如果进行范围查询，哈希索引的时间复杂度会退化为O（n);而树的有序特性，依然能够保持log(n)的高效率。如果Hash的等值查询中，索引列的重复值很多，效率也会降低。因为开链法需要遍历桶中的元素一个个去对比。

#### 1.9、树的存储结构

##### 1、双亲表示法

​		以双亲作为索引的关键词的一种存储方式。假设以一组连续空间存储数的结点，同时在每个结点中，**附设一个指示器指示其双亲结点到链表中的位置**。

​		双亲表示的**结点结构**：

|    data(数据域)    |          parent(指针域)          |
| :----------------: | :------------------------------: |
| 存储结点的数据信息 | 存储该结点的双亲所在数组中的下标 |

​		双亲表示法的**特点**：

- 由于**根结点是没有双亲的**，约定根结点的位置位置域为-1.
- 根据结点的`parent`指针**很容易找到它的双亲结点**。所用时间复杂度为O(1)，直到parent为-1时，表示找到了树结点的根。
- 缺点：如果要找到孩子结点，**需要遍历整个结构才行**。

##### 2、孩子表示法

​		由于每个结点可有多个子树（无法确定子树个数），可以考虑使用多重链表来实现。把每个结点的孩子结点排列起来，以**单链表作为存储结构**，则n个结点有n个孩子链表，如果是叶子结点则此单链表为空。然后**n个头指针又组成一个线性表，采用顺序存储结构**，存放进一个一维数组中。

​		孩子表示法有两种结点结构：**孩子链表的孩子结点**和**表头数组的表头结点**：

- 孩子链表的孩子结点

|         child(数据域)          |             next(指针域)             |
| :----------------------------: | :----------------------------------: |
| 存储某个结点在表头数组中的下标 | 存储指向某结点的下一个孩子结点的指针 |

- 表头数组的表头结点

|      data(数据域)      |     firstchild(头指针域)     |
| :--------------------: | :--------------------------: |
| 存储某个结点的数据信息 | 存储该结点的孩子链表的头指针 |

##### 3、双亲孩子表示法定义

​		对于孩子表示法，查找某个结点的某个孩子，或者找某个结点的兄弟，只需要查找这个结点的孩子单链表即可。但是**当要寻找某个结点的双亲时**，就不是那么方便了。所以可以将双亲表示法和孩子表示法结合，形成**双亲孩子表示法**。

##### 4、孩子兄弟表示法

​		任意一棵树，它的结点的第一个孩子如果存在就是唯一的，它的右兄弟存在也是唯一的。因此，设置两个指针，分别指向该结点的第一个孩子和此结点的右兄弟。

​		孩子兄弟表示法的**结点结构**：

|    data(数据域)    |        firstchild(指针域)        |         rightsib(指针域)         |
| :----------------: | :------------------------------: | :------------------------------: |
| 存储结点的数据信息 | 存储该结点的第一个孩子的存储地址 | 存储该结点的右兄弟结点的存储地址 |



### 2、map底层实现

#### 2.1、map底层为什么用红黑树

​       map,set底层都提供了排序功能，且查找速度快。红黑树实际上是AVL的一种变形（低配版，尽量维持了树的平衡，平衡二叉树是严格平衡的，需要频繁的rebalance，导致效率低下），红黑树通过对任意一条从根到叶子的路径上各个结点着色方式的限制，确保没有一条路径会比其他路径长两倍，是弱平衡的，插入最多旋转2次，删除最多旋转3次，所以它可以在O(log n)时间内做查找，插入和删除，有较高的效率。

#### 2.2、map和set

​      map是key_value键值对，set是单值，他们都是按照顺序排序，但是set不允许修改key，并且值不重复。    

#### 2.3、为什么用红黑树？

​		因为map和set要求是**自动排序**的，红黑树能够实现这一功能，而且时间复杂度比较低。



###   3、unordered_map 和 map

​      都是存储的key-value的值，可以通过key快速索引到value。unordered_map不会根据key的大小进行排序，存储时根据key的hash判断元素是否相同，unordered_map内部元素是无序的底层由哈希表实现，map中的元素是按照红黑树进行的存储。

​     unordered_map 用链表散列的存储方式，频繁在大量数据中查询，速度几乎是常数级别，所以比起map搜索速度快（红黑树实现，查找速度O(logn))。

​    unordered_map和map，红黑树（每个节点都额外保存父节点、孩子节点和红黑性质，其实占空间也蛮大的）和哈希表（链表散列空间会存在部分未被使用的位置，所以内存效率不是100%），还是unorderd_map内存占用高。同时还有一点就是，因为unorded_map这样的容器，其遍历顺序与创建该容器时输入的顺序不一定相同，因为遍历是按照哈希表从前往后依次遍历的。

​    综上，对有顺序要求的问题且需要元素有序，用map。但是查找问题，还是unorded_map高效。但是查找性能的稳定性，还是map高，因为map的查找是类似于平衡二叉树的查找，查找次数与存储数据的分布和大小无关。unordered_map的查找次数与存储数据的分布与大小有密切关系，所以unordered_map还是适用于要求查找速率快，且对单次查询性能要求不敏感的场景。

### 4、unordered_set和set

​     set基于红黑树实现，红黑树具有自动排序功能，内部数据在任何时候都是有序的。

​     unordered_set内部基于哈希表，数据插入和查找时间复杂度很低，几乎为常数级别，但是会消耗较多的内存，无自动排序功能。底层上，使用一个下标范围较大的数组来存储元素，就相当于形成很多的桶，利用哈希函数对key进行映射存储。unordered_set这样的容器，其遍历顺序与创建该容器时输入的顺序不一定相同，因为遍历是按照哈希表从前往后依次遍历的。

### 5、二分查找与二叉树查找 

​		时间复杂度**O(logN)**

#### 5.1、二分查找

​		二分查找：即折半查找，优点是比较次数少，查找速度快，平均性能好；其缺点是要求待查表为有序表，且插入删除困难

#### 5.2、二叉树查找

​		二叉树查找：它或者是一棵空树，或者若它的左子树不空，则左子树上所有结点的值均小于它的根结点的值；
​		若它的右子树不空，则右子树上所有结点的值均大于它的根结点的值； 它的左、右子树也分别为二叉排序树。

#### 5.3、二分查找与二叉树查找的区别

​		两者明显的区别是二分查找速度快删除和插入困难，二对于建立的二叉树索引来说，他的插入和删除是相对较快的。为什么会出现这两者的差别其实底层更多的考虑的是数据的存储结构：

##### 1、顺序存储和链式存储的概念：

- 从空间性能，顺序存储会对空间资源做到百分之百的利用，而链式存储对对空间的利用不是百分之百，因为存储了指针，不是真正的数据
- 从时间性能上来讲读取速度的话顺序存储更优，插入和删除操作链式存储更优，链式存储只需要移动指针，不需要移动元素。

##### 2、什么时候采用二分？什么时候采用二叉索引？

- 如果我们的数据是不进行频繁变化且是有序，而且查询相对较多的情况下采用二分查找
- 我们的数据是频繁变化的考虑到后面的数据扩容的情况下，我们考虑采用二叉索引的方式，但是这种会有一点空间资源的牺牲。



### 6、哈希表

​		哈希函数：根据查找的关键字key值，可以直接确定查找值所在的位置

####    6.1、哈希函数的构造方法：

1、直接定地址法：取关键字或关键字的某个线性函数值为哈希地址；

2、数字分析法：假设关键字集合中的每个关键字key都是由s位数字组成，分析key中的数据，从中提取某位某均匀分布的数字做为key。此种方法通常用于数字位数较长的情况，且数字需要存在一定的规律。比如：一个班同学的ID，就可以用身份证后五位；

3、平法取中法：如果关键字的每一位都有某些数字重复出现频率很高的现象，可以先求关键字的平方值，通过平方扩大差异，而后取中间数位作为最终存储地址比如key=1234 1234^2=1522756 取227作hash地址，比如key=4321 4321^2=18671041 取671作hash地址。 这种方法适合事先不知道数据并且数据长度较小的情况；

4、折叠法：数字的位数很多，将数字分割成几部分，取他们的叠加和做为hash地址；

5、除留余数法：H = key MOD p ,p应该为不大于m的质数，可以有效减少地址的重复；

6、随机数法：H = random key。当关键字长度不等时用这种方法；

#### 6.2、哈希函数设计的考虑因素：

- 计算哈希函数所需时间；
- 关键字长度；
- 哈希表的大小；
- 关键字的分布情况；
- 记录的查找频率。

#### 6.3、哈希冲突

​    例如：6 3 9，模取3的话，都会发生地址冲突。

#### 6.4、哈希冲突的解决方式

##### 1、开放地址法

​        线性探测再散列（直接往后面挨个挨个排）、二次探测再散列（左右两边探测）、随机探测再散列

##### 2、链地址法

​        在产生hash冲突后在存储数据后面加个指针，指向后面冲突的数据

##### 3、公共溢出区法

​        建立一个特殊存储空间，专门存放冲突数据。此种方法适用于数据和冲突较少的情况。

##### 4、哈希表的查找效率

​		首先与选用的哈希函数、处理哈希冲突的方法、哈希表的饱和度

### 7、一致性哈希

一致性哈希是一种特殊的哈希算法，目的是解决分布式缓存的问题。对存储节点的哈希值进行计算，其将存储空间抽象为一个环，将存储节点配置到环上。环上所有的节点都有一个值。其次，对数据进行哈希计算，按顺时针方向将其映射到离其最近的节点上去。当有节点出现故障离线时，按照算法的映射方法，受影响的仅仅为环上故障节点开始逆时针方向至下一个节点之间区间的数据对象，而这些对象本身就是映射到故障节点之上的。当有节点增加时，比如，在节点A和B之间重新添加一个节点H，受影响的也仅仅是节点H逆时针遍历直到B之间的数据对象，将这些重新映射到H上即可，因此，当有节点出现变动时，不会使得整个存储空间上的数据都进行重新映射，解决了简单哈希算法增删节点，重新映射所有数据带来的效率低下的问题。

## 三、操作系统

线程如何保证安全
多线程同时对同一块内存操作一定会崩溃吗
32位能分配的内存大小

### 1、虚拟内存

虚拟内存提供了三个重要的能力： **缓存**，**内存管理**，**内存保护**

1）将主存视为一个存储在磁盘上的地址空间的高速缓存，在主存中只保存活动区域，并根据需要在磁盘和主存之间来回传送数据（允许执行进程不必完全处于内存。这种方案的一个主要优点就是，程序可以大于物理内存）

2）为每个进程提供了一致的地址空间，简化内存管理

3）保护了每个进程的地址空间不被其他进程破坏





#### 1.1、虚拟内存意义

​		虚拟内存：将不同进程的虚拟地址和不同内存的物理地址映射起来，**让物理内存扩充成更大的逻辑内存**，从而让程序获得更多的可用内存。

​		为了更好的管理内存，操作系统将内存抽象成地址空间。每个程序拥有自己的地址空间，这个地址空间被**分割成多个块**，每一块称为一**页**。**（内存分段和内存分页）**

​		这些**页被映射到物理内存**，但不需要映射到连续的物理内存，也不需要所有页都必须在物理内存中。当程序引用到不在物理内存中的页时，由硬件执行必要的映射，将缺失的部分装入物理内存并重新执行失败的指令。

​		虚拟内存还允许进程轻松共享文件和实现共享内存。

​		从上面的描述中可以看出，虚拟内存允许程序不用将地址空间中的每一页都映射到物理内存，也就是说一个程序不需要全部调入内存就可以运行，这使得有限的内存运行大程序成为可能。

​		例如有一台计算机可以产生 16 位地址，那么一个程序的地址空间范围是 0~64K。该计算机只有 32KB 的物理内存，虚拟内存技术允许该计算机运行一个 64K 大小的程序。

#### 1.2、内存分段

​		程序是由若⼲个逻辑分段组成的，如可由代码分段、数据分段、栈段、堆段组成。不同的段是有不同的属性的，所以就⽤分段（**Segmentation**）的形式把这些段分离出来。

##### 1、分段机制下，如何映射呢？

​		分段机制下的虚拟地址由两部分组成，**段选择子 + 段内偏移量**。

<img src="总结面试题.assets/image-20210831104142524.png" alt="image-20210831104142524" style="zoom: 80%;" />

- **段选择⼦**就保存在段寄存器⾥⾯。段选择⼦⾥⾯最重要的是**段号**，⽤作段表的索引。段表⾥⾯保存的是这个段的基地址、段的界限和特权等级等。

- 虚拟地址中的**段内偏移量**应该位于 0 和段界限之间，如果段内偏移量是合法的，就将段基地址加上段内偏移量得到物理内存地址。

虚拟地址是通过段表与物理地址进⾏映射的，分段机制会把程序的虚拟地址分成 4 个段，每个段在段表中有⼀个项，在这⼀项找到段的基地址，再加上偏移量，于是就能找到物理内存中的地址。

##### 2、分段的缺点

- 内存碎片

- 内存交换的效率低

  **(由内存分页解决内存分段的缺点)**

###### 1）内存碎片

- 外部内存碎片：产生了多个不连续的小物理内存，导致新的程序无法被装载
- 内部内存碎片：程序所有的内存都被装载到了物理内存，但是这个程序有部分的内存可能并不经常使用，导致内存的浪费

###### 2）解决内存碎片的方法

- 外部内存碎片：内存交换，Swap空间：从硬盘划分，用于内存与硬盘的空间交换
- 内部内存碎片：

###### 3）内存交换的效率低

- 对于多进程的系统来说，⽤分段的⽅式，内存碎片是很容易产⽣的，产⽣了内存碎⽚，那不得不重新**Swap** 内存区域，这个过程会产⽣性能瓶颈。因为**硬盘的访问速度**要⽐内存**慢**太多了，每⼀次内存交换，我们都需要把⼀⼤段连续的内存数据写到硬盘上。
- 所以，如果内存交换的时候，交换的是⼀个占内存空间很⼤的程序，这样整个机器都会显得卡顿。

#### 1.3、内存分页

​		分段的好处就是能**产⽣连续**的内存空间，但是会出现内存碎⽚和内存交换的空间太⼤的问题。要解决这些问题，那么就要想出能少出现⼀些内存碎⽚的办法。另外，当需要进⾏内存交换的时候，让需要交换写⼊或者从磁盘装载的数据更少⼀点，这样就可以解决问题了。这个办法，也就是内存分⻚（*Paging*）。

##### 1、内存分页如何实现内存管理？

​		**分页是把整个虚拟和物理内存空间切成⼀段段固定尺⼨的⼤⼩**。这样⼀个连续并且尺⼨固定的内存空间，我们叫**⻚**（*Page*）。在 Linux 下，每⼀⻚的⼤⼩为 **4KB** 。

​		虚拟地址与物理地址之间通过⻚表来映射。页表存储在内存中，通过MMU（内存管理单元）来实现虚拟内存到物理内存的转换。⽽当进程访问的虚拟地址在⻚表中查不到时，系统会产⽣⼀个**缺⻚异常**，进⼊系统内核空间分配物理内存、更新进程⻚表，最后再返回⽤户空间，恢复进程的运⾏。

##### 2、怎么解决内存碎片和效率低？

​		由于内存空间都是预先划分好的，也就不会像分段会产⽣间隙⾮常⼩的内存，这正是分段会产⽣内存碎⽚的原因。⽽采⽤了分⻚，那么**释放的内存都是以⻚为单位释放的，也就不会产生无法给进程使⽤的小内存**。

​		如果内存空间不够，操作系统会把其他正在运⾏的进程中的「最近没被使⽤」的内存⻚⾯给释放掉，也就是暂时写在硬盘上，称为**换出（Swap Out）**。⼀旦需要的时候，再加载进来，称为**换⼊（*Swap In*）**。所以，⼀次性写⼊磁盘的也只有少数的⼀个⻚或者⼏个⻚，不会花太多时间，内存交换的效率就相对⽐较⾼。

​		因此，分⻚的⽅式使得我们在加载程序的时候，**不再需要⼀次性都把程序加载到物理内存中**。我们完全可以在进⾏虚拟内存和物理内存的页之间的映射之后，并不真的把页加载到物理内存⾥，⽽是**只有在程序运⾏中，需要用到对应虚拟内存页里面的指令和数据时，再加载到物理内存里面去。**

##### 3、分页机制下，如何映射呢？

​		在分⻚机制下，虚拟地址分为两部分，**⻚号**和**⻚内偏移**。⻚号作为⻚表的索引，**⻚表**包含物理⻚每⻚所在**物理内存的基地址**，这个基地址与⻚内偏移的组合就形成了物理内存地址。

##### ==总结==内存转换步骤

- 把虚拟内存地址，切分成⻚号和偏移量；
- 根据⻚号，从⻚表⾥⾯，查询对应的物理⻚号；
- 直接拿物理⻚号，加上前⾯的偏移量，就得到了物理内存地址。

如果有**快表**，则先查询快表中是否存在所需要查找的页号，如果存在，则直接获取对应的内存块号，得到物理地址；如果不存在，则根据页号查询对应的页表，找到对应的内存块号，计算得到物理地址，并把相应的页号和内存块号写入快表中，方便下一次查询。

<img src="总结面试题.assets/image-20210831104632604.png" alt="image-20210831104632604" style="zoom:80%;" />

##### 4、分页的缺点

- 空间上的缺陷：操作系统可以多进程

  **例如**：在 32 位的环境下，虚拟地址空间共有 4GB，假设⼀个⻚的⼤⼩是 4KB（2^12），那么就需要⼤约 100 万 （2^20） 个⻚，每个「⻚表项」需要 4 个字节⼤⼩来存储，那么整个 4GB 空间的映射就需要有 4MB的内存来存储⻚表。这 4MB ⼤⼩的⻚表，看起来也不是很⼤。但是要知道每个进程都是有⾃⼰的虚拟地址空间的，也就说都有⾃⼰的⻚表。那么， 100 个进程的话，就需要 400MB 的内存来存储⻚表，这是⾮常⼤的内存了，更别说 64 位的环境了。

##### 5、多级页表解决分页的空间上的缺点



#### 1.4、段页式内存管理

#### 1.5、Linux内存管理

#### 1.6、内存交换和覆盖

##### 1、内存交换

​		**交换(对换)技术的设计思想**：内存空间紧张时，系统将内存中某些进程暂时换出外存，把外存中某些已具备运行条件的进程换入内存(进程在内存与磁盘间动态调度)

- 换入：把准备好竞争CPU运行的程序从辅存移到内存。
- 换出：把处于等待状态（或CPU调度原则下被剥夺运行权力）的程序从内存移到辅存，把内存空间腾出来。

##### 2、内存覆盖

​		由于程序运行时并非任何时候都要访问程序及数据的各个部分（尤其是大程序），因此可以把用户空间分成为一个固定区和若干个覆盖区。将经常活跃的部分放在固定区，其余部分按照调用关系分段，首先将那些即将要访问的段放入覆盖区，其他段放在外存中，在需要调用前，系统将其调入覆盖区，替换覆盖区中原有的段。

​		覆盖技术的**特点**：是打破了必须将一个进程的全部信息装入内存后才能运行的限制，但当同时运行程序的代码量大于主存时仍不能运行，再而，大家要注意到，内存中能够更新的地方只有覆盖区的段，不在覆盖区的段会常驻内存。

##### 3、总结

![Image](总结面试题.assets/Image-16322784573334.png)

##### 4、什么时候内存交换？

​		内存交换通常在许多进程运行且内存吃紧时进行，而系统负荷降低就暂停。例如:在发现许多进程运行时经常发生缺页，就说明内存紧张，此时可以换出一些进程;如果缺页率明显下降，就可以暂停换出。

##### 5、内存交换中，被换出的进程保存在哪里？

​		保存在磁盘中，也就是**外存**中。具有对换功能的操作系统中，通常把磁盘空间分为文件区和对换区两部分。文件区主要用于存放文件，主要追求存储空间的利用率，因此对文件区空间的管理采用离散分配方式;对换区空间只占磁盘空间的小部分，被换出的进程数据就存放在对换区。由于对换的速度直接影响到系统的整体速度，因此对换区空间的管理主要追求换入换出速度，因此通常对换区采用连续分配方式(学过文件管理章节后即可理解)。总之，对换区的I/O速度比文件区的更快。

##### 6、在发生内存交换时，哪些进程优先考虑？

​		可优先换出阻塞进程;可换出优先级低的进程;为了防止优先级低的进程在被调入内存后很快又被换出，有的系统还会考虑进程在内存的驻留时间… (注意: PCB 会常驻内存，不会被换出外存)

##### 7、内存交换需要注意什么？

- 交换需要备份存储，通常是快速磁盘，它必须足够大，并且提供对这些内存映像的直接访问。
- 为了有效使用CPU，需要每个进程的执行时间比交换时间长，而影响交换时间的主要是转移时间，转移时间与所交换的空间内存成正比。
- 如果换出进程，比如确保该进程的内存空间成正比。
- 交换空间通常作为磁盘的一整块，且独立于文件系统，因此使用就可能很快。
- 交换通常在有许多进程运行且内存空间吃紧时开始启动，而系统负荷降低就暂停。
- 普通交换使用不多，但交换的策略的某些变种在许多系统中（如UNIX系统）仍然发挥作用。



#### 1.7、具有快表的地址变换过程

![Image](总结面试题.assets/Image-16322789075106.png)

#### 1.8、虚拟技术

​		虚拟技术把一个物理实体转换为多个逻辑实体。主要有两种虚拟技术：时（时间）分复用技术和空（空间）分复用技术。

##### 1、时分复用

​		多进程与多线程：多个进程能在同一个处理器上并发执行使用了时分复用技术，让每个进程轮流占用处理器，每次只执行一小个时间片并快速切换。

##### 2、空分复用

​		虚拟内存使用了空分复用技术，它将物理内存抽象为地址空间，每个进程都有各自的地址空间。地址空间的页被映射到物理内存，地址空间的页并不需要全部在物理内存中，当使用到一个没有在物理内存的页时，执行页面置换算法，将该页置换到内存中。

#### 1.9、局部性原理

​		主要分为**时间局部性和空间局部性**。

- 时间局部性:如果执行了程序中的某条指令，那么不久后这条指令很有可能再次执行;如果某个数据被访问过，不久之后该数据很可能再次被访问。(因为程序中存在大量的循环)；
- 空间局部性:一旦程序访问了某个存储单元，在不久之后，其附近的存储单元也很有可能被访问。(因为很多数据在内存中都是连续存放的，并且程序的指令也是顺序地在内存中存放的)。

#### 1.10、交换空间与虚拟内存的关系

##### 1、交换空间

​		Linux 中的交换空间（Swap space）在**物理内存**（RAM）被充满时被使用。如果系统需要更多的内存资源，而物理内存已经充满，内存中不活跃的页就会被移到交换空间去。虽然交换空间可以为带有少量内存的机器提供帮助，但是这种方法不应该被当做是对内存的取代。交换空间位于硬盘驱动器上，它比进入物理内存要慢。

​		交换空间可以是一个专用的交换分区（推荐的方法），交换文件，或两者的组合。交换空间的总大小应该相当于你的计算机内存的两倍和 32 MB这两个值中较大的一个，但是它不能超过2048MB（2 GB）。

##### 2、虚拟内存

​		虚拟内存是文件数据交叉链接的活动文件。是WINDOWS目录下的一个"WIN386.SWP"文件，这个文件会不断地扩大和自动缩小。就速度方面而言,CPU的L1和L2缓存速度最快，内存次之，硬盘再次之。但是**虚拟内存使用的是硬盘的空间**，为什么我们要使用速度最慢的硬盘来做 为虚拟内存呢？因为电脑中所有运行的程序都需要经过内存来执行，如果执行的程序很大或很多，就会导致我们只有可怜的256M/512M内存消耗殆尽。而硬盘空间动辄几十G上百G，为了解决这个问题，Windows中运用了虚拟内存技术，即拿出一部分硬盘空间来充当内存使用。

#### 1.11、什么是抖动？

​		刚刚换出的页面马上又要换入内存，刚刚换入的页面马上又要换出外存，这种频繁的页面调度行为称为抖动，或颠簸。产生抖动的主要原因是**进程频繁访问的页面数目高于可用的物理块数**(分配给进程的物理块不够)为进程分配的物理块太少，会使进程发生抖动现象。为进程分配的物理块太多，又会降低系统整体的并发度，降低某些资源的利用率。为了研究为应该为每个进程分配多少个物理块，Denning 提出了进程工作集” 的概念。



### 2、进程

#### 2.1、进程、线程、协程的区别

|          | 进程                                                         | 线程                                                 | 协程                                                         |
| -------- | ------------------------------------------------------------ | ---------------------------------------------------- | ------------------------------------------------------------ |
| 定义     | 资源分配和拥有的基本单位                                     | 资源调度的基本单位                                   | 用户态的轻量级线程，线程内部调度的基本单位                   |
| 切换情况 | 进程CPU环境（栈、寄存器、页表、句柄等）的保存以及新调度的进程CPU环境的设置 | 保存和设置程序计数器、少量寄存器和栈的内容           | 先将寄存器上下文和栈保存，后期恢复                           |
| 切换过程 | 用户->内核->用户                                             | 用户->内核->用户                                     | 用户态（没有陷入内核）                                       |
| 拥有资源 | CPU资源、内存资源、文件资源等                                | 程序计数器、寄存器、栈和状态字                       | 独有的寄存器上下文和栈                                       |
| 并发性   | 不同进程之间切换实现并发，各自占有CPU并行                    | 一个进程内部的多个线程并发执行                       | 同一时间只能执行一个协程，而其他协程处于休眠状态，适合多任务进行分时处理 |
| 系统开销 | 切换虚拟地址空间，切换内核栈和硬件上下文，CPU高速缓存失效、页表切换，开销大 | 切换时只需保存和设置少量寄存器内容，开销较小         | 直接操作栈则基本没有内核切换开销，可以不加锁的访问全局变量，上下文切换快 |
| 通信方面 | 进程间通信需要借助操作系统                                   | 线程间可以直接读写进程数据段（如全局变量）来进行通信 | 共享内存、消息队列                                           |

#### 2.2、并发和并行

- 并发：同一时间间隔内做多件事情，比如“时间片轮转进程调度算法”，就是在操作系统的管理下，所有正在运行的进程轮流使用CPU，每个进程允许占用CPU的时间非常短(比如10毫秒)，这样用户根本感觉不出来CPU是在轮流为多个进程服务，就好象所有的进程都在不间断地运行一样。
- 并行：同一时刻同时做多件事情，如果有多台CPU，进程数若是小于CPU数，则不同的进程可以分配给不同的CPU来运行，这样多个进程就是真正同时进行，若是进程数大于CPU数，仍需要使用并发技术。

#### 2.3、进程的定义和状态

##### 1、定义

​		进程是系统进行资源分配和调度的基本单位，进程是程序的基本执行实体

​		创建进程：BOOL ret = CreateProcess(NULL, chCommandLine, NULL, NULL, FALSE, 0,       NULL, NULL, &si, &pi);

​		关闭进程：CloseHandle(pi.hThread);

##### 2、状态

<img src="总结面试题.assets/image-20210918151609075.png" alt="image-20210918151609075" style="zoom: 67%;" />

##### 3、进程的同步和互斥

![Image](总结面试题.assets/Image-16319495123553.png)

#### 2.4、进程的创建、杀死、退出

##### 1、进程的创建

​		进程结构由以下几个部分组成：代码段、堆栈段、数据段。代码段是静态的二进制代码，多个程序可以共享。实际上在父进程创建子进程之后，父、子进程除了pid外，几乎所有的部分几乎一样。父、子进程**共享全部数据**，但并不是说他们就是对同一块数据进行操作，子进程在读写数据时会通过**写时复制**机制将公共的数据重新拷贝一份，之后在拷贝出的数据上进行操作。如果子进程想要运行自己的代码段，还可以通过调用execv()函数重新加载新的代码段，之后就和父进程独立开了。我们在shell中执行程序就是通过shell进程先fork()一个子进程再通过execv()重新加载新的代码段的过程。

```c++
pid_fork(void);//出错返回-1，父进程中返回pid > 0,子进程pid = 0;
```

##### 2、杀死进程的方式

```c++
//用ps查看进程
ps -ef 或 ps -aux;
//杀死进程
kill -s 9 PID;

//进阶版1
ps -ef | grep firefox;
kill -s 9 PID;

//进阶版2
//pgrep的p表明了这个命令是专门用于进程查询的grep
pgrep firefox;//得pid
kill -s 9 PID;

//进阶版3
//和pgrep相比稍显不足的是，pidof必须给出进程的全名
pidof firefox-bin;//得pid
kiss -s 9 PID;

//进阶版4
/*“grep firefox”的输出结果是，所有含有关键字“firefox”的进程。
“grep -v grep”是在列出的进程中去除含有关键字“grep”的进程。
“cut -c 9-15”是截取输入行的第9个字符到第15个字符，而这正好是进程号PID。
“xargs kill -s 9”中的xargs命令是用来把前面命令的输出结果（PID）作为“kill -s 9”命令的参数，并执行该命令。
“kill -s 9”会强行杀掉指定进程。*/
ps -ef | grep firefox | grep -v grep | cut -c 9-15 | xargs kill -s 9;

//进阶版5
pgrep firefox | xargs kill -s 9;
ps -ef | grep firefox | awk '{print $2}' | xargs kill -9;

//进阶版6
pkill -９ firefox;//pkill与kill在这点的差别是：pkill无须 “ｓ”，终止信号等级直接跟在 “-“ 后面。之前我一直以为是 "-s 9"，结果每次运行都无法终止进程。
```

##### 3、进程的退出

###### 1）进程终止的几种方式

- main函数的自然返回，return
- 调用exit函数，属于c的函数库
- 调用_exit函数，属于系统调用
- 调用abort函数，异常程序终止，同时发送SIGABRT信号给调用进程。
- 接受能导致进程终止的信号：ctrl+c (^C)、SIGINT(SIGINT中断进程) 

###### 2）区别

![image-20210922112250999](总结面试题.assets/image-20210922112250999.png)

- exit()和_exit()区别：exit()是对_exit()的封装，都会终止进程并做相关收尾工作，最主要的区别是_exit()函数关闭全部描述符和清理函数后不会刷新流，但是exit()会在调用_'exit()函数前刷新数据流。
- return和exit()区别：exit()是函数，但有参数，执行完之后控制权交给系统。return若是在调用函数中，执行完之后控制权交给调用进程，若是在main函数中，控制权交给系统。
- 异常退出方式：abort()、终止信号。



##### 4、如何让进程在后台运行

-  命令后面加上&即可，实际上，这样是将命令放入到一个作业队列中了
- ctrl + z 挂起进程，使用jobs查看序号，在使用bg %序号后台运行进程
- nohup + &，将标准输出和标准错误缺省会被重定向到 nohup.out 文件中，忽略所有挂断（SIGHUP）信号
- 运行指令前面 + setsid，使其父进程编程init进程，不受HUP信号的影响
- 将 命令+ &放在()括号中，也可以是进程不受HUP信号的影响

##### 5、一个进程可以创建多少个线程？

​		理论上，一个进程可用虚拟空间是2G，默认情况下，线程的栈的大小是1MB，所以理论上最多只能创建2048个线程。如果要创建多于2048的话，必须修改编译器的设置。因此，**一个进程可以创建的线程数由可用虚拟空间和线程的栈的大小共同决定**，只要虚拟空间足够，那么新线程的建立就会成功。如果需要创建超过2K以上的线程，减小你线程栈的大小就可以实现了，虽然在一般情况下，你不需要那么多的线程。过多的线程将会导致大量的时间浪费在线程切换上，给程序运行效率带来负面影响。

#### 2.5、进程间通信

- **信号量**（semophore)：计数器，控制多个进程对共享资源的访问，做为一种锁的机制，防止某进程在访问共享资源的时候，其他进程也在访问该资源。主要作为进程间以及同一进程内不同线程之间的同步手段。（信号量的数据结构为一个值及一个指针，指针指向等待该信号量的下一个进程）。
- **信号**（sinal、notify)：一种比较复杂的通信方式，用于通知接收进程某个事件已经发生；
- **共享内存**（shared region)：共享内存就是映射一段能被其他进程所访问的内存，这段共享内存由一个进程创建，多个线程可以访问。往往与notify、semophere配合使用，来实现进程间的同步和通信。多个进程可以同时操作，所以需要进行同步。信号量用来同步对共享内存的访问。
- **套接字**(socket)：用于不同器件间的进程通信。可以将套接字看作不同主机间的进程进行双间通信的端点。
- **消息队列**（message queue）：消息队列是消息链表，存放在内核中并由消息队列标识符标识。消息队列克服了信号传递量少、管道只能承载无格式字节流以及缓冲区大小受限等缺点；
- **管道**（pipe)：管道是半双工通信方式，数据只能单向流动，且只能在具有亲缘关系间的进程使用。进程的亲缘关系通常是指父子进程关系；
  - **有名管道**（FIFO文件，借助文件系统）：半双工通信方式，但允许无亲缘关系进程间通信。
  - **无名管道**（内存文件）：管道是一种半双工的通信方式，数据只能单向流动，而且只能在具有亲缘关系的进程间使用。进程的亲缘关系通常指父子进程关系。



#### 2.6、进程上下文切换	

​		进程切换：**切换虚拟地址空间、切换内核栈、硬件上下文**。

​		线程切换：切换内核栈、硬件上下文。

进程的上下文切换：不仅包含了虚拟内存、栈、全局变量等⽤户空间的资源，还包括了内核堆栈、寄存器等内核空间的资源。

- 切换页目录以使用新的地址空间

- 切换内核栈和硬件上下文

对于linux来说，线程和进程的最大区别就在于地址空间，对于线程切换，第1步是不需要做的，第2是进程和线程切换都要做的。

##### 1、进程上下文切换开销

###### 1）切换的性能消耗：

- 线程上下文切换和进程上下文切换一个最主要的区别是线程的切换**虚拟内存空间**依然是相同的，但是进程切换是不同的。这两种上下文切换的处理都是通过操作系统内核来完成的。内核的这种切换过程伴随的最显著的性能损耗是将寄存器中的内容切换出。
- 另外一个隐藏的损耗是上下文的切换会扰乱**处理器的缓存机制**。简单的说，一旦去切换上下文，处理器中所有已经缓存的内存地址一瞬间都作废了。还有一个显著的区别是当你改变虚拟内存空间的时候，处理的页表缓冲（processor's Translation Lookaside Buffer (TLB)）被全部刷新，这将导致内存的访问在一段时间内相当的低效。但是在线程的切换中，不会出现这个问题。

###### 2）切换的开销：

- 最显著的性能损耗是将保存寄存器中的内容
- CPU高速缓存失效
  - 页表查找是一个很慢的过程，因此通常使用Cache来缓存常用的地址映射，这样可以加速页表查找，这个cache就是TLB。当进程切换后页表也要进行切换，页表切换后TLB就失效了，cache失效导致命中率降低，那么虚拟地址转换为物理地址就会变慢，表现出来的就是程序运行会变慢。

##### 2、线程上下文切换的原因？

​		引入线程（线程上下文切换开销较小）。

- 当前执行任务的时间用完之后，系统CPU正常调度下一个任务；**（时间片用完）**
- 当前执行任务碰到I/O阻塞，调度器将此任务挂起，继续下一个任务；**（I/O阻塞）**
- 多个任务抢占锁资源，当前任务没有抢到锁资源，被调度器挂起，继续下一个任务；**（没抢到资源）**
- 用户代码挂起当前任务，让出CPU时间；**（挂起）**
- 硬件中断。**（中断）**

##### 3、用 vmstat 查看上下文切换次数

##### 4、如何减少上下文切换

​		既然上下文切换会导致额外的开销，因此减少上下文切换次数便可以提高多线程程序的运行效率。减少上下文切换的方法有：**无锁并发编程、CAS算法、使用最少的线程、使用协程。**

- 无锁并发编程：多线程竞争时，会引起上下文切换，所以多线程处理数据时，可以用一些办法来避免使用锁，比如将数据的ID按照hash取模分段，不同的线程处理不同段的数据；
- CAS算法：利用CAS算法来更新数据，不需要进行加锁处理；
- 使用最少的线程：避免创建不需要的线程，比如任务很少，但是常见了很多线程来处理，这就导致了大量线程处于等待状态；
- 使用协程：在单线程里实现多任务的调度，并在单线程里维持多个任务间的切换。

#### 2.7、详解进程上下文切换

​		原文链接：https://blog.csdn.net/21cnbao/article/details/108860584

##### 1、进程上下文的概念

​		进程上下文是进程执行活动全过程的静态描述。我们把已执行过的进程指令和数据在相关寄存器与堆栈中的内容称为进程上文，把正在执行的指令和数据在寄存器与堆栈中的内容称为进程正文，把待执行的指令和数据在寄存器与堆栈中的内容称为进程下文。

​		实际上linux内核中，进程上下文包括进程的**虚拟地址空间**和**硬件上下文**。进程硬件上下文包含了当前cpu的一组寄存器的集合，arm64中使用**task_struct**结构的thread成员的cpu_context成员来描述，包括x19-x28,sp, pc等。

<img src="总结面试题.assets/image-20210909150435736.png" alt="image-20210909150435736" style="zoom:80%;" />

##### 2、上下文切换过程

​		进程上下文切换主要涉及到两部分主要过程：**进程地址空间切换**和**处理器状态切换**。地址空间切换主要是针对用户进程而言，而处理器状态切换对应于所有的调度单位。

###### 1）进程地址空间切换

​		进程地址空间指的是进程所拥有的**虚拟地址空间**，而这个地址空间是假的，是Linux内核通过**数据结构**来描述出来的，从而使得每一个进程都感觉到自己拥有整个内存的假象，CPU访问的指令和数据最终会落实到实际的物理地址，对用进程而言通过**缺页异常**来分配和建立页表映射。进程地址空间内有进程运行的指令和数据，因此到调度器从其他进程重新切换到我的时候，为了保证当前进程访问的虚拟地址是自己的必须切换地址空间。
​		实际上，进程地址空间使用**mm_struct结构体**来描述，这个结构体被嵌入到进程描述符（我们通常所说的进程控制块PCB）task_struct中，mm_struct结构体将各个vma组织起来进行管理，其中有一个成员**pgd**至关重要，地址空间切换中最重要的是pgd的设置。

​		**pgd中保存的是进程的页全局目录的虚拟地址**，记住保存的是虚拟地址，那么pgd的值是何时被设置的呢？答案是**fork**的时候，如果是创建进程，需要分配设置mm_struct，其中会分配进程页全局目录所在的页，然后将首地址赋值给pgd。

​		进程地址空间转换最终将**进程的pgd虚拟地址转化为物理地址**存放在（ttbr0_el1）**用户空间的页表基址寄存器**，当访问用户空间地址的时候MMU会通过这个寄存器来做遍历页表获得物理地址（ttbr1_el1是内核空间的页表基址寄存器，访问内核空间地址时使用，所有进程共享，不需要切换）。完成了这一步，也就完成了进程的地址空间切换，确切的说是进程的虚拟地址空间切换。

**注**：上述仅仅切换用户地址空间，内核地址空间由于是共享的不需要切换，也就是为何切换到内核线程不需要也没有地址空间的原因。

###### 2）处理器状态（硬件上下文）切换

​		地址空间切换，只是保证了进程访问指令数据时访问的是自己地址空间（当然上下文切换的时候处于内核空间，执行的是内核地址数据，当返回用户空间的时候才有机会执行用户空间指令数据**，地址空间切换为进程访问自己用户空间做好了准备**），但是进程执行的内核栈还是前一个进程的，当前执行流也还是前一个进程的，需要做切换。

​		实际上，处理器状态切换就是将前一个进程的sp,pc等寄存器的值保存到一块内存上，然后将即将执行的进程的sp,pc等寄存器的值从另一块内存中恢复到相应寄存器中，恢复sp完成了进程内核栈的切换，恢复pc完成了指令执行流的切换。其中保存/恢复所用到的那块内存需要被进程所标识，这块内存这就是**cpu_contex**这个结构的位置（进程切换都是在内核空间完成）。

​		由于用户空间通过异常/中断进入内核空间的时候都需要**保存现场**，也就是保存发生异常/中断时的所有通用寄存器的值，内核会把“现场”保存到每个进程特有的进程内核栈中，并用**pt_regs**结构来描述，当异常/中断处理完成之后会返回用户空间，返回之前会恢复之前保存的“现场”，用户程序继续执行。
​		所以当进程切换的时候，当前进程被时钟中断打断，将发生中断时的现场保存到进程内核栈（如：sp, lr等），然后会切换到下一个进程，当再次回切换回来的时候，返回用户空间的时候会恢复之前的现场，进程就可以继续执行（执行之前被中断打断的下一条指令，继续使用自己用户态sp），这对于用户进程来说是透明的。

##### 3、ASID机制

​		ASID(Ａddress Space Identifer 地址空间标识符)。

##### 4、普通用户进程、普通用户线程、内核线程切换的差别

##### 5、进程切换全景图

#### ==总结==进程和线程区别

- 线程是运⾏在进程中的⼀个“逻辑流”，单进程中可以运⾏多个线程，同进程⾥的线程可以共享进程的部分资源的，⽐如⽂件描述符列表、进程空间、代码、全局数据、堆、共享库等，这些共享些资源在上下⽂切换时是不需要切换，⽽只需要切换线程的私有数据、寄存器等不共享的数据，因此同⼀个进程下的线程上下⽂切换的开销要⽐进程小得多。
- 一个进程挂掉了不会影响其他进程，而线程挂掉了会影响其他线程



#### 2.8、僵尸进程

##### 1、什么是僵尸进程？

​		僵尸进程是一个进程使用fork创建子进程，如果子进程退出，而父进程并没有调用wait或waitpid获取子进程的状态信息，那么子进程的进程描述符仍然保存在系统中。这种进程称之为僵尸进程。

##### 2、设置**僵尸进程的目**的

​		设置**僵尸进程的目**的是维护子进程的信息，以便父进程在以后某个时候获取。这些信息至少包括进程ID，进程的终止状态，以及该进程使用的CPU时间，所以当终止子进程的父进程调用wait或waitpid时就可以得到这些信息。如果一个进程终止，而该进程有子进程处于僵尸状态，那么它的所有僵尸子进程的父进程ID将被重置为1（init进程）。继承这些子进程的init进程将清理它们（也就是说init进程将wait它们，从而去除它们的僵尸状态）。

##### 3、如何避免僵尸进程？

- 通过signal(SIGCHLD, SIG_IGN)通知内核对子进程的结束不关心，由内核回收。如果不想让父进程挂起，可以在父进程中加入一条语句：signal(SIGCHLD,SIG_IGN);表示父进程忽略SIGCHLD信号，该信号是子进程退出的时候向父进程发送的。
- 父进程调用wait/waitpid等函数等待子进程结束，如果尚无子进程退出wait会导致父进程阻塞。waitpid可以通过传递WNOHANG使父进程不阻塞立即返回。
- 如果父进程很忙可以用signal注册信号处理函数，在信号处理函数调用wait/waitpid等待子进程退出。
- 通过两次调用fork。父进程首先调用fork创建一个子进程然后waitpid等待子进程退出，子进程再fork一个孙进程后退出。这样子进程退出后会被父进程等待回收，而对于孙子进程其父进程已经退出所以孙进程成为一个孤儿进程，孤儿进程由init进程接管，孙进程结束后，init会等待回收。

第一种方法忽略SIGCHLD信号，这常用于并发服务器的性能的一个技巧因为并发服务器常常fork很多子进程，子进程终结之后需要服务器进程去wait清理资源。如果将此信号的处理方式设为忽略，可让内核把僵尸子进程转交给init进程去处理，省去了大量僵尸进程占用系统资源。

#### 2.9、孤儿进程

​		孤儿进程是因为父进程异常结束，然后子进程被init进程异常收养（注：任何一个进程都必须有父进程）。一个父进程退出，而它的一个或多个子进程还在运行，那么那些子进程将成为孤儿进程。孤儿进程将被init进程(进程号为1)所收养，并由init进程对它们完成状态收集工作。

#### 2.10、守护进程

##### 1、什么是守护进程？

​		守护进程是创建守护进程时有意把父进程结束，然后被init进程收养。它指在后台运行的，没有控制终端与之相连的进程。它独立于控制终端，周期性地执行某种任务。Linux的大多数服务器就是用守护进程的方式实现的，如web服务器进程http等。

##### 2、创建守护进程要点

- 让程序在后台执行。方法是调用fork（）产生一个子进程，然后使父进程退出。
- 调用setsid（）创建一个新对话期。控制终端、登录会话和进程组通常是从父进程继承下来的，守护进程要摆脱它们，不受它们的影响，方法是调用setsid（）使进程成为一个会话组长。setsid（）调用成功后，进程成为新的会话组长和进程组长，并与原来的登录会话、进程组和控制终端脱离。
- 禁止进程重新打开控制终端。经过以上步骤，进程已经成为一个无终端的会话组长，但是它可以重新申请打开一个终端。为了避免这种情况发生，可以通过使进程不再是会话组长来实现。再一次通过fork（）创建新的子进程，使调用fork的进程退出。
- 关闭不再需要的文件描述符。子进程从父进程继承打开的文件描述符。如不关闭，将会浪费系统资源，造成进程所在的文件系统无法卸下以及引起无法预料的错误。首先获得最高文件描述符值，然后用一个循环程序，关闭0到最高文件描述符值的所有文件描述符。
- 将当前目录更改为根目录。
- 子进程从父进程继承的文件创建屏蔽字可能会拒绝某些许可权。为防止这一点，使用unmask（0）将屏蔽字清零。
- 处理SIGCHLD信号。对于服务器进程，在请求到来时往往生成子进程处理请求。如果子进程等待父进程捕获状态，则子进程将成为僵尸进程（zombie），从而占用系统资源。如果父进程等待子进程结束，将增加父进程的负担，影响服务器进程的并发性能。在Linux下可以简单地将SIGCHLD信号的操作设为SIG_IGN。这样，子进程结束时不会产生僵尸进程。

僵尸进程、孤儿进程、守护进程三者区分：

​	**一个正常运行的子进程，如果此刻子进程退出，父进程没有及时调用wait和waitpid收回子进程的系统资源，该进程就是僵尸进程，如果系统收回了，就是正常退出。如果一个正常运行的子进程，它的父进程退出了但子进程还在，还进程此刻就是孤儿进程，被init进程收养，如果父进程是故意被杀掉，子进程做相应处理后就是守护进程。**

#### 2.11、进程同步的方法

##### 1、临界区

​		对临界资源进行访问的那段代码称为临界区。为了互斥访问临界资源，每个进程在进入临界区之前，需要先进行检查。

##### 2、同步和互斥

- 同步：多个进程因为合作产生的直接制约关系，使得进程有一定的先后执行关系。
- 互斥：多个进程在同一时刻只有一个进程能进入临界区。

##### 3、信号量

​		信号量（Semaphore）是一个整型变量，可以对其执行 down 和 up 操作，也就是常见的 P 和 V 操作。

- **down** : 如果信号量大于 0 ，执行 -1 操作；如果信号量等于 0，进程睡眠，等待信号量大于 0；
- **up** ：对信号量执行 +1 操作，唤醒睡眠的进程让其完成 down 操作。

​		down 和 up 操作需要被设计成原语，不可分割，通常的做法是在执行这些操作的时候屏蔽中断。如果信号量的取值只能为 0 或者 1，那么就成为了 **互斥量（Mutex）** ，0 表示临界区已经加锁，1 表示临界区解锁。

```c++
typedef int semaphore;
semaphore mutex = 1;
void P1() {
    down(&mutex);
    // 临界区
    up(&mutex);
}
void P2() {
    down(&mutex);
    // 临界区
    up(&mutex);
}
```

##### 4、管程

​		管程有一个重要特性：在一个时刻只能有一个进程使用管程。进程在无法继续执行的时候不能一直占用管程，否则其它进程永远不能使用管程。管程引入了 **条件变量** 以及相关的操作：**wait()** 和 **signal()** 来实现同步操作。对条件变量执行 wait() 操作会导致调用进程阻塞，把管程让出来给另一个进程持有。signal() 操作用于唤醒被阻塞的进程。



#### 2.12、父进程、子进程、进程组、作业、会话

##### 1、父进程

​		已创建一个或多个子进程的进程。

##### 2、子进程

​		由fork创建的新进程被称为子进程（child process）。该函数被调用一次，但返回两次。两次返回的区别是子进程的返回值是0，而父进程的返回值则是新进程（子进程）的进程 id。将子进程id返回给父进程的理由是：

- 因为一个进程的子进程可以多于一个，没有一个函数使一个进程可以获得其所有子进程的进程id。对子进程来说，之所以fork返回0给它，是因为它随时可以调用getpid()来获取自己的pid；
- 也可以调用getppid()来获取父进程的id。(进程id 0总是由交换进程使用，所以一个子进程的进程id不可能为0 )。

​		fork之后，操作系统会复制一个与父进程完全相同的子进程，虽说是父子关系，但是在操作系统看来，他们更像兄弟关系，这2个进程共享代码空间，但是数据空间是互相独立的，子进程数据空间中的内容是父进程的完整拷贝，指令指针也完全相同，子进程拥有父进程当前运行到的位置（两进程的程序计数器pc值相同，也就是说，子进程是从fork返回处开始执行的），但有一点不同，如果fork成功，子进程中fork的返回值是0，父进程中fork的返回值是子进程的进程号，如果fork不成功，父进程会返回错误。

​		子进程与父进程：

- **继承**：进程的资格(真实(real)/有效(effective)/已保存(saved)用户号(UIDs)和组号(GIDs))、环境(environment)、堆栈、内存、进程组号；
- **独有**：进程号、不同的父进程号(即子进程的父进程号与父进程的父进程号不同， 父进程号可由getppid函数得到)、资源使用(resource utilizations)设定为0。

##### 3、进程组

​		进程组就是多个进程的集合，其中肯定有一个组长，其进程PID等于进程组的PGID。只要在某个进程组中一个进程存在，该进程组就存在，这与其组长进程是否终止无关。

##### 4、作业

​		shell分前后台来控制的不是进程而是作业（job）或者进程组（Process Group）。一个前台作业可以由多个进程组成，一个后台也可以由多个进程组成，shell可以运行一个前台作业和任意多个后台作业，这称为作业控制。

###### 1）为什么只能运行一个前台作业？

​		当我们在前台新起了一个作业，shell就被提到了后台，因此shell就没有办法再继续接受我们的指令并且解析运行了。 但是如果前台进程退出了，shell就会有被提到前台来，就可以继续接受我们的命令并且解析运行。

###### 2）作业与进程组的区别

​		如果作业中的某个进程有创建了子进程，则该子进程是不属于该作业的。一旦作业运行结束，shell就把自己提到前台（子进程还存在，但是子进程不属于作业），如果原来的前台进程还存在（这个子进程还没有终止），他将自动变为后台进程组。

##### 5、会话

​		会话（Session）是一个或多个进程组的集合。一个会话可以有一个控制终端。在xshell或者WinSCP中打开一个窗口就是新建一个会话。



### 3、线程

#### 3.1、线程的状态

##### 1、五种状态

- 新建：新创建了一个线程对象。
- 就绪：该状态的线程位于“**可运行线程池**”中，变得可运行，只**等待获取**[**CPU**](http://product.it168.com/list/b/0217_1.shtml)**的使用权**。**即在就绪状态的进程除CPU之外，其它的运行所需资源都已全部获得。**
- 运行：就绪状态的线程获取了CPU，执行程序代码。
- 阻塞（等待）：线程因为某种原因放弃CPU使用权，暂时停止运行
- 销毁

##### 2、如何创建线程

​		 pthread_create  C++新增线程库。线程的创建是由AfxBeginThread()函数完成，函数中传参分别是**线程回调函数、传递给线程回调函数的参数、优先级别、线程的堆栈值、创建线程时的初始状态和线程的安全属性**。线程回调函数的创建格式为UINT MyCreateThread(LPVOID pParam),LPVOID表示任意类型的指针，一般传递创建线程的类的this指针。

```c++
#include <thread> 
void Fun_1();
void Fun_2();
unsigned int counter = 0;
std::mutex mtx;   //互斥锁
int main()
{
    std::thread thrd_1(Fun_1);
    std::thread thrd_2(Fun_2);
    thrd_1.join();
    thrd_2.join();
    system("pause");
    return 0;
}
```

#### 3.2、线程共享的资源和独立的资源

##### 1、共享的资源

- 进程代码段 
- 进程的公有数据(利用这些共享的数据，线程很容易的实现相互之间的通讯) 
- 进程打开的文件描述符、信号的处理器、进程的当前目录和进程用户ID与进程组ID。

##### 2、独立的资源

- **线程ID**，每个线程都有自己的线程ID，这个ID在本进程中是唯一的。进程用此来标识线程。
- **寄存器组的值**，由于线程间是并发运行的，每个线程有自己不同的运行线索，当从一个线程切换到另一个线程上时，必须将原有的线程的寄存器集合的状态保存，以便将来该线程在被重新切换到时能得以恢复。
- 线程的**堆栈**，堆栈是保证线程独立运行所必须的。线程函数可以调用函数，而被调用函数中又是可以层层嵌套的，所以线程必须拥有自己的函数堆栈， 使得函数调用可以正常执行，不受其他线程的影响。
- **错误返回码**，由于同一个进程中有很多个线程在同时运行，可能某个线程进行系统调用后设置了errno值，而在该线程还没有处理这个错误，另外一个线程就在此时被调度器投入运行，这样错误值就有可能被修改。所以，不同的线程应该拥有自己的错误返回码变量。
- 线程的信号屏蔽码，由于每个线程所感兴趣的信号不同，所以线程的信号屏蔽码应该由线程自己管理。但所有的线程都共享同样的信号处理器。
- 线程的**优先级**，由于线程需要像进程那样能够被调度，那么就必须要有可供调度使用的参数，这个参数就是线程的优先级。

#### 3.3、线程间通信

##### 1、条件变量

​		互斥锁一个明显的缺点是他只有两种状态：锁定和非锁定。而条件变量通过允许线程阻塞和等待另一个线程发送信号的方法弥补了互斥锁的不足，他常和互斥锁一起使用，以免出现竞态条件。当条件不满足时，线程往往解开相应的互斥锁并阻塞线程然后等待条件发生变化。一旦其他的某个线程改变了条件变量，他将通知相应的条件变量唤醒一个或多个正被此条件变量阻塞的线程。总的来说互斥锁是线程间互斥的机制，条件变量则是同步机制。

##### 2、自旋锁

​		如果进线程无法取得锁，进线程不会立刻放弃CPU时间片，而是一直循环尝试获取锁，直到获取为止。如果别的线程长时期占有锁那么自旋就是在浪费CPU做无用功，但是自旋锁一般应用于加锁时间很短的场景，这个时候效率比较高。

##### 3、互斥锁

​		一次只能一个线程拥有互斥锁，其他线程只有等待

​		互斥锁是在抢锁失败的情况下主动放弃CPU进入睡眠状态直到锁的状态改变时再唤醒，而操作系统负责线程调度，为了实现锁的状态发生改变时唤醒阻塞的线程或者进程，需要把锁交给操作系统管理，所以互斥锁在加锁操作时涉及上下文的切换。互斥锁实际的效率还是可以让人接受的，加锁的时间大概100ns左右，而实际上互斥锁的一种可能的实现是先自旋一段时间，当自旋的时间超过阀值之后再将线程投入睡眠中，因此在并发运算中使用互斥锁（每次占用锁的时间很短）的效果可能不亚于使用自旋锁。

##### 4、读写锁

- 多个读者可以同时进行读
- 写者必须互斥（只允许一个写者写，也不能读者写者同时进行）
- 写者优先于读者（一旦有写者，则后续读者必须等待，唤醒时优先考虑写者）

#### 3.4、线程中的sleep和wait

- wait：释放执行权，释放锁（指定时间内，当然也可以不指定时间，在这个时间内notify唤不醒）
- sleep：释放执行权，不释放锁（相当于等待一定时间然后继续向下执行）

#### 3.5、怎么回收线程

##### 1、等待线程结束

```c++
int pthread_join(pthread_t tid, void** retval)；
```

​	主线程调用，等待子线程退出并回收其资源，类似于进程中wait/waitpid回收僵尸进程，调用pthread_join的线程会被阻塞。

- tid：创建线程时通过指针得到tid值。
- retval：指向返回值的指针。

##### 2、结束线程

```c++
pthread_exit(void* retval);
```

​	子线程执行，用来结束当前线程并通过retval传递返回值，该返回值可通过pthread_join获得。

- retval：同上。

##### 3、分离线程

```c++
int pthread_detach(pthread_t tid);
```

​	主线程、子线程均可调用。主线程中pthread_detach(tid)，子线程中pthread_detach(pthread_self())，调用后和主线程分离，子线程结束时自己立即回收资源。

- tid：同上。



### 4、多进程与多线程模型

#### 4.1、多进程模型

​		使⽤多进程模型，也就是为每个客户端分配⼀个进程来处理请求。服务器的主进程负责监听客户的连接，⼀旦与客户端连接完成，accept() 函数就会返回⼀个「已连接Socket」，这时就通过 **fork()** 函数创建⼀个**⼦进程**，实际上就把⽗进程所有相关的东⻄都**复制**⼀份，包括**⽂件描述符、内存地址空间、程序计数器、执⾏的代码**等。

​		这两个进程刚复制完的时候，⼏乎一模一样。不过，会根据**返回值**来区分是⽗进程还是⼦进程，如果返回值是 0，则是⼦进程；如果返回值是其他的整数，就是⽗进程。

​		正因为⼦进程会复制⽗进程的⽂件描述符，于是就可以直接使⽤「已连接 Socket 」和客户端通信了，可以发现，⼦进程不需要关⼼「监听 Socket」，只需要关⼼「已连接 Socket」；⽗进程则相反，将客户服务交给⼦进程来处理，因此⽗进程不需要关⼼「已连接 Socket」，只需要关⼼「监听 Socket」。

**存在问题：进程间上下文切换开销大**

#### 4.2、多线程模型

​		对于多线程模式，也就说来了client，服务器就会新建一个线程来处理该client的读写事件。 这种模式虽然处理起来简单方便，但是由于服务器为每个client的连接都采用一个线程去处理，使得资源占用非常大。因此，当连接数量达到上限时，再有用户请求连接，直接会导致资源瓶颈，严重的可能会直接导致服务器崩溃。因此，为了解决这种一个线程对应一个客户端模式带来的问题，提出了采用**线程池**的方式。

##### 为什么引入多线程模型？

​		主要是因为进程间上下文切换**系统开销**大。

​		线程是运⾏在进程中的⼀个“逻辑流”，单进程中可以运⾏多个线程，同进程⾥的线程可以共享进程的部分资源的，⽐如⽂件描述符列表、进程空间、代码、全局数据、堆、共享库等，这些共享些资源在上下⽂切换时是不需要切换，⽽只需要切换线程的私有数据、寄存器等不共享的数据，因此同⼀个进程下的线程上下⽂切换的开销要⽐进程⼩得多。

​		当服务器与客户端 TCP 完成连接后，通过 pthread_create() 函数创建线程，然后将「已连接 Socket」的⽂件描述符传递给线程函数，接着在线程⾥和客户端进⾏通信，从⽽达到并发处理的⽬的。

##### 线程池

​		可以使⽤线程池的⽅式来避免线程的频繁创建和销毁，所谓的线程池，就是提前创建一个固定大小的线程池，来一个客户端，就从线程池取一个空闲线程来处理，当客户端处理完读写操作之后，就交出对线程的占用。也就是说当由新连接建⽴时，将这个**已连接的Socket 放⼊到⼀个队列**里，然后线程池⾥的线程负责从队列中取出已连接 Socket 进程处理。这样就避免为每一个客户端都要创建线程带来的资源浪费，使得线程可以重用。

​		但是线程池也有它的弊端，如果连接大多是长连接，因此可能会导致在一段时间内，线程池中的线程都被占用，那么当再有用户请求连接时，由于没有可用的空闲线程来处理，就会导致客户端连接失败，从而影响用户体验。因此，线程池比较适合大量的**短连接**应用。

#### 4.3、如何实现线程池？

##### 多线程安全问题？

##### 怎么解决

##### 多个线程对于同一元素的操作会导致什么？



#### 4.4、多线程和多进程的区别

<img src="总结面试题.assets/Image-16309158874851.png" alt="Image" style="zoom: 80%;" />

### 5、中断和异常

#### 5.1、中断

​		大家都知道，当我们在敲击键盘的同时就会产生中断，当硬盘读写完数据之后也会产生中断，所以，我们需要知道，中断是由硬件设备产生的，而它们从物理上说就是电信号，之后，它们通过中断控制器发送给CPU，接着CPU判断收到的中断来自于哪个硬件设备（这定义在内核中），最后，由CPU发送给内核，有内核处理中断。下面这张图显示了中断处理的流程：

![image-20210922112515883](总结面试题.assets/image-20210922112515883.png)

#### 5.2、异常

​		我们在学习《计算机组成原理》的时候会知道两个概念，CPU处理程序的时候一旦程序不在内存中，会产生缺页异常；当运行除法程序时，当除数为0时，又会产生除0异常。所以，大家也需要记住的是，**异常是由CPU产生的，同时，它会发送给内核，要求内核处理这些异常**，下面这张图显示了异常处理的流程：

![image-20210922112556486](总结面试题.assets/image-20210922112556486.png)

#### 5.3、外中断和异常的区别

##### 1、相同点

- 最后都是由CPU发送给内核，由内核去处理
- 处理程序的流程设计上是相似的

##### 2、不同点

- 产生源不相同，异常是由CPU产生的，而中断是由硬件设备产生的
- 内核需要根据是异常还是中断调用不同的处理程序
- 中断不是时钟同步的，这意味着中断可能随时到来；异常由于是CPU产生的，所以它是时钟同步的
- 当处理中断时，处于中断上下文中；处理异常时，处于进程上下文中

​		总的来说：外中断是指由 CPU 执行指令以外的事件引起，如 I/O 完成中断，表示设备输入/输出处理已经完成，处理器能够发送下一个输入/输出请求。此外还有时钟中断、控制台中断等。而异常时由 CPU 执行指令的内部事件引起，如非法操作码、地址越界、算术溢出等。

#### 5.4、Linux接收网络包的流程

​		最基本的触发方式：**中断**，但是，如果在高性能网络场景下，网络包的数量非常多，就会导致非常多的中断，然后频繁触发中断，影响系统的整体效率。为了解决这个问题，引入**NAPI机制：中断 + 轮询**，核心是**不**采用中断的方式读取数据，而是首先**采用中断唤醒数据接收的服务程序，然后poll的方法来轮询数据。**

​		⽐如，当有⽹络包到达时，⽹卡发起硬件中断，于是会执⾏⽹卡硬件中断处理函数，**中断处理函数处理完需要「暂时屏蔽中断」，然后唤醒「软中断」来轮询处理数据，直到没有新数据时才恢复中断，这样⼀次中断处理多个⽹络包**，于是就可以降低⽹卡中断带来的性能开销。



### 6、死锁

​		**死锁是指两个（多个）线程相互等待对方数据的过程，死锁的产生会导致程序卡死，不解锁程序将永远无法进行下去。**

#### 6.1、死锁产生的原因

​		举个例子：两个线程A和B，两个数据1和2。线程A在执行过程中，首先对资源1加锁，然后再去给资源加锁，但是由于线程的切换，导致线程A没能给资源2加锁。线程切换到B后，线程B先对资源2加锁，然后再去给资源1加锁，由于资源1已经被线程A加锁，因此线程B无法加锁成功，当线程切换为A时，A也无法成功对资源2加锁，由此就造成了线程AB双方相互对一个已加锁资源的等待，死锁产生。	

#### 6.2、死锁的必要条件

- **互斥条件**：进程对所需求的资源具有排他性，若有其他进程请求该资源，请求进程只能等待。

- **不剥夺条件**：进程在所获得的资源未释放前，不能被其他进程强行夺走，只能自己释放。

-  **请求和保持条件**：进程当前所拥有的资源在进程请求其他新资源时，由该进程继续占有。

- **循环等待条件**：存在一种进程资源循环等待链，链中每个进程已获得的资源同时被链中下一个进程所请求。

#### 6.3、死锁的解决方案

​		保证上锁的顺序一致

#### 6.4、如何排除死锁问题

##### 1、鸵鸟策略

​		把头埋在沙子里，假装根本没发生问题。因为解决死锁问题的代价很高，因此鸵鸟策略这种不采取任务措施的方案会获得更高的性能。当发生死锁时不会对用户造成多大影响，或发生死锁的概率很低，可以采用鸵鸟策略。大多数操作系统，包括 Unix，Linux 和 Windows，处理死锁问题的办法仅仅是忽略它。

##### 2、死锁检测与死锁恢复

###### 1）死锁检测

​		不试图阻止死锁，而是当检测到死锁发生时，采取措施进行恢复。

- 每种类型一个资源的死锁检测
- 每种类型多个资源的死锁检测

###### 2）死锁恢复

- 利用抢占恢复
- 利用回滚恢复
- 通过杀死进程恢复

##### 3、死锁预防

​		在程序运行之前预防发生死锁。

- 破坏互斥条件

   例如假脱机打印机技术允许若干个进程同时输出，唯一真正请求物理打印机的进程是打印机守护进程。

- 破坏请求和保持条件

  一种实现方式是规定所有进程在开始执行前请求所需要的全部资源。

- 破坏不剥夺条件

  允许抢占资源

- 破坏循环请求等待

  给资源统一编号，进程只能按编号顺序来请求资源。

##### 4、死锁避免



#### 6.5、死锁的预防

​		在程序运行之前预防发生死锁，即破坏死锁的必要条件。

- 破坏互斥条件：例如假脱机打印机技术允许若干个进程同时输出，唯一真正请求物理打印机的进程是打印机守护进程。

- 破坏请求和保持条件：一种实现方式是规定所有进程在开始执行前请求所需要的全部资源。

- 破坏不剥夺条件：允许抢占资源

- 破坏循环请求等待：给资源统一编号，进程只能按编号顺序来请求资源。



### 7、常见的锁

​		多线程访问共享资源的时候，避免不了资源竞争⽽导致数据错乱的问题，所以我们通常为了解决这⼀问题，都会在访问共享资源之前加锁。最常⽤的就是互斥锁，当然还有很多种不同的锁，⽐如⾃旋锁、读写锁、乐观锁等，不同种类的锁⾃然适⽤于不同的场景。

​		加锁的**目的**：保证共享资源在任意时间⾥，只有⼀个线程访问，这样就可以避免多线程导致共享数据错乱的问题。当已经有⼀个线程加锁后，其他线程加锁则就会失败，互斥锁和⾃旋锁对于加锁失败后的处理⽅式是不⼀样的：

- 互斥锁加锁失败后，线程会释放 **CPU** ，给其他线程；
- ⾃旋锁加锁失败后，线程会忙等待，直到它拿到锁；

#### 7.1、互斥锁与自旋锁

##### 1、互斥锁

​		互斥锁是⼀种「独占锁」，⽐如当线程 A 加锁成功后，此时互斥锁已经被线程 A 独占了，只要线程 A 没有释放⼿中的锁，线程 B 加锁就会失败，于是就会释放 CPU 让给其他线程，既然线程 **B** 释放掉了 **CPU**，⾃然线程 **B** 加锁的代码就会被阻塞。对于互斥锁加锁失败⽽阻塞的现象，是由操作系统内核实现的。当加锁失败时，内核会将线程置为「睡眠」状态，等到锁被释放后，内核会在合适的时机唤醒线程，当这个线程成功获取到锁后，于是就可以继续执⾏。

![image-20210922151133694](总结面试题.assets/image-20210922151133694.png)

​		所以，互斥锁加锁失败时，会从⽤户态陷⼊到内核态，让内核帮我们切换线程，虽然简化了使⽤锁的难度，但是存在⼀定的**性能开销**成本。性能开销主要是会有两次线程上下文切换的成本：

- 当线程加锁失败时，内核会把线程的状态从「运⾏」状态设置为「睡眠」状态，然后把 CPU 切换给其他线程运⾏；
- 接着，当锁被释放时，之前「睡眠」状态的线程会变为「就绪」状态，然后内核会在合适的时间，把CPU 切换给该线程运⾏。

##### 线程的上下文切换是什么？

​		当两个线程是属于同⼀个进程，因为虚拟内存是共享的，所以在切换时，虚拟内存这些资源就保持不动，只需要切换线程的私有数据、寄存器等不共享的数据。

##### 2、自旋锁

###### 1）实现原理

​		⾃旋锁是通过 CPU 提供的 CAS 函数（*Compare And Swap*），在「⽤户态」完成加锁和解锁操作，不会主动产⽣线程上下⽂切换，所以相⽐互斥锁来说，会快⼀些，开销也⼩⼀些。

​		⼀般加锁的过程，包含两个步骤：

- 第⼀步，查看锁的状态，如果锁是空闲的，则执⾏第⼆步；
- 第⼆步，将锁设置为当前线程持有；

​		CAS 函数就把这两个步骤合并成⼀条硬件级指令，形成原⼦指令，这样就保证了这两个步骤是不可分割的，要么⼀次性执⾏完两个步骤，要么两个步骤都不执⾏。

​		使⽤⾃旋锁的时候，当发⽣多线程竞争锁的情况，加锁失败的线程会「忙等待」，直到它拿到锁。这⾥的「忙等待」可以⽤ **while** 循环等待实现，不过最好是使⽤ CPU 提供的 **PAUSE** 指令来实现「忙等待」，因为可以减少循环等待时的耗电量。

​		⾃旋锁是最⽐较简单的⼀种锁，⼀直⾃旋，利⽤ CPU 周期，直到锁可⽤。需要注意，在单核 **CPU** 上，需要抢占式的调度器（即不断通过时钟中断⼀个线程，运⾏其他线程）。否则，⾃旋锁在单 **CPU** 上⽆法使⽤，因为⼀个⾃旋的线程永远不会放弃 **CPU**。

###### 2）特点

​		⾃旋锁开销少，在多核系统下⼀般不会主动产⽣线程切换，适合异步、协程等在⽤户态切换请求的编程⽅式，但如果被锁住的代码执⾏时间过⻓，⾃旋的线程会⻓时间占⽤ CPU 资源，所以⾃旋的时间和被锁住的代码执⾏的时间是成「正⽐」的关系，我们需要清楚的知道这⼀点。

​		⾃旋锁与互斥锁使⽤层⾯⽐较相似，但实现层⾯上完全不同：当加锁失败时，互斥锁⽤「线程切换」来应对，⾃旋锁则⽤「忙等待」来应对。

#### 7.2、读写锁

​		读写锁从字⾯意思我们也可以知道，它由「读锁」和「写锁」两部分构成，如果只读取共享资源⽤「读锁」加锁，如果要修改共享资源则⽤「写锁」加锁。所以，**读写锁适用于能明确区分读操作和写操作的场景**。

**工作原理**

- 当「写锁」没有被线程持有时，多个线程能够并发地持有读锁，这⼤⼤提⾼了共享资源的访问效率，因为「读锁」是⽤于读取共享资源的场景，所以多个线程同时持有读锁也不会破坏共享资源的数据。
- 但是，⼀旦「写锁」被线程持有后，读线程的获取读锁的操作会被阻塞，⽽且其他写线程的获取写锁的操作也会被阻塞。

​		写锁是独占锁，因为任何时刻只能有⼀个线程持有写锁，类似互斥锁和⾃旋锁，⽽读锁是共享锁，因为读锁可以被多个线程同时持有。

#### 7.3、悲观锁与乐观锁

​		前⾯提到的互斥锁、⾃旋锁、读写锁，都是属于悲观锁。

- **悲观锁**：认为多线程同时修改共享资源的概率⽐较⾼，于是很容易出现冲突，所以访问共享资源前，先要上锁。
- **乐观锁**：它假定冲突的概率很低，它的⼯作⽅式是：先修改完共享资源，再验证这段时间内有没有发⽣冲突，如果没有其他线程在修改资源，那么操作完成，如果发现有其他线程已经修改过这个资源，就放弃本次操作。**乐观锁全程并没有加锁，所以它也叫无锁编程。**



### 8、调度算法

#### 8.1、进程调度算法

##### 1、先来先服务FCFS

​		非抢占式调度算法，按照请求的顺序进行调度。有利于长作业，不利于短作业，短作业必须等长作业执行完毕才执行，长作业耗时又很长，这样会导致短作业等待时间过长。

##### 2、短作业优先SJF

​		非抢占式调度算法，按预估运行时间最短的顺序进行调度。**长**作业有可能会**饿死**，处于一直等待短作业执行完毕的状态，要是一直一直有短作业来，长作业永远得不到调度。

##### 3、最短剩余时间优先SRTN

​		最短作业优先的抢占式版本，按照剩余运行时间的顺序进行调度，一个新作业到大，整个运行时间与当前进程的剩余时间做比较。要是新的进程需要时间更少，就挂起当前的进程，运行新的进程。

##### 4、时间片轮转

​		将所有就绪进程按照FCFS的原则排成一个队列，每次调度，把CPU的时间分给队首进程，该进程可以执行一个时间片。时间片用完了，计时器会发出时钟中断，调度程序便停止该进程的执行，并将它送往就绪队列的末尾，然后继续把CPU时间分配给队首进程。所以其实这个算法的效率跟时间片的大小有很大的关系：

- 因为进程切换都要保存进程的信息并载入新进程的信息，要是时间片太小，会导致进程切换的太频繁，在进程切换上会花过多的时间；
- 时间片过长，那实时性就不能保证。

##### 5、优先级调度

​		为每个进程分配一个优先级，按优先级进行调度。为了防止优先级低的进程永远等不到调度，可以随着时间的推移增加等待进程的优先级。

##### 6、多级反馈队列

​		一个进程需要执行100个时间片，要是采用时间片轮转调度算法，就需要交换100次。那多级队列是为这种需要连续执行多个时间片的进程考虑，会设置时间片大小不用的队列（比如：1，2，4，8，32），进程在第一个队列没有执行完，就会被移到下一个队列，这样一来需要执行100个时间片的进程，只需要交换7次了。同时，每个队列优先级也不同，最上面的优先级最高，所以只有上一个队列没有进程在排队，才能调度当前队列上的进程。所以可以把多级反馈队列这种算法，看作是时间片轮转调度和优先级调度算法的结合版。

![image-20210922102925450](总结面试题.assets/image-20210922102925450.png)

#### 8.2、页面置换算法

##### 1、最佳置换算法OPT

​		最佳置换算法(OPT，Optimal) :每次选择淘汰的页面将是以后永不使用，或者在最长时间内不再被访问的页面，这样可以保证最低的缺页率。最佳置换算法可以保证最低的缺页率，但实际上，只有在进程执行的过程中才能知道接下来会访问到的是哪个页面。操作系统无法提前预判页面访问序列。因此，最佳置换算法是无法实现的。

##### 2、先进先出置换算法FIFO

​		先进先出置换算法(FIFO) :每次选择淘汰的页面是最早进入内存的页面

- 实现方法:把调入内存的页面根据调入的先后顺序排成一个队列，需要换出页面时选择队头页面队列的最大长度取决于系统为进程分配了多少个内存块。
- FIFO的性能较差，因为较早调入的页往往是经常被访问的页，这些页在FIFO算法下被反复调入和调出，并且有Belady现象。所谓Belady现象是指：采用FIFO算法时，如果对—个进程未分配它所要求的全部页面，有时就会出现分配的页面数增多但缺页率反而提高的异常现象。

##### 3、最近最久未使用置换算法LRU

​		最近最久未使用置换算法(LRU，least recently used) :每次淘汰的页面是最近最久未使用的页面。

- 实现方法:赋予每个页面对应的页表项中，用访问字段记录该页面自.上次被访问以来所经历的时间t(该算法的实现需要专门的硬件支持，虽然算法性能好，但是实现困难，开销大)。当需要淘汰一个页面时，选择现有页面中t值最大的，即最近最久未使用的页面。
- LRU性能较好，但需要寄存器和栈的硬件支持。LRU是堆栈类算法，理论上可以证明，堆栈类算法不可能出现Belady异常。

##### 4、时钟置换算法CLOCK

​		最佳置换算法性OPT能最好，但无法实现；先进先出置换算法实现简单，但算法性能差；最近最久未使用置换算法性能好，是最接近OPT算法性能的，但是实现起来需要专门的硬件支持，算法开销大。所以操作系统的设计者尝试了很多算法，试图用比较小的开销接近LRU的性能，这类算法都是CLOCK算法的变体，因为算法要循环扫描缓冲区像时钟一样转动。所以叫clock算法。

​		时钟置换算法是一种性能和开销较均衡的算法，又称CLOCK算法，或最近未用算法(NRU，Not Recently Used)。简单的CLOCK算法实现方法:为每个页面设置一个访问位，再将内存中的页面都通过链接指针链接成一个循环队列。当某页被访问时，其访问位置为1。当需要淘汰-一个页面时，只需检查页的访问位。如果是0，就选择该页换出;如果是1，则将它置为0，暂不换出，继续检查下一个页面，若第- - ~轮扫描中所有页面都是1，则将这些页面的访问位依次置为0后，再进行第二轮扫描(第二轮扫描中一定会有访问位为0的页面，因此简单的CLOCK算法选择–个淘汰页面最多会经过两轮扫描) 。

![image-20210922145127549](总结面试题.assets/image-20210922145127549.png)

##### 5、改进型的时钟置换算法

​		简单的时钟置换算法仅考虑到一个页面最近是否被访问过。事实上，如果被淘汰的页面没有被修改过,就不需要执行I/O操作写回外存。只有被淘汰的页面被修改过时，才需要写回外存。

​		因此，除了考虑一个页面最近有没有被访问过之外，操作系统还应考虑页面有没有被修改过。在其他条件都相同时，应优先淘汰没有修改过的页面，避免I/O操作。这就是改进型的时钟置换算法的思想。修改位=0，表示页面没有被修改过;修改位=1，表示页面被修改过。为方便讨论，用(访问位，修改位)的形式表示各页面状态。如(1, 1)表示一个页面近期被访问过，且被修改过。

​		改进型的Clock算法需要综合考虑某一内存页面的访问位和修改位来判断是否置换该页面。在实际编写算法过程中，同样可以用一个等长的整型数组来标识每个内存块的修改状态。访问位A和修改位M可以组成一下四种类型的页面。

##### 6、总结

| 算法        | 规则                                                         | 优缺点                                         |
| ----------- | ------------------------------------------------------------ | ---------------------------------------------- |
| OPT         | 优先淘汰最长时间内不会被访问的页面                           | 缺页率最小，性能最好，但无法实现               |
| FIFO        | 优先淘汰最先进入内存的页面                                   | 实现简单，但性能很差，可能出现Belady异常       |
| LRU         | 优先淘汰最近最久没访问的页面                                 | 性能很好，但需要硬件支持，算法开销大           |
| CLOCK       | 循环扫描各页面，第一轮淘汰访问位=0，并将扫描过的页面访问位改为1.若第一轮没选中，则进行第二轮扫描 | 实现简单，算法开销小，但未考虑页面是否被修改过 |
| 改进型CLOCK | 若用(访问位，修改位)的形式表述，则 第一轮:淘汰(0,0) 第二轮:淘汰(O,1)，并将扫描过的页面访问位都置为0 第三轮:淘汰（O,0），第四轮淘汰（0,1） | 算法开销小，性能较稳定                         |



#### 8.3、动态分区算法

##### 1、首次适应算法

- 算法思想：每次都从低地址开始查找，找到第–个能满足大小的空闲分区。
- 如何实现：空闲分区以地址递增的次序排列。每次分配内存时顺序查找空闲分区链( 或空闲分[表)，找到大小能满足要求的第-一个空闲分区。

![image-20210922105032522](总结面试题.assets/image-20210922105032522.png)

##### 2、最佳适应算法

- 算法思想:由于动态分区分配是一种连续分配方式，为各进程分配的空间必须是连续的一整片区域。因此为了保证当“大进程”到来时能有连续的大片空间，可以尽可能多地留下大片的空闲区,即，优先使用更小的空闲区。
- 如何实现:空闲分区按容量递增次序链接。每次分配内存时顺序查找空闲分区链(或空闲分区表)，找到大小能满足要求的第-一个空闲分区。

![image-20210922105011391](总结面试题.assets/image-20210922105011391.png)

##### 3、最坏适应算法

- 又称最大适应算法(Largest Fit)
- 算法思想:为了解决最佳适应算法的问题—即留下太多难以利用的小碎片，可以在每次分配时优先使用最大的连续空闲区，这样分配后剩余的空闲区就不会太小，更方便使用。
- 如何实现:空闲分区按容量递减次序链接。每次分配内存时顺序查找空闲分区链(或空闲分区表)，找到大小能满足要求的第-一个空闲分区。

![image-20210922105048814](总结面试题.assets/image-20210922105048814.png)

##### 4、邻近适应算法

- 算法思想：首次适应算法每次都从链头开始查找的。这可能会导致低地址部分出现很多小的空闲分区，而每次分配查找时，都要经过这些分区，因此也增加了查找的开销。如果每次都从上次查找结束的位置开始检索，就能解决上述问题。
- 如何实现：空闲分区以地址递增的顺序排列(可排成-一个循环链表)。每次分配内存时从上次查找结束的位置开始查找空闲分区链(或空闲分区表)，找到大小能满足要求的第一个空闲分区。

![image-20210922105101866](总结面试题.assets/image-20210922105101866.png)

##### 5、总结

![Image](总结面试题.assets/Image-16322786162015.png)

#### 8.4、磁盘调度算法

​	读写一个磁盘块的时间的影响因素有：

- 旋转时间（主轴转动盘面，使得磁头移动到适当的扇区上）

- 寻道时间（制动手臂移动，使得磁头移动到适当的磁道上）

- 实际的数据传输时间

  其中，寻道时间最长，因此磁盘调度的主要目标是使磁盘的平均寻道时间最短。

##### 1、先来先服务

​		按照磁盘请求的顺序进行调度。

​		优点是公平和简单。缺点也很明显，因为未对寻道做任何优化，使平均寻道时间可能较长。

##### 2、最短寻道时间优先

​		优先调度与当前磁头所在磁道距离最近的磁道。

​		虽然平均寻道时间比较低，但是不够公平。如果新到达的磁道请求总是比一个在等待的磁道请求近，那么在等待的磁道请求会一直等待下去，也就是出现饥饿现象。具体来说，两端的磁道请求更容易出现饥饿现象。

##### 3、电梯扫描算法

​		电梯总是保持一个方向运行，直到该方向没有请求为止，然后改变运行方向。

​		电梯算法（扫描算法）和电梯的运行过程类似，总是按一个方向来进行磁盘调度，直到该方向上没有未完成的磁盘请求，然后改变方向。因为考虑了移动方向，因此所有的磁盘请求都会被满足，解决了 SSTF 的饥饿问题。



### 9、零拷贝

#### 9.1、为什么要有DMA技术？

##### 1、在没有 DMA 技术前，I/O 的过程：

- CPU 发出对应的**指令**给磁盘控制器，然后返回；
- 磁盘控制器收到指令后，于是就开始准备数据，会把数据放⼊到磁盘控制器的内部缓冲区中，然后产⽣⼀个**中断**；
- CPU 收到中断信号后，停下⼿头的⼯作，接着把磁盘控制器的缓冲区的数据⼀次⼀个字节地读进⾃⼰的寄存器，然后再把寄存器⾥的数据**写⼊到内存**，⽽在数据传输的期间 **CPU 是⽆法执⾏其他任务**的。

##### 2、什么是DMA技术？

​		**DMA（Direct Memory Access）：直接内存访问**，核心是**在进行I/O设备和内存的数据传输的时候，数据搬运的工作全部交给DMA控制器，而CPU不再参与任何与数据搬运相关的事情**，这样CPU就可以去处理其他事务。

##### 3、有DMA技术后，I/O的过程：

- **用户调用read()**，向操作系统**发出I/O请求**，请求读取数据到自己的内存缓冲区中，进程进入**阻塞**状态；
- 操作系统接收到I/O请求后，进一步将I/O请求**发送DMA**，然后CPU执行其他任务
- DMA将I/O请求**发送**给**磁盘**；
- 磁盘收到 DMA 的 I/O 请求，把数据从磁盘读取到磁盘控制器的缓冲区中，当磁盘控制器的**缓冲区**被**读满**后，向 DMA 发起**中断**信号，告知⾃⼰缓冲区已满；
- **DMA** 收到磁盘的信号，将磁盘控制器缓冲区中的数据**拷⻉到内核**缓冲区中，此时不占⽤ **CPU**，**CPU**可以执⾏其他任务； 
- 当 DMA 读取了⾜够多的数据，就会发送**中断**信号给 CPU；
- CPU 收到 DMA 的信号，知道数据已经准备好，于是将数据从**内核**拷⻉到**⽤户**空间，系统调⽤**返回**；



#### 9.2、如何优化文件传输性能?

##### 1、传统的I/O工作方式

​		传统的I/O工作方式是：数据读取和写入都是从用户空间到内核空间来回复制，而内核空间的数据是通过操作系统层面的I/O接口从磁盘读取或写入。

```c++
//两个系统调用函数：
read(file, tmp_buf, len);
write(socket, tmp_buf, len);
```

<img src="总结面试题.assets/image-20210902113500321.png" alt="image-20210902113500321" style="zoom: 80%;" />

​		期间，总共发生**4次用户态与内核态的上下文切换**（两次DMA拷贝，两次CPU拷贝），两次系统调用，每一次系统调用都需要从用户态 < — > 内核态。

- 第⼀次拷⻉，把**磁盘**上的数据拷⻉到操作系统**内核的缓冲区**⾥，这个拷⻉的过程是通过 **DMA** 搬运的。
- 第⼆次拷⻉，把**内核缓冲区**的数据拷⻉到**⽤户的缓冲区**⾥，于是我们应⽤程序就可以使⽤这部分数据了，这个拷⻉到过程是由 **CPU** 完成的。
- 第三次拷⻉，把刚才拷⻉到**⽤户**的缓冲区⾥的数据，再拷⻉到**内核的 socket** 的缓冲区⾥，这个过程依然还是由 CPU 搬运的。
- 第四次拷⻉，把**内核的 socket** 缓冲区⾥的数据，拷⻉到**⽹卡**的缓冲区⾥，这个过程⼜是由 DMA 搬运的。

**==总结==：要想提高文件传输的性能，就需要减少「⽤户态与内核态的上下⽂切换」和「内存拷⻉」的次数**。

##### 2、如何优化文件传输效率？

###### 1）减少「⽤户态与内核态的上下⽂切换」的次数

- 要想减少上下⽂切换到次数，就要**减少系统调⽤**的次数

###### 2）减少「数据拷⻉」的次数

- 因为⽂件传输的应⽤场景中，在⽤户空间我们并不会对数据「再加⼯」，所以数据实际上可以不⽤搬运到⽤户空间，因此⽤户的缓冲区是没有必要存在的，即「从内核的读缓冲区拷⻉到⽤户的缓冲区⾥，再从⽤户的缓冲区⾥拷⻉到 socket 的缓冲区⾥」，这个过程是没有必要的。



#### 9.3、如何实现零拷贝？

实现零拷贝两种方式：

- mmap + write
- sendfile

##### 1、mmap + write

​		read()系统调用的过程中会把内核缓冲区的数据拷贝到用户的缓冲区里，为了减少这一步开销，可以用mmap() 替换 read()，m**map() 系统调⽤函数会直接把内核缓冲区⾥的数据「映射」到⽤户空间**，这样，操作系统内核与⽤户空间就不需要再进⾏任何的数据拷⻉操作。通过使用mmap() 替换 read() ,可以减少一次数据拷贝的过程。

```C++
//用mmap()函数替换read()
buf = mmap(file, len);
write(sockfd, buf, len);
```

<img src="总结面试题.assets/image-20210902153044605.png" alt="image-20210902153044605" style="zoom: 67%;" />

##### 2、sendfile

```c++
#include <sys/socket.h>
ssize_t sendfile(int out_fd, int in_fd, off_t *offset, size_t count);
//返回实际复制数据的长度
```

​		该系统调⽤，可以直接把内核缓冲区⾥的数据拷⻉到 socket 缓冲区⾥，不再拷⻉到⽤户态，这样就只有 2 次上下⽂切换，和 3 次数据拷⻉。

<img src="总结面试题.assets/image-20210902153509944.png" alt="image-20210902153509944" style="zoom:80%;" />

##### 3、零拷贝

​		如果⽹卡⽀持 **SG-DMA**（*The Scatter-Gather Direct Memory Access*）技术（和普通的 DMA 有所不同），可以进⼀步减少通过CPU 把内核缓冲区⾥的数据拷⻉到 socket缓冲区的过程。

```c++
//查看网卡是否支持scatter-gather
$ ethtool -k eth0 | grep scatter-gather
scatter-gather: on
```

###### 1）实现步骤：

- 通过 DMA 将磁盘上的数据拷⻉到内核缓冲区⾥；
- 缓冲区描述符和数据⻓度传到 socket 缓冲区，这样⽹卡的 SG-DMA 控制器就可以直接将内核缓存中的数据拷⻉到⽹卡的缓冲区⾥，此过程不需要将数据从操作系统内核缓冲区拷⻉到 socket缓冲区中，这样就减少了⼀次数据拷⻉

<img src="总结面试题.assets/image-20210902154042312.png" alt="image-20210902154042312" style="zoom:67%;" />

###### 2）零拷贝技术

- 这就是所谓的**零拷贝（Zero-copy）技术，因为我们没有在内存层面去拷贝数据，也就是说全程没有通过CPU 来搬运数据，所有的数据都是通过 DMA 来进⾏传输的**。
- 零拷贝技术的⽂件传输⽅式相⽐传统⽂件传输的⽅式，减少了 2 次上下⽂切换和数据拷⻉次数，**只需要2次上下文切换和数据拷贝次数，就可以完成文件的传输，⽽且 2 次的数据拷贝过程，都不需要通过 CPU，2 次都是由 DMA 来搬运。**
- 所以，总体来看，零拷贝技术可以把⽂件传输的性能**提⾼**⾄少⼀倍以上。

###### 3）应用

- Nginx 也⽀持零拷⻉技术，⼀般默认是开启零拷⻉技术，这样有利于提⾼⽂件传输的效率。

#### 9.4、PageCache有什么作用？

##### 1、什么是PageCache？

​		磁盘⾼速缓存（**PageCache**）：即上述的由磁盘文件拷贝到内核缓冲区。由于读写磁盘比读写内存速度慢，但是内存往往也是有限的，所以就需要考虑哪些数据应该搬到内存中去？--PageCache

​		【局部性原理】：刚被访问是数据在短时间内再次被访问的概率较高。**PageCache一般用于缓存最近被访问的数据，当空间不⾜时淘汰最久未被访问的缓存(LRU)**。所以，在读磁盘数据的时候，优先在PageCache中查找，如果存在，则直接返回；如果不存在，则从磁盘中读取，然后缓存在PageCache中。

##### 2、PageCache优点

- 缓存最近被访问的数据
- 预读功能
  - 假设 read ⽅法每次只会读 32 KB 的字节，虽然 read 刚开始只会读 0 ～ 32 KB 的字节，但内核会把其后⾯的 32～64 KB 也读取到 PageCache，这样后⾯读取 32～64 KB 的成本就很低，如果在 32～64KB 淘汰出 PageCache 前，进程读取到它了，收益就⾮常⼤

##### 3、缺点

- 但是，在传输⼤⽂件（**GB** 级别的⽂件）的时候，**PageCache** 会不起作⽤，那就⽩⽩浪费 **DMA** 多做的⼀次数据拷⻉，造成性能的降低，即使使⽤了 **PageCache** 的零拷⻉也会损失性能。
- 由于⽂件太⼤，可能某些部分的⽂件数据被再次访问的概率⽐较低，会导致另外两个问题：
  - PageCache 由于⻓时间被⼤⽂件占据，其他「热点」的⼩⽂件可能就⽆法充分使⽤到 PageCache，于是这样磁盘读写的性能就会下降了；
  - PageCache 中的⼤⽂件数据，由于没有享受到缓存带来的好处，但却耗费 DMA 多拷⻉到PageCache ⼀次。

**SO**：针对**大文件**的传输，不应该使⽤ PageCache，也就是说不应该使⽤零拷⻉技术，因为可能由于PageCache 被⼤⽂件占据，⽽导致「热点」⼩⽂件⽆法利⽤到 PageCache，这样在⾼并发的环境下，会带来严重的性能问题。

#### 9.5、大文件如何传输？

​		在⾼并发的场景下，针对⼤⽂件的传输的⽅式，应该使⽤「异步 **I/O +** 直接 **I/O**」来替代零拷⻉技术。

##### 1、直接I/O



##### 2、异步I/O

​		异步I/O主要解决进程阻塞问题，异步 I/O 并没有涉及到 PageCache，所以使⽤异步 I/O 就意味着要绕开PageCache

##### 3、直接 I/O 应⽤场景常⻅的两种：

- 应⽤程序已经实现了磁盘数据的缓存，那么可以不需要 PageCache 再次缓存，减少额外的性能损耗。在 MySQL 数据库中，可以通过参数设置开启直接 I/O，默认是不开启；

- 传输⼤⽂件的时候，由于⼤⽂件难以命中 PageCache 缓存，⽽且会占满 PageCache 导致「热点」⽂件⽆法充分利⽤缓存，从⽽增⼤了性能开销，因此，这时应该使⽤直接 I/O。

另外，由于直接 I/O 绕过了 PageCache，就⽆法享受内核的这两点的优化：

- 内核的 I/O 调度算法会缓存尽可能多的 I/O 请求在 PageCache 中，最后**「合并」**成⼀个更⼤的 I/O请求再发给磁盘，这样做是为了减少磁盘的寻址操作；

- 内核也会**「预读」**后续的 I/O 请求放在 PageCache 中，⼀样是为了减少对磁盘的操作；

##### 4、传输大文件「异步 I/O + 直接 I/O」

​		于是，传输⼤⽂件的时候，使⽤「异步 I/O + 直接 I/O」了，就可以⽆阻塞地读取⽂件了。所以，传输⽂件的时候，我们要根据⽂件的⼤⼩来使⽤不同的⽅式：

- 传输⼤⽂件的时候，使⽤「异步 I/O + 直接 I/O」；

- 传输⼩⽂件的时候，则使⽤「零拷⻉技术」；

#### **==总结==**

​		早期 I/O 操作，内存与磁盘的数据传输的⼯作都是由 CPU 完成的，⽽此时 CPU 不能执⾏其他任务，会特别浪费 CPU 资源。

​		于是，为了解决这⼀问题，DMA 技术就出现了，每个 I/O 设备都有⾃⼰的 DMA 控制器，通过这个 DMA控制器，CPU 只需要告诉 DMA 控制器，我们要传输什么数据，从哪⾥来，到哪⾥去，就可以放⼼离开了。后续的实际数据传输⼯作，都会由 DMA 控制器来完成，CPU 不需要参与数据传输的⼯作。

​		传统 IO 的⼯作⽅式，从硬盘读取数据，然后再通过⽹卡向外发送，我们需要进⾏ 4 上下⽂切换，和 4 次数据拷⻉，其中 2 次数据拷⻉发⽣在内存⾥的缓冲区和对应的硬件设备之间，这个是由 DMA 完成，另外2 次则发⽣在内核态和⽤户态之间，这个数据搬移⼯作是由 CPU 完成的。

​		为了提⾼⽂件传输的性能，于是就出现了零拷⻉技术，它通过⼀次系统调⽤（ sendfile ⽅法）合并了磁盘读取与⽹络发送两个操作，降低了上下⽂切换次数。另外，拷⻉数据都是发⽣在内核中的，天然就降低了数据拷⻉的次数。

​		Kafka 和 Nginx 都有实现零拷⻉技术，这将⼤⼤提⾼⽂件传输的性能。

​		零拷⻉技术是基于 PageCache 的，PageCache 会缓存最近访问的数据，提升了访问缓存数据的性能，同时，为了解决机械硬盘寻址慢的问题，它还协助 I/O 调度算法实现了 IO 合并与预读，这也是顺序读⽐随机读性能好的原因。这些优势，进⼀步提升了零拷⻉的性能。

​		需要注意的是，零拷⻉技术是不允许进程对⽂件内容作进⼀步的加⼯的，⽐如压缩数据再发送。

​		另外，当传输⼤⽂件时，不能使⽤零拷⻉，因为可能由于 PageCache 被⼤⽂件占据，⽽导致「热点」⼩

​		⽂件⽆法利⽤到 PageCache，并且⼤⽂件的缓存命中率不⾼，这时就需要使⽤「异步 IO + 直接 IO 」的⽅式。

​		在 Nginx ⾥，可以通过配置，设定⼀个⽂件⼤⼩阈值，针对⼤⽂件使⽤异步 IO 和直接 IO，⽽对⼩⽂件使⽤零拷⻉。



### 10、I/O相关概念

https://www.cnblogs.com/xiaoxi/p/6525396.html

#### 10.1、同步和异步

​		同步就是：如果有多个任务或者事件要发生，这些任务或者事件必须逐个地进行，一个事件或者任务的执行会导致整个流程的暂时等待，这些事件没有办法并发地执行；

​		异步就是：如果有多个任务或者事件发生，这些事件可以并发地执行，一个事件或者任务的执行不会导致整个流程的暂时等待。

​		举个简单的例子：

​		假如有一个任务包括两个子任务A和B，对于同步来说，当A在执行的过程中，B只有等待，直至A执行完毕，B才能执行；而对于异步就是A和B可以并发地执行，B不必等待A执行完毕之后再执行，这样就不会由于A的执行导致整个任务的暂时等待。

同步和异步区别在于：多个任务和事件发生时，一个事件的发生或执行是否会导致整个流程的暂时等待。当多个线程同时访问一个变量时，每个线程访问该变量就是一个事件，对于同步来说，就是这些线程必须逐个地来访问该变量，一个线程在访问该变量的过程中，其他线程必须等待；而对于异步来说，就是多个线程不必逐个地访问该变量，可以同时进行访问。

#### 10.2、阻塞和非阻塞

​		阻塞就是：当某个事件或者任务在执行过程中，它发出一个请求操作，但是由于该请求操作需要的条件不满足，那么就会一直在那等待，直至条件满足；

　　非阻塞就是：当某个事件或者任务在执行过程中，它发出一个请求操作，如果该请求操作需要的条件不满足，会立即返回一个标志信息告知条件不满足，不会一直在那等待。

　　这就是阻塞和非阻塞的区别。也就是说阻塞和非阻塞的区别关键在于当发出请求一个操作时，如果条件不满足，是会一直等待还是返回一个标志信息。

　　举个简单的例子：

　　假如我要读取一个文件中的内容，如果此时文件中没有内容可读，对于阻塞来说就是会一直在那等待，直至文件中有内容可读；而对于非阻塞来说，就会直接返回一个标志信息告知文件中暂时无内容可读。

#### ==总结==

- **同步和异步着重点在于多个任务的执行过程中，一个任务的执行是否会导致整个流程的暂时等待；**

- **而阻塞和非阻塞着重点在于发出一个请求操作时，如果进行操作的条件不满足是否会返会一个标志信息告知条件不满足。**

#### 10.3、阻塞I/O和非阻塞I/O

​		IO操作包括：对硬盘的读写、对socket的读写以及外设的读写。

　　当用户线程发起一个IO请求操作（本文以读请求操作为例），内核会去查看要读取的数据是否就绪，对于阻塞IO来说，如果数据没有就绪，则会一直在那等待，直到数据就绪；对于非阻塞IO来说，如果数据没有就绪，则会返回一个标志信息告知用户线程当前要读的数据没有就绪。当数据就绪之后，便将数据拷贝到用户线程，这样才完成了一个完整的IO读请求操作，也就是说一个完整的IO读请求操作包括两个阶段：

　　**1）查看数据是否就绪；**

　　**2）进行数据拷贝（内核将数据拷贝到用户线程）。**

　　那么阻塞（blocking IO）和非阻塞（non-blocking IO）的区别就在于第一个阶段，如果数据没有就绪，在查看数据是否就绪的过程中是一直等待，还是直接返回一个标志信息。

　　传统的IO都是阻塞IO，比如通过socket来读数据，调用read()方法之后，如果数据没有就绪，当前线程就会一直阻塞在read方法调用那里，直到有数据才返回；而如果是非阻塞IO的话，当数据没有就绪，read()方法应该返回一个标志信息，告知当前线程数据没有就绪，而不是一直在那里等待。

#### 10.4、同步I/O和异步I/O

​		同步IO：如果一个线程请求进行IO操作，在IO操作完成之前，该线程会被阻塞；

​		异步IO：如果一个线程请求进行IO操作，IO操作不会导致请求线程被阻塞。

​		事实上，**同步IO和异步IO模型是针对用户线程和内核的交互来说的**：

- 同步IO：当用户发出IO请求操作之后，如果数据没有就绪，需要通过用户线程或者内核不断地去轮询数据是否就绪，当数据就绪时，再将数据从内核拷贝到用户线程；
- 异步IO：只有IO请求操作的发出是由用户线程来进行的，IO操作的两个阶段都是由内核自动完成，然后发送通知告知用户线程IO操作已经完成。也就是说在异步IO中，不会对用户线程产生任何阻塞。

   这是同步IO和异步IO关键区别所在，**同步IO和异步IO的关键区别反映在数据拷贝阶段是由用户线程完成还是内核完成**。所以说异步IO必须要有操作系统的底层支持。注意同步IO和异步IO与阻塞IO和非阻塞IO是不同的两组概念。

​		阻塞IO和非阻塞IO是反映在当用户请求IO操作时，如果数据没有就绪，是用户线程一直等待数据就绪，还是会收到一个标志信息这一点上面的。也就是说，**阻塞IO和非阻塞IO是反映在IO操作的第一个阶段，在查看数据是否就绪时是如何处理的**。



### 11、五种I/O模型

#### 11.1、阻塞I/O

​		即在**读写数据过程中会发生阻塞现象**。

　　当用户线程发出IO请求之后，内核会去查看数据是否就绪，如果没有就绪就会等待数据就绪，而用户线程就会处于阻塞状态，用户线程交出CPU。当数据就绪之后，内核会将数据拷贝到用户线程，并返回结果给用户线程，用户线程才解除block状态。如果数据没有就绪，就会一直阻塞在read方法。

​        阻塞会带来一定的问题，比如在调用send（）的时候，线程被阻塞，无法响应任何的网络请求，无法适应多客户机、多业务逻辑的网络编程。所以，对于多客户机的网络应用，可以在服务端使用多线程，这样任何一个连接的阻塞都不会影响其他的连接。

#### 11.2、非阻塞I/O

​		进程**反复调用IO函数**（系统多次查询）。

​		当用户线程发起一个read操作后，并不需要等待，而是马上就得到了一个结果。如果结果是一个error时，它就知道数据还没有准备好，于是它可以再次发送read操作。一旦内核中的数据准备好了，并且又再次收到了用户线程的请求，那么它马上就将数据拷贝到了用户线程，然后返回。

​		所以事实上，在非阻塞IO模型中，用户线程需要不断地询问内核数据是否就绪，也就说非阻塞IO不会交出CPU，而会一直占用CPU。对于非阻塞IO就有一个非常严重的问题，在**while循环**中需要不断地去询问内核数据是否就绪，这样会导致CPU占用率非常高，因此一般情况下很少使用while循环这种方式来读取数据。

​		SOCKET设置为非阻塞模式，当所请求的IO无法完成时，不会进入进程睡眠，而是返回一个错误，系统就不断测试数据是否已经准备好，直到数据准备好为止，在不断测试的过程中，会占用大量的CPU时间。创建的SOCKET都是默认阻塞的，非阻塞套接字需要对查询时数据没有准备好的情况进行处理，有些复杂。但是，相对于阻塞套接字，非阻塞套接字对于建立多个连接、数据收发不均匀、时间不定时，有明显的优势。

#### 11.3、多路复用I/O

​		 I/O多路复用：关键是实现同时对多个IO端口进行监听。I/O是指网络I/O，多路是指多个TCP连接（socket或channel），复用是指复用一个线程或几个线程。就是说一个或一组线程处理多个TCP连接，最大的优势是减少了系统开销，不必创建过多的线程/进程，也不用维护这些进程/线程。

​      I/O多路复用是使用两个系统调用（select/poll/epoll和recvfrom），blocking I/O只调用了recvfrom。select/poll/epoll核心是可以同时处理多个connection，在连接数不高的情况下，其性能并不一定比多线程+阻塞I/O好，多路复用模型中，每一个socket，都设置为non-blocking，阻塞是被select这个函数阻塞，而不是被socket阻塞。

​		在多路复用IO模型中，会有一个线程不断去轮询多个socket的状态，只有当socket真正有读写事件时，才真正调用实际的IO读写操作。因为在多路复用IO模型中，只需要使用一个线程就可以管理多个socket，系统不需要建立新的进程或者线程，也不必维护这些线程和进程，并且只有在真正有socket读写事件进行时，才会使用IO资源，所以它大大减少了资源占用。

##### 1、Select

​		select 实现多路复⽤的⽅式是，将已连接的 Socket 都放到⼀个**⽂件描述符集合**，然后调⽤ select 函数将⽂件描述符集合拷⻉到内核⾥，让内核来检查是否有⽹络事件产⽣，检查的⽅式很粗暴，就是通过**遍历**⽂件描述符集合的⽅式，当检查到有事件产⽣后，将此 Socket 标记为**可读或可写**， 接着再把整个⽂件描述符集合**拷⻉**回⽤户态⾥，然后⽤户态还需要再通过**遍历**的⽅法找到可读或可写的 Socket，然后再对其处理。		

​		所以，对于 select 这种⽅式，需要进⾏ **2 次「遍历」文件描述符集合**，⼀次是在内核态⾥，⼀个次是在⽤户态⾥ ，⽽且还会发⽣ **2 次「拷贝」文件描述符集合**，先从⽤户空间传⼊内核空间，由内核修改后，再传出到⽤户空间中。

​		Select 使⽤固定⻓度的 **BitsMap**，表示⽂件描述符集合，⽽且所⽀持的⽂件描述符的个数是有限制的，在Linux 系统中，由内核中的 FD_SETSIZE 限制， 默认最⼤值为 **1024** ，只能监听 0~1023 的⽂件描述符。

​		客户端操作服务器时就会产生这三种文件描述符(简称fd)：writefds(写)、readfds(读)、和exceptfds(异常)。会定时对IO进程查询，没有数据会立即返回。select会阻塞住监视3类文件描述符，等有数据、可读、可写、出异常 或超时、就会返回；返回后通过遍历fdset整个数组来找到就绪的描述符fd，进行对应的IO操作。但是select中的timeval设置成{0，0}；就可以变为非阻塞的，服务器就可以处理更多的事务。

######  1）优点

​		几乎在所有平台上支持，跨平台支持性好

###### 2）缺点

- 但是采用的是轮询方式全盘扫描，会随着文件描述符FD数量增加而性能下降；
- 每次调用select()，需要把fd集合从用户态拷贝到内核态，并进行遍历（消息传递都是从内核到用户空间）；
-  默认单个进程打开的FD有限制1024个，可以修改宏定义，但是效率依然不高。

##### 2、Poll

 		基本原理与select一致，也是轮询+遍历。唯一的区别是poll没有最大文件描述符的限制，用**动态数据**，以**链表**的方式存储fd，突破了BitsMap的文件描述符的限制。

​		poll 和 select 并没有太⼤的本质区别，都是使⽤「线性结构」存储进程关注的 **Socket** 集合，因此都需要遍历⽂件描述符集合来找到可读或可写的 **Socket**，时间复杂度为 **O(n)**，⽽且也需要在⽤户态与内核态之间拷⻉⽂件描述符集合，这种⽅式随着并发数上来，性能的损耗会呈指数级增⻓。

##### 3、epoll

​		epoll 通过两个⽅⾯，很好解决了 select/poll 的问题。

- epoll 在内核⾥使⽤**红⿊树**来跟踪进程所有待检测的⽂件描述字，把需要监控的 socket 通过**epoll_ctl()** 函数加⼊内核中的红⿊树⾥，红⿊树是个⾼效的数据结构，增删查⼀般时间复杂度是O(logn) ，通过对这棵⿊红树进⾏操作，这样就不需要像 select/poll 每次操作时都传⼊整个 socket 集合，只需要传⼊⼀个待检测的 socket，减少了内核和⽤户空间⼤量的数据拷⻉和内存分配。

- epoll 使⽤事件驱动的机制，内核⾥维护了⼀个链表来记录就绪事件，当某个 socket 有事件发⽣时，通过回调函数内核会将其加⼊到这个就绪事件列表中，当⽤户调⽤ **epoll_wait()** 函数时，只会返回有事件发⽣的⽂件描述符的个数，不需要像 select/poll 那样轮询扫描整个 socket 集合，⼤⼤提⾼了检测的效率。

​		没有fd个数的限制，用户拷贝到内核态只需要一次，使用时间通知机制来触发。通过epoll_ctl注册fd，一旦fd就绪就会通过callback回调机制来激活对应的fd，进行相关的IO操作。

- **epoll_create() **系统启动时，在Linux内核里面申请一个红黑树结构文件系统，返回epoll对象，也是一个fd

- **epoll_ctl()** 每新建一个连接，都通过该函数操作epoll对象，在这个对象里面修改添加删除对应的链接fd，绑定一个callback函数

- **epoll_wait()** 轮询所有的callback集合，完成对应的IO操作
  - 注： epoll_wait 实现的内核代码中调⽤了 **__put_user** 函数，这个函数就是将数据从内核拷⻉到⽤户空间。

###### 1）优点

- 没有fd个数限制，所支持的最大个数是操作系统的最大文件句柄数，1G内存大概支持10万个句柄；
- 效率高，使用回调通知而不是轮询的方式，所以效率不会随着FD数量的增多而下降；
- 内核和用户map是同一块内存实现（map是一种内存映射文件的方法，即将一个文件或者其他对象映射到进程的地址空间）

###### 2）epoll两种触发模式

- 边缘触发ET
- 水平触发LT

**ET和LT具体用法：**

- 使⽤边缘触发模式时，当被监控的 Socket 描述符上有可读事件发⽣时，服务器端只会从 **epoll_wait**中苏醒⼀次，即使进程没有调⽤ read 函数从内核读取数据，也依然只苏醒⼀次，因此我们程序要保证⼀次性将内核缓冲区的数据读取完；

- 使⽤⽔平触发模式时，当被监控的 Socket 上有可读事件发⽣时，服务器端不断地从 **epoll_wait** 中苏醒，直到内核缓冲区数据被 **read** 函数读完才结束，⽬的是告诉我们有数据需要读取；

**ET和LT具体区别：**

- ⽔平触发的意思是只要满⾜事件的条件，⽐如内核中有数据需要读，就⼀直不断地把这个事件传递给⽤户；
- ⽽边缘触发的意思是只有第⼀次满⾜条件的时候才触发，之后就不会再传递同样的事件了。

**ET和LT中I/O事件发生：**

- 如果使⽤**LT**⽔平触发模式，当内核通知⽂件描述符可读写时，接下来还可以继续去检测它的状态，看它是否依然可读或可写。所以在收到通知后，没必要⼀次执⾏尽可能多的读写操作。

- 如果使⽤**ET**边缘触发模式，I/O 事件发⽣时只会通知⼀次，⽽且我们不知道到底能读写多少数据，所以在收到通知后应尽可能地读写数据，以免错失读写的机会。因此，我们会**循环**从⽂件描述符读写数据，那么如果⽂件描述符是阻塞的，没有数据可读写时，进程会阻塞在读写函数那⾥，程序就没办法继续往下执⾏。所以，**边缘触发模式⼀般和⾮阻塞 I/O 搭配使⽤**，程序会⼀直执⾏ I/O 操作，直到系统调⽤（如 read 和write ）返回错误，错误类型为 **EAGAIN 或 EWOULDBLOCK** 。

⼀般来说，边缘触发的效率⽐⽔平触发的效率要⾼，因为边缘触发可以减少 epoll_wait 的系统调⽤次数，系统调⽤也是有⼀定的开销的的，毕竟也存在上下⽂的切换。

#### ==总结==select、poll、epoll区别

**三者的效率对比：**

​       100万个连接，里面有1万个是活跃的

​       select：需要建立100w/1024 = 977个进程来支持100W个连接，CPU的性能就特别差；

​       poll：没有连接限制，但是遍历都响应不过来的，而且还有空间的拷贝消耗大量的资源；

​      epoll：请求进来时就创建一个fd并绑定callback，那么就主要遍历1W个活跃的callback即可，既高效又不需要内存拷贝。

##### 深入理解select、poll、epoll：https://blog.csdn.net/wteruiycbqqvwt/article/details/90299610



#### 11.4、信号驱动I/O

​		 在信号驱动IO模型中，当用户线程发起一个IO请求操作，会给对应的socket注册一个信号函数，然后用户线程会继续执行，当内核数据就绪时会发送一个信号给用户线程，用户线程接收到信号之后，便在信号函数中调用IO读写操作来进行实际的IO请求操作。 		 

​		允许接口进行信号驱动I/O，并设置一个信号处理函数，进程继续运行不阻塞，当数据准备好的时候，会收到一个信号，在信号处理函数中调用I/O操作函数处理数据。

#### 11.5、异步I/O

​		异步IO模型才是最理想的IO模型，在异步IO模型中，当用户线程发起read操作之后，立刻就可以开始去做其它的事。而另一方面，从内核的角度，当它收到一个asynchronous read之后，它会立刻返回，说明read请求已经成功发起了，因此不会对用户线程产生任何block。然后，内核会等待数据准备完成，然后将数据拷贝到用户线程，当这一切都完成之后，内核会给用户线程发送一个信号，告诉它read操作完成了。也就说用户线程完全不需要知道实际的整个IO操作是如何进行的，只需要先发起一个请求，当接收内核返回的成功信号时表示IO操作已经完成，可以直接去使用数据了。

　　也就说在异步IO模型中，**IO操作的两个阶段都不会阻塞用户线程**，这两个阶段都是由**内核**自动完成，然后发送一个**信号告知用户线程操作已完成**。用户线程中不需要再次调用IO函数进行具体的读写。

​		但是需要操作系统提供Asynchronous IO 底层支持。

​		**前面四种IO模型实际上都属于同步IO，只有最后一种是真正的异步IO，因为无论是多路复用IO还是信号驱动模型，IO操作的第2个阶段都会引起用户线程阻塞，也就是内核进行数据拷贝的过程都会让用户线程阻塞**



### 12、高性能网络模型

#### 12.1、Reactor

##### 1、Reator模式介绍

​		Reactor 模式也叫 Dispatcher 模式，即 **I/O 多路复⽤监听事件，收到事件后，根据事件类型分配（Dispatch）给某个进程 / 线程**。

- Reactor 模式主要由 Reactor 和处理资源池这两个核⼼部分组成，它俩负责的事情如下：
  - Reactor 负责监听和分发事件，事件类型包含连接事件、读写事件；
  - 处理资源池负责处理事件，如 read -> 业务逻辑 -> send；

- Reactor 模式是灵活多变的，可以应对不同的业务场景，灵活在于：
  - Reactor 的数量可以只有⼀个，也可以有多个；
  - 处理资源池可以是单个进程 / 线程，也可以是多个进程 /线程；

##### 2、单 Reactor 单进程/线程

<img src="总结面试题.assets/image-20210903113647746.png" alt="image-20210903113647746" style="zoom:67%;" />

###### 1）进程⾥有 **Reactor**、**Acceptor**、**Handler**：

- Reactor 对象的作⽤是监听和分发事件；
- Acceptor 对象的作⽤是获取连接；
- Handler 对象的作⽤是处理业务；

###### 2）具体实现方案：

- Reactor 对象通过 select （IO 多路复⽤接⼝） 监听事件，收到事件后通过 dispatch 进⾏分发，具体分发给 Acceptor 对象还是 Handler 对象，还要看收到的事件类型；
- 如果是连接建⽴的事件，则交由 Acceptor 对象进⾏处理，Acceptor 对象会通过 accept ⽅法 获取连接，并创建⼀个 Handler 对象来处理后续的响应事件；
- 如果不是连接建⽴事件， 则交由当前连接对应的 Handler 对象来进⾏响应；
- Handler 对象通过 read -> 业务处理 -> send 的流程来完成完整的业务流程。

###### 3）缺点

- 只有⼀个进程，⽆法充分利⽤ 多核 **CPU** 的性能；
- Handler 对象在业务处理时，整个进程是⽆法处理其他连接的事件的，如果业务处理耗时⽐较⻓，那么就造成响应的延迟；

###### 4）总结

- 单 Reactor 单进程的⽅案不适⽤计算机密集型的场景，只适⽤于业务处理⾮常快速的场景

##### 3、单 **Reactor** 多线程 **/** 多进程

<img src="总结面试题.assets/image-20210903114430754.png" alt="image-20210903114430754" style="zoom: 80%;" />

###### 1）实现方案

- Reactor 对象通过 select （IO 多路复⽤接⼝） 监听事件，收到事件后通过 dispatch 进⾏分发，具体分发给 Acceptor 对象还是Handler 对象，还要看收到的事件类型；
- 如果是连接建⽴的事件，则交由 Acceptor 对象进⾏处理，Acceptor 对象会通过 accept ⽅法 获取连接，并创建⼀个 Handler 对象来处理后续的响应事件；
- 如果不是连接建⽴事件， 则交由当前连接对应的 Handler 对象来进⾏响应；

###### 2）与单Reactor单线程不同点

- Handler 对象不再负责业务处理，只负责数据的接收和发送，Handler 对象通过 read 读取到数据后，会将数据发给⼦线程⾥的 Processor 对象进⾏业务处理；
- ⼦线程⾥的 Processor 对象就进⾏业务处理，处理完后，将结果发给主线程中的 Handler 对象，接着由 Handler 通过 send ⽅法将响应结果发送给 client；
- 单 Reactor 多进程相⽐单 Reactor 多线程实现起来很麻烦，主要因为要考虑⼦进程 <-> ⽗进程的双向通信，并且⽗进程还得知道⼦进程要将数据发送给哪个客户端。
- ⽽多线程间可以共享数据，虽然要额外考虑并发问题，但是这远⽐进程间通信的复杂度低得多，因此实际应⽤中也看不到单 Reactor 多进程的模式。

##### 4、多 **Reactor** 多线程 **/** 多进程

<img src="总结面试题.assets/image-20210903114810532.png" alt="image-20210903114810532" style="zoom:67%;" />

###### 1）实现方案

- 主线程中的 MainReactor 对象通过 select 监控连接建⽴事件，收到事件后通过 Acceptor 对象中的accept 获取连接，将新的连接分配给某个⼦线程；
- ⼦线程中的 SubReactor 对象将 MainReactor 对象分配的连接加⼊ select 继续进⾏监听，并创建⼀个Handler ⽤于处理连接的响应事件。
- 如果有新的事件发⽣时，SubReactor 对象会调⽤当前连接对应的 Handler 对象来进⾏响应。
- Handler 对象通过 read -> 业务处理 -> send 的流程来完成完整的业务流程。

###### 2）优点

- 主线程和⼦线程分⼯明确，主线程只负责接收新连接，⼦线程负责完成后续的业务处理。
- 主线程和⼦线程的交互很简单，主线程只需要把新连接传给⼦线程，⼦线程⽆须返回数据，直接就可以在⼦线程将处理结果发送给客户端。

#### 12.2、Proactor

​		Reactor 是⾮阻塞同步⽹络模式，⽽ **Proactor** 是异步⽹络模式。异步 I/O 在「内核数据准备好」和「数据从内核空间拷⻉到

⽤户空间」这两个过程都不⽤等待。

<img src="总结面试题.assets/image-20210903115529498.png" alt="image-20210903115529498" style="zoom:80%;" />

##### 1、工作流程

- Proactor Initiator 负责创建 Proactor 和 Handler 对象，并将 Proactor 和 Handler 都通过Asynchronous Operation Processor 注册到内核；
- Asynchronous Operation Processor 负责处理注册请求，并处理 I/O 操作；
- Asynchronous Operation Processor 完成 I/O 操作后通知 Proactor；
- Proactor 根据不同的事件类型回调不同的 Handler 进⾏业务处理；
- Handler 完成业务处理；

#### 12.3、Proactor 和 Reactor 区别

- **Reactor** 是⾮阻塞同步⽹络模式，感知的是就绪可读写事件。在每次感知到有事件发⽣（⽐如可读就绪事件）后，就需要应⽤进程主动调⽤ read ⽅法来完成数据的读取，也就是要应⽤进程主动将socket 接收缓存中的数据读到应⽤进程内存中，这个过程是同步的，读取完数据后应⽤进程才能处理数据。

- **Proactor** 是异步⽹络模式， 感知的是已完成的读写事件。在发起异步读写请求时，需要传⼊数据缓冲区的地址（⽤来存放结果数据）等信息，这样系统内核才可以⾃动帮我们把数据的读写⼯作完成，这⾥的读写⼯作全程由操作系统来做，并不需要像 Reactor 那样还需要应⽤进程主动发起 read/write来读写数据，操作系统完成读写⼯作后，就会通知应⽤进程直接处理数据。

#### ==总结==

​		**Reactor** 可以理解为「来了事件操作系统通知应⽤进程，让应⽤进程来处理」，⽽ **Proactor** 可以理解为「来了事件操作系统来处理，处理完再通知应⽤进程」。这⾥的「事件」就是有新连接、有数据可读、有数据可写的这些 I/O 事件这⾥的「处理」包含从驱动读取到内核以及从内核读取到⽤户空间。

​		⽆论是 Reactor，还是 Proactor，都是⼀种基于「事件分发」的⽹络编程模式，区别在于 **Reactor** 模式是基于「待完成」的 **I/O** 事件，⽽ **Proactor** 模式则是基于「已完成」的 **I/O** 事件。



## 四、计算机网络

### 1、HTTP

####  1.1、概念：

​		超文本传输协议，HTTP是一个基于TCP/IP通信协议来传递数据（HTML 文件, 图片文件, 查询结果等）。HTTP协议工作于客户端-服务端（C/S）架构为上。浏览器作为HTTP客户端通过URL向HTTP服务端即Web服务器发送所有请求。Web服务器根据接收到的请求后，向客户端发送响应信息。HTTP协议是以明文方式发送信息的，如果有人截取了web浏览器和服务器之间的传输报文，就可以直接获得其中的信息。

#### **1.2、HTTP请求过程**

一次HTTP操作称为一个事务，其工作过程可分为四步：

1）**首先客户机与服务器需要建立连接**。只要单击某个超级链接，HTTP的工作开始。

2）**建立连接后，客户机发送一个请求给服务器**，请求方式的格式为：统一资源标识符（URL）、协议版本号，后边是MIME信息包括请求修饰符、客户机信息和可能的内容。

3）**服务器接到请求后，给予相应的响应信息**，其格式为一个状态行，包括信息的协议版本号、一个成功或错误的代码，后边是MIME信息包括服务器信息、实体信息和可能的内容。

4）**客户端接收服务器所返回的信息通过浏览器显示在用户的显示屏上，然后客户机与服务器断开连接**

#### **1.3、HTTP的状态码**

HTTP无状态是指不能保存客户信息，响应一次就断开。状态码是用于**表示HTTP的状态** 。

<img src="总结面试题.assets/image-20210825152445724.png" alt="image-20210825152445724" style="zoom:67%;" />

常见的状态码：

​	100 continue  表明到目前为止都很正常，客户端可以继续发生请求或忽略该响应

​     200 OK             //客户端请求成功，如果是⾮ HEAD 请求，服务器返回的响应头都会有 body数据

​     400 Bad Request        //客户端请求有语法错误，不能被服务器所理解

​     401 Unauthorized        //请求未经授权，这个状态代码必须和WWW-Authenticate报头域一起使用 

​     403 Forbidden         //服务器收到请求，但是拒绝提供服务

​     404 Not Found         //请求资源不存在，eg：输入了错误的URL

​     408 Request Timeout   //请求超时

​     500 Internal Server Error      //服务器发生不可预期的错误

​     503 Server Unavailable      //服务器当前不能处理客户端的请求，一段时间后可能恢复正常

| 100  | Continue                        | 继续。[客户端](http://www.dreamdu.com/webbuild/client_vs_server/)应继续其请求 |
| ---- | ------------------------------- | ------------------------------------------------------------ |
| 101  | Switching Protocols             | 切换协议。服务器根据客户端的请求切换协议。只能切换到更高级的协议，例如，切换到HTTP的新版本协议 |
|      |                                 |                                                              |
| 200  | OK                              | 请求成功。一般用于GET与POST请求                              |
| 201  | Created                         | 已创建。成功请求并创建了新的资源                             |
| 202  | Accepted                        | 已接受。已经接受请求，但未处理完成                           |
| 203  | Non-Authoritative Information   | 非授权信息。请求成功。但返回的meta信息不在原始的服务器，而是一个副本 |
| 204  | No Content                      | 无内容。服务器成功处理，但未返回内容。在未更新网页的情况下，可确保浏览器继续显示当前文档 |
| 205  | Reset Content                   | 重置内容。服务器处理成功，用户终端（例如：浏览器）应重置文档视图。可通过此返回码清除浏览器的表单域 |
| 206  | Partial Content                 | 部分内容。服务器成功处理了部分GET请求                        |
|      |                                 |                                                              |
| 300  | Multiple Choices                | 多种选择。请求的资源可包括多个位置，相应可返回一个资源特征与地址的列表用于用户终端（例如：浏览器）选择 |
| 301  | Moved Permanently               | 永久移动。请求的资源已被永久的移动到新URI，返回信息会包括新的URI，浏览器会自动定向到新URI。今后任何新的请求都应使用新的URI代替 |
| 302  | Found                           | 临时移动。与301类似。但资源只是临时被移动。客户端应继续使用原有URI |
| 303  | See Other                       | 查看其它地址。与301类似。使用GET和POST请求查看               |
| 304  | Not Modified                    | 未修改。所请求的资源未修改，服务器返回此状态码时，不会返回任何资源。客户端通常会缓存访问过的资源，通过提供一个头信息指出客户端希望只返回在指定日期之后修改的资源 |
| 305  | Use Proxy                       | 使用代理。所请求的资源必须通过代理访问                       |
| 306  | Unused                          | 已经被废弃的HTTP状态码                                       |
| 307  | Temporary Redirect              | 临时重定向。与302类似。使用GET请求重定向                     |
|      |                                 |                                                              |
| 400  | Bad Request                     | 客户端请求的语法错误，服务器无法理解                         |
| 401  | Unauthorized                    | 请求要求用户的身份认证                                       |
| 402  | Payment Required                | 保留，将来使用                                               |
| 403  | Forbidden                       | 服务器理解请求客户端的请求，但是拒绝执行此请求               |
| 404  | Not Found                       | 服务器无法根据客户端的请求找到资源（网页）。通过此代码，网站设计人员可设置"您所请求的资源无法找到"的个性页面 |
| 405  | Method Not Allowed              | 客户端请求中的方法被禁止                                     |
| 406  | Not Acceptable                  | 服务器无法根据客户端请求的内容特性完成请求                   |
| 407  | Proxy Authentication Required   | 请求要求代理的身份认证，与401类似，但请求者应当使用代理进行授权 |
| 408  | Request Time-out                | 服务器等待客户端发送的请求时间过长，超时                     |
| 409  | Conflict                        | 服务器完成客户端的 PUT 请求时可能返回此代码，服务器处理请求时发生了冲突 |
| 410  | Gone                            | 客户端请求的资源已经不存在。410不同于404，如果资源以前有现在被永久删除了可使用410代码，网站设计人员可通过301代码指定资源的新位置 |
| 411  | Length Required                 | 服务器无法处理客户端发送的不带Content-Length的请求信息       |
| 412  | Precondition Failed             | 客户端请求信息的先决条件错误                                 |
| 413  | Request Entity Too Large        | 由于请求的实体过大，服务器无法处理，因此拒绝请求。为防止客户端的连续请求，服务器可能会关闭连接。如果只是服务器暂时无法处理，则会包含一个Retry-After的响应信息 |
| 414  | Request-URI Too Large           | 请求的URI过长（URI通常为网址），服务器无法处理               |
| 415  | Unsupported Media Type          | 服务器无法处理请求附带的媒体格式                             |
| 416  | Requested range not satisfiable | 客户端请求的范围无效                                         |
| 417  | Expectation Failed              | 服务器无法满足Expect的请求头信息                             |
|      |                                 |                                                              |
| 500  | Internal Server Error           | 服务器内部错误，无法完成请求                                 |
| 501  | Not Implemented                 | 服务器不支持请求的功能，无法完成请求                         |
| 502  | Bad Gateway                     | 作为网关或者代理工作的服务器尝试执行请求时，从远程服务器接收到了一个无效的响应 |
| 503  | Service Unavailable             | 由于超载或系统维护，服务器暂时的无法处理客户端的请求。延时的长度可包含在服务器的Retry-After头信息中 |
| 504  | Gateway Time-out                | 充当网关或代理的服务器，未及时从远端服务器获取请求           |
| 505  | HTTP Version not supported      | 服务器不支持请求的HTTP协议的版本，无法完成处理               |

#### 1.4、HTTP请求报文

​		一个HTTP请求报文由请求行（request line）、请求头部（header）、空行和请求数据4个部分组成。

<img src="总结面试题.assets/image-20210828212600320.png" alt="image-20210828212600320" style="zoom:67%;" />

Host：将请求发往「同⼀台」服务器上的不同⽹站

Content-Length：服务器在返回数据时，表明本次回应的数据⻓度

Connection：⽤于客户端要求服务器使⽤ TCP 持久连接，以便其他请求复⽤，keep_alive

Content-Type：⽤于服务器回应时，告诉客户端，本次数据是什么格式

Accept：声明自己可以接受那些数据格式

Content-Encoding ：说明数据的压缩⽅法，表示服务器返回的数据使⽤了什么压缩格式

#### 1.5、Get和Post的区别

​		HTTP/1.1 定义的请求方法有8种：GET、POST、PUT、DELETE、PATCH、HEAD、OPTIONS、TRACE。

##### 1、get和post的区别

​		Get是请求从服务器获取资源，这个资源可以是静态的⽂本、⻚⾯、图⽚视频等。

​		Post是向 URI 指定的资源提交数据，数据就放在报⽂的 body ⾥

==get是向URL添加数据，post有request body==

- 对于后退按钮/刷新：get是无害的，post数据会被重新提交（所以浏览器应该告知用户数据会被重新提交）；
- 书签：get可收藏为数千，post不行；
- 历史：get参数保留在浏览器历史中，post参数不会保存在浏览器历史中；
- 对数据长度的限制：发送的时候GET向URL添加数据（URL的长度是受限制的，最大长度是2048个字符），POST没有限制；
-  安全性：GET安全性更差，因为所发送的数据是URL的一部分（在发送密码或其他敏感信息不要使用GET），POST更安全（参数不会被保存在浏览器历史或web服务器日志中）；
- GET产生一个TCP数据包，浏览器会把http header和data一并发送出去，服务器响应200(返回数据); POST产生两个TCP数据包，浏览器先发送header，服务器响应100 continue，浏览器再发送data，服务器响应200 ok(返回数据)

##### 2、get和post的本质

- HTTP的底层是TCP/IP ,所以get和post的底层也是TCP/IP。所以从原理上来说，给get加上request body，post加上URL参数，都是完全可行的。但是，HTTP准则就这么规定的，就相当于是交通规则，只是要求get和post这么做，其实他们的实现还是用TCP做的。


- 关于参数长度的限制，数据量太大对于浏览器和服务器都是很大的负担，通常浏览器会限制URL长度在2K个字节，大多数服务器最多处理64K大小的URL，超过的部分就不处理了。要是用get加上request body，不同的服务器处理方式不同，有些服务器会读出数据，有些就直接忽略了，所以，虽然GET可以带上request body，但是不能保证一定会被收到；

##### 3、GET 和 POST 都是安全和幂等的吗？

​		先说明下安全和幂等的概念：

- 在 HTTP 协议⾥，所谓的「安全」是指请求⽅法不会「破坏」服务器上的资源。

- 所谓的「幂等」，意思是多次执⾏相同的操作，结果都是「相同」的。

​		那么很明显 **GET ⽅法就是安全且幂等**的，因为它是「只读」操作，⽆论操作多少次，服务器上的数据都是安全的，且每次的结果都是相同的。**POST** 因为是「新增或提交数据」的操作，会修改服务器上的资源，所以是**不安全**的，且多次提交数据就会创建多个资源，所以**不是幂等**的。

#### 1.6、Cookie和Session

因为HTTP协议是无状态的，所以需要用到cookie和session来记录用户信息，用来跟踪浏览器用户身份的会话方式， cookies 机制采用的是客户端保持状态的方案，session 采用在服务器端保持的方案。但时，客户量大的时候，采用session的会话方式，因为数据保存在服务器端，服务器的压力会较大。

##### 1、Cookie

​      举个例子：网上购物的时候，开始的时候先登录，选中商品加入到购物车这个过程，可以通过以下4步描述：

​         客户端带着登录信息请求服务器端；

​         服务器端响应（登录成功与否）到客户端；

​         客户端发送购物车里的信息到服务器端；

​         然后服务器端返回添加成功与否到服务器端；

​     问题的关键就是在第二次请求加入购物车的时候，因为HTTP客户端请求服务端是一种无状态的连接，那服务器怎么直到是谁以及加入谁的购物车；解决办法就是在request到达服务器的时候，服务器在response中加入一个小饼干，cookies包含用户登录时的一些基本信息，当第二次客户端发起请求的时候，服务器端检查小饼干，识别出客户端，找到相应的缓存，缓存中放着用户名、密码和一些用户设置项。

##### 2、Session

​        session也有cookie，但其中保存的不再是直接的数据，而是一个ID，在服务器端，服务器根据客户端的JsessinID来判断。服务器端是以键值对的方式来保存数据的，key就是JsessionID，根据key来获得value,要是没有jsessionID ,就创建一个加入MAP中。

#### 1.7、长连接和短连接

​		没有数据传也要保持TCP连接就是长连接，反之则为短链接。比如HTTP就是无状态的短连接，浏览器和服务器每进行一次HTTP操作，就建立一次连接，任务结束就中断连接。也可以这么说短连接就是SOCKET连接后，发送接受完的数据就马上断开连接；

​    	长连接是至建立SOCKET连接之后不管使用与否都保持连接，直到某一方关闭连接，安全性较差。建立长连接不关闭socket就行。

##### 1、适用情况

   1）长连接主要用于操作频繁，点对点通讯，并且连接数不多的情况下。因为每个TCP链接都需要三次握手，这需要时间，要是每个操作都先连接再操作的话处理速度就会降低很多，所以每个操作完之后都不用断开，次处理的时候直接发送数据包就可以了。

　2）短连接可以节省资源，在每个用户无需频繁操作情况下使用短连接比较好。因为长连接对于服务端来说会耗费一定的资源，像Web网站这么频繁的成千上万客户端的连接用短连接会更节省资源，要是使用长连接，每个用户都占一个连接的话，太占资源了。所以并发量大，但每个用户无需频繁访问操作情况下用短连接比较好。

##### 2、长连接的实现

​      socket中有个API是socket.keepAlive(true);就是让TCP保持连接不断开，但是这个仅仅只是在两个小时内没有通信，底层会发一个心跳，看看对方是不是还活着。两小时发一次，也就是说，没有实际数据通信的时候，把网线拔了，对方要两个小时才能知道。其实会有很多情况导致socket不可用：a)某一段关闭了socket，主动关闭的一方会发送 FIN，通知对方要关闭 TCP 连接。在这种情况下，另一端如果去读 socket，将会读到 EoF。于是我们知道对方关闭了 socket；b)应用程序崩溃，socket会由内核关闭，情况和上面一样；c)系统崩溃，这时候系统是来不及发送FIN的，对方无法知道你这边什么情况，读数据之类的就会返回read time out；d)电线被挖断、网线被拔，就跟上面一直情况差不多，如果没有对socket进行读写，两边都不会知道发生了事故。

​      就以上可能出现的情景中，有一个共同点就是，只要读、写socket，就能知道异常，所以我们要实现长连接，就需要的是不断地给对方写数据，然后读对方的数据就好啦，这个心跳的时间需要根据实际时间来决定，只需要在数据前面加个type，识别是心跳还是真实数据就好。

 ==长连接的心跳机制，项目中用不上心跳机制，因为每次都是在一定时间内传输大量的数据，这段时间内只要保持不断就可以，就总的来说，在我需要发送的时候，发送一次是200ms，那我在很多很多次的200ms内，一个三次握手建立连接的时间，是可以忽略不记的==

#### **1.8、HTTP的特性**

HTTP 最凸出的优点是「简单、灵活和易于扩展、应⽤⼴泛和跨平台」。

##### 1、简单

​		HTTP 基本的报⽂格式就是 header + body ，头部信息也是 key-value 简单⽂本的形式，易于理解，降低了学习和使⽤的⻔槛。

##### 2、灵活和易于扩展

​		HTTP协议⾥的各类请求⽅法、URI/URL、状态码、头字段等每个组成要求都没有被固定死，都允许开发⼈员⾃定义和扩充。

​		比如说：HTTPS 也就是在 HTTP 与 TCP 层之间增加了 SSL/TLS 安全传输层，HTTP/3 甚⾄把 TCP 层换成了基于 UDP 的QUIC。

#### 1.9、在浏览器输入URL后执行的全过程

##### 1、域名解析。根据用户输入的网址去寻找它对应的IP地址

​           先从浏览器缓存里找IP，因为浏览器会缓存DNS（域名系统）记录一段时间；若没找到，从Hosts查找是否有该域名和IP；再没找到，从路由器缓存查找；再从DNS缓存查找；若再没有找到，浏览器域名服务器向根域名服务器查找对应IP，还没找到就把请求转发到下一级，直到找到IP

##### 2、建立TCP连接

首先客户端发起请求：

​       使用应用层发起HTTP请求（可根据本身输入URL访问时，用什么协议就发起对应协议去进行请求）；然后是传输层的TCP协议为传输报文提供可靠的字节流服务，使用了TCP三次握手；网络层将TCP分割好的各种数据包传送给接收方（要保证确实能传到接收方还需要接收方的MAC地址）；最后链路层将数据发送到数据链路层传输

服务器接收请求处理：

​                    链路层->网络层->传输层->应用层

##### 3、根据后台业务返回数据，并把数据填充到HTML页面上，然后返回给浏览器

##### 4、浏览器进行处理。服务器通过后台语言程序处理，找到数据返回给浏览器，断开TCP连接，然后绘制页面



### 2、HTTP的演变

#### 2.1、HTTP1.1

##### 1、长连接--HTTP1.0是短连接

​		早期 HTTP/1.0 性能上的⼀个很⼤的问题，那就是每发起⼀个请求，都要新建⼀次 TCP 连接（三次握⼿），⽽且是串⾏请求，做了⽆谓的 TCP 连接建⽴和断开，增加了通信开销。

​		为了解决上述 TCP 连接问题，HTTP/1.1 提出了**⻓连接**的通信⽅式，也叫持久连接。这种⽅式的好处在于**减少了TCP 连接的重复建⽴和断开所造成的额外开销，减轻了服务器端的负载。**

​		持久连接的特点是，只要任意⼀端没有明确提出断开连接，则保持 TCP 连接状态。

##### 2、管道网络传输

​		长连接使管道Pipeling网络传输成为可能。即可在同⼀个 TCP 连接⾥⾯，客户端可以发起多个请求，只要第⼀个请求发出去了，不必等其回来，就可以发第⼆个请求出去，可以**减少整体的响应时间**。

​		举例来说，客户端需要请求两个资源。以前的做法是，在同⼀个TCP连接⾥⾯，先发送 A 请求，然后等待服务器做出回应，收到后再发出 B 请求。管道机制则是允许浏览器同时发出 A 请求和 B 请求。

​		但是服务器还是**按照顺序**，先回应 A 请求，完成后再回应 B 请求。要是前⾯的回应特别慢，后⾯就会有许多请求排队等着。这称为「队头堵塞」。

##### 3、对头阻塞

​	「请求 - 应答」的模式加剧了 HTTP 的性能问题。因为当顺序发送的请求序列中的⼀个请求因为某种原因被阻塞时，在后⾯排队的所有请求也⼀同被阻塞了，会招致客户端⼀直请求不到数据，这也就是「队头阻塞」

#### ==总结==HTTP/1.0与HTTP/1.1 区别

###### 1）HTTP/1.1 相⽐ HTTP/1.0 性能上的改进：

- 使⽤ TCP ⻓连接的⽅式改善了 HTTP/1.0 短连接造成的性能开销。**（长连接）**

- ⽀持管道（pipeline）⽹络传输，只要第⼀个请求发出去了，不必等其回来，就可以发第⼆个请求出去，可以减少整体的响应时间。**（管道网络传输）**

###### 2） HTTP/1.1 还是有性能瓶颈：

- 请求 / 响应头部（Header）未经压缩就发送，⾸部信息越多延迟越⼤。只能压缩 Body 的部分；**（头部未压缩）**

- 发送冗⻓的⾸部。每次互相发送相同的⾸部造成的浪费较多；**（首部冗余）**

- 服务器是按请求的顺序响应的，如果服务器响应慢，会招致客户端⼀直请求不到数据，也就是队头阻塞；**（对头阻塞）**

- 没有请求优先级控制；**（无请求优先级）**

- 请求只能从客户端开始，服务器只能被动响应。**（被动响应）**

#### 2.2、HTTP2.0

##### 1、HTTP2.0相当于HTTP1.0的改进

###### 1）头部压缩

- HTTP/2 会压缩头（Header）如果你同时发出多个请求，他们的头是⼀样的或是相似的，那么，协议会帮你**消除重复**的部分。

- 这就是所谓的 **HPACK** 算法：在客户端和服务器同时维护⼀张头信息表，所有字段都会存⼊这个表，⽣成⼀个索引号，以后就不发送同样字段了，只发送索引号，这样就提⾼速度了。
  - HPACK算法：

###### 2）二进制格式

- HTTP/2 不再像 HTTP/1.1 ⾥的**纯文本**形式的报⽂，⽽是全⾯采⽤了**⼆进制格式**，头信息和数据体都是⼆进制，并且统称为帧（frame）：头信息帧和数据帧。

###### 3）数据流

- HTTP/2 的数据包不是按顺序发送的，同⼀个连接⾥⾯连续的数据包，可能属于不同的回应。因此，必须要对数据包做标记，指出它属于哪个回应。

- 每个请求或回应的所有数据包，称为⼀个**数据流**（ Stream ）。每个数据流都标记着⼀个独⼀⽆⼆的编号，其中规定客户端发出的数据流编号为奇数， 服务器发出的数据流编号为偶数

- 客户端还可以**指定数据流的优先级**。优先级⾼的请求，服务器就先响应该请求

###### 4）多路复用



##### **2、HTTP2.0中存在的问题**

###### **1）HTTP/2 对头阻塞**

​		所谓的对头阻塞是因为HTTP是C/S模型，多个HTTP请求在一个TCP连接中实现，那么就存在一个问题，当发生**TCP丢包**时，整个TCP都需要等待重传，那么就会导致该TCP中的其他所有请求被阻塞。因为**TCP是字节流协议**，TCP层协议必须保证收到的**字节数据完整且有序**，如果序列号较低的TCP段在网络传输过程中发生了丢包，即使序列号较高的TCP段已经被接收了，应用层也无法从内核中读取到这部分数据，从HTTP的视角上看，就是请求被阻塞了。

###### **2）TCP与TLS的握手时延迟**

​		发起 HTTP 请求时，需要经过 TCP 三次握⼿和 TLS 四次握⼿（TLS 1.2）的过程，因此共需要 **3 个 RTT 的时延**才能发出请求数据。另外， **TCP 由于具有「拥塞控制」的特性，所以刚建⽴连接的 TCP 会有个「慢启动」的过程，它会对 TCP 连接产⽣"减速"效果**。

###### **3**）**网络迁移需要重新连接**

​		⼀个 TCP 连接是由**四元组**（源 IP 地址，源端⼝，⽬标 IP 地址，⽬标端⼝）确定的，这意味着**如果 IP 地址或者端⼝变动**了，就会导致**需要 TCP 与 TLS 重新握⼿**，这不利于移动设备切换⽹络的场景，⽐如 4G ⽹络环境切换成WIFI。这些问题都是 TCP 协议固有的问题，⽆论应⽤层的 HTTP/2 在怎么设计都⽆法逃脱。要解决这个问题，就必须把传输层协议替换成 **UDP**，这个⼤胆的决定，HTTP/3 做了。（将TCP换为UDP，实现无连接传输）

#### 2.3、HTTP3.0

<img src="总结面试题.assets/image-20210825105602356.png" alt="image-20210825105602356" style="zoom: 67%;" />

<img src="总结面试题.assets/image-20210825111553031.png" alt="image-20210825111553031" style="zoom:67%;" />

​		UDP 是⼀个面向报文的、简单、不可靠的传输协议，⽽且是 UDP 包之间是⽆序的，也没有依赖关系。

​		UDP 是不需要连接的，也就不需要握⼿和挥⼿的过程，所以天然的就⽐ TCP 快。

​		HTTP3.0不仅将TCP传输协议替换成UDP协议，而且还基于UDP协议在应用层上实现了QUIC协议，QUIC协议具有与TCP类似的**连接管理、拥塞窗口、流量控制**的网络特性，相当于把不可靠的UDP协议变得“可靠”了。

##### **1、QUIC协议**

​		QUIC(quick UDP internet connection)特点：**无对头阻塞、更快建立连接、连接迁移**

###### **1）无对头阻塞**

​		**多路复用：**QUIC 协议也有类似 **HTTP/2 Stream 与多路复⽤**的概念，也是可以在**同⼀条连接上并发传输多个 Stream**，Stream可以认为就是⼀条 HTTP 请求。

​		**不care丢包：**由于 QUIC 使⽤的传输协议是 UDP，UDP 不关⼼数据包的顺序，如果数据包丢失，UDP 也不关⼼。

​		**保证可靠传输：**不过 QUIC 协议会保证数据包的可靠性，每个数据包都有⼀个序号**唯⼀标识**。当某个流中的⼀个数据包丢失了，即使该流的其他数据包到达了，数据也⽆法被 HTTP/3 读取，直到 QUIC 重传丢失的报⽂，数据才会交给 HTTP/3。⽽其他流的数据报⽂只要被完整接收，HTTP/3 就可以读取到数据。这与 HTTP/2 不同，HTTP/2 只要某个流中的数据包丢失了，其他流也会因此受影响**（对数据包做标识，如果发生丢包，则只需重传丢包的数据包，不影响其他stream数据包的接收）**

​		**stream之间相互独立：**QUIC 连接上的多个 Stream 之间并没有依赖，都是独⽴的，某个流发⽣丢包了，只会影响该流，其他流不受影响。

###### **2）更快建立连接**

​		**TCP与TLS分层：**对于 HTTP/1 和 HTTP/2 协议，TCP 和 TLS 是分层的，分别属于**内核实现的传输层、openssl 库实现的表示层**，因此它们难以合并在⼀起，需要分批次来握⼿，先 TCP 握⼿，再 TLS 握⼿。

​		**QUIC握手只是确认ID：**HTTP/3 在传输数据前虽然需要 QUIC 协议握⼿，这个握⼿过程只需要 **1 RTT**，握⼿的⽬的是为确认双⽅的「连接ID」，连接迁移就是基于连接 ID 实现的。

​		但是 HTTP/3 的 QUIC 协议并不是与 TLS 分层，⽽是**QUIC 内部包含了 TLS**，它在⾃⼰的帧会携带 TLS ⾥的“记录”，再加上 QUIC 使⽤的是 TLS1.3，因此仅需 1 个 RTT 就可以「同时」完成建⽴连接与密钥协商，甚⾄在**第⼆次连接**的时候，应⽤数据包可以和 QUIC 握⼿信息（**连接信息 + TLS 信息**）⼀起发送，达到 **0-RTT** 的效果。**

​		即HTTP/3 当**会话恢复**时，有效负载数据与第⼀个数据包⼀起发送，可以做到 0-RTT。

###### **3）连接迁移**

​		在前⾯我们提到，基于 TCP 传输协议的 HTTP 协议，由于是通过四元组（源 IP、源端⼝、⽬的 IP、⽬的端⼝）确定⼀条 TCP 连接，那么当移动设备的⽹络从 4G 切换到 WIFI 时，意味着 IP 地址变化了，那么就必须要断开连接，然后重新建⽴连接，⽽建⽴连接的过程包含 TCP 三次握⼿和 TLS 四次握⼿的时延，以及 TCP 慢启动的减速过程，给⽤户的感觉就是⽹络突然卡顿了⼀下，因此连接的迁移成本是很⾼的。⽽ QUIC 协议没有⽤四元组的⽅式来“绑定”连接，⽽是通过连接 **ID**来标记通信的两个端点，**客户端和服务器可以各自选择⼀组 ID来标记⾃⼰**，因此即使移动设备的⽹络变化后，导致 IP 地址变化了，**只要仍保有上下⽂信息（⽐如连接 ID、TLS 密钥等）**，就可以“⽆缝”地复⽤原连接，消除重连的成本，没有丝毫卡顿感，达到了**连接迁移**的功能。

##### **2、HTTP3.0协议**

​		 HTTP/3 同 HTTP/2 ⼀样采⽤**⼆进制帧**的结构，不同的地⽅在于 HTTP/2 的⼆进制帧⾥需要定义 Stream，⽽ HTTP/3 ⾃身不需要再定义 Stream，直接使⽤ QUIC ⾥的 Stream，于是 HTTP/3 的帧的结构也变简单了**（HTTP2.0需要定义stream，HTTP3.0直接使用QUIC中stream）。**

![image-20210825114117058](总结面试题.assets/image-20210825114117058.png)

​		从上图可以看到，HTTP/3 帧头只有两个字段：**类型和⻓度**。

​		根据帧类型的不同，⼤体上分为数据帧和控制帧两⼤类，HEADERS 帧（HTTP 头部）和 DATA 帧（HTTP 包体）属于数据帧。

​		HTTP/3 在头部压缩算法这⼀⽅便也做了升级，升级成了 **QPACK**。与 HTTP/2 中的 HPACK 编码⽅式相似，HTTP/3 中的 QPACK 也采⽤了**静态表、动态表及 Huffman 编码**。

- 对于静态表的变化，HTTP/2 中的 HPACK 的静态表只有 **61** 项，⽽ HTTP/3 中的 QPACK 的静态表扩⼤到 **91** 项。
- HTTP/2 和HTTP/3 的 Huffman 编码并没有多⼤不同，但是动态表编解码⽅式不同。

- 所谓的动态表，在⾸次请求-响应后，双⽅会将未包含在静态表中的 Header 项更新各自的动态表，接着后续传输时仅⽤ 1 个数字表示，然后对⽅可以根据这 1 个数字从动态表查到对应的数据，就不必每次都传输长长的数据，⼤⼤提升了编码效率。

​       可以看到，动态表是具有**时序性**的，如果⾸次出现的请求发⽣了**丢包**，后续的收到请求，对⽅就⽆法解码出**HPACK** 头部，因为对⽅还没建⽴好动态表，因此后续的请求解码会**阻塞**到⾸次请求中丢失的数据包重传过来。

**HTTP/3 的 QPACK 解决了这⼀问题，那它是如何解决的呢？**

​		QUIC 会有两个特殊的单向流，所谓的单项流只有⼀端可以发送消息，双向则指两端都可以发送消息，传输 HTTP消息时⽤的是双向流，这两个单向流的⽤法：

- ⼀个叫 QPACK Encoder Stream， ⽤于将⼀个字典（key-value）传递给对⽅，⽐如⾯对不属于静态表的HTTP 请求头部，客户端可以通过这个 Stream 发送字典；

- ⼀个叫 QPACK Decoder Stream，⽤于响应对⽅，告诉它刚发的字典已经更新到⾃⼰的本地动态表了，后续就可以使⽤这个字典来编码了。

  ​	

  这两个特殊的单向流是⽤来**同步双⽅的动态表**，编码⽅收到解码⽅更新确认的通知后，才使⽤动态表编码 HTTP 头部。

#### **==总结==**HTTP/2.0与HTTP/3.0区别

HTTP/2 虽然具有多个流并发传输的能⼒，但是传输层是 TCP 协议，于是存在以下缺陷：

- **队头阻塞**，HTTP/2 多个请求跑在⼀个 TCP 连接中，如果序列号较低的 TCP 段在⽹络传输中丢失了，即使序列号较⾼的 TCP 段已经被接收了，应⽤层也⽆法从内核中读取到这部分数据，从 HTTP 视⻆看，就是多个请求被阻塞了；

- **TCP 和 TLS 握⼿时延**，TCL 三次握⼿和 TLS 四次握⼿，共有 3-RTT 的时延；

- **连接迁移需要重新连接**，移动设备从 4G ⽹络环境切换到 WIFI 时，由于 TCP 是基于四元组来确认⼀条 TCP连接的，那么⽹络环境变化后，就会导致 IP 地址或端⼝变化，于是 TCP 只能断开连接，然后再᯿新建⽴连接，切换⽹络环境的成本⾼；

HTTP/3 就将传输层从 TCP 替换成了 UDP，并在 UDP 协议上开发了 QUIC 协议，来保证数据的可靠传输。

**QUIC 协议的特点：**

- **⽆队头阻塞**，QUIC 连接上的多个 Stream 之间并没有依赖，都是独⽴的，也不会有底层协议限制，某个流发⽣丢包了，只会影响该流，其他流不受影响；

- **建⽴连接速度快**，因为 QUIC 内部包含 TLS1.3，因此仅需 1 个 RTT 就可以「同时」完成建⽴连接与 TLS 密钥协商，甚⾄在第⼆次连接的时候，应⽤数据包可以和 QUIC 握⼿信息（连接信息 + TLS 信息）⼀起发送，达到 0-RTT 的效果。

- **连接迁移**，QUIC 协议没有⽤四元组的⽅式来“绑定”连接，⽽是通过「连接 ID 」来标记通信的两个端点，客户端和服务器可以各⾃选择⼀组 ID 来标记⾃⼰，因此即使移动设备的⽹络变化后，导致 IP 地址变化了，只要仍保有上下⽂信息（⽐如连接 ID、TLS 密钥等），就可以“⽆缝”地复⽤原连接，消除᯿连的成本；

另外 HTTP/3 的 QPACK 通过两个特殊的单向流来同步双⽅的动态表，解决了 HTTP/2 的 HPACK 队头阻塞问题。



### **3、HTTPS**

#### 3.1、HTTPS实现

##### 1、混合加密

​		**混合加密**的⽅式实现信息的机密性，解决了窃听的⻛险。

1）HTTPS 采⽤的是**对称加密**和**⾮对称加密**结合的「混合加密」⽅式：

- 在通信建⽴前采⽤非对称加密的⽅式交换「会话秘钥」，后续就不再使⽤⾮对称加密。**（非对称加密--密钥）**
- 在通信过程中全部使⽤对称加密的「会话秘钥」的⽅式加密明⽂数据。**（对称加密--明文）**

2）采⽤「混合加密」的⽅式的原因：

- 对称加密只使⽤⼀个密钥，运算速度快，密钥必须保密，⽆法做到安全的密钥交换。

- ⾮对称加密使⽤两个密钥：公钥和私钥，公钥可以任意分发⽽私钥保密，解决了密钥交换问题但速度慢。

##### 2、摘要算法

​		**摘要算法**的⽅式来实现完整性，它能够为数据⽣成独⼀⽆⼆的「指纹」，指纹（摘要）⽤于校验数据的完整性，解决了篡改的⻛险。

​		客户端在发送明⽂之前会通过摘要算法算出明⽂的「指纹」，发送的时候把「指纹 + 明⽂」⼀同加密成密⽂后，发送给服务器，服务器解密后，⽤相同的摘要算法算出发送过来的明⽂，通过⽐较客户端携带的「指纹」和当前算出的「指纹」做⽐较，若「指纹」相同，说明数据是完整的。

##### 3、数字证书

数字证书一般包含：公钥、持有者信息、证书认证机构CA的信息、CA对这份文件的数字签名及使用的算法、证书有效期...

###### 1）什么是数字签名？

​		当服务器向客户端发送信息时，会将报文生成报文摘要，同时对报文摘要进行hash计算，得到hash值，然后对hash值进行加密，然后将加密的hash值放置在报文后面，这个加密后的hash值就称为签名。

​		服务器将报文、签名和数字证书一同发送给客户端。客户端收到这些信息后，会首先验证签名，利用签名算法对签名进行解密，得到报文摘要的hash值，然后将得到的报文生成报文摘要并利用签名hash算法生成新的hash值，通过对比这两个hash值是否一致，就能判断信息是否完整，是否是由真正的服务器发送的。可知签名有两个作用**确认消息发送方可靠，确认消息完整准确**。	

###### 2）数字证书的作用

​		用来认证公钥持有者的身份，防止第三方冒充，简单的来说就是告诉客户端，该服务端是否合法，只有证书合法，才能保证服务端身份是可信的。

​		为了让服务端的公钥被⼤家信任，服务端的证书都是由 CA （*Certificate Authority*，证书认证机构）签名的，CA就是⽹络世界⾥的公安局、公证中⼼，具有极⾼的可信度，所以由它来给各个公钥签名，信任的⼀⽅签发的证书，那必然证书也是被信任的。**签名的作用可以避免中间人在获取证书时对证书内容的篡改。**

###### 3）证书是如何产生的？

###### <img src="总结面试题.assets/image-20210904162324225.png" alt="image-20210904162324225" style="zoom:80%;" />

证书的颁发过程：

- ⾸先 CA 会把持有者的公钥、⽤途、颁发者、有效时间等信息打成⼀个包，然后对这些信息进⾏ **Hash** 计算，得到⼀个 **Hash 值**；
- 然后 CA 会使⽤⾃⼰的**私钥**将该 **Hash 值加密**，⽣成 Certificate Signature，也就是 CA 对证书做了**签名**；
- 最后将 Certificate Signature 添加在⽂件证书上，形成数字证书；

###### 4）客户端是如何验证CA证书是可信任的？

- ⾸先客户端会使⽤同样的 Hash 算法获取该证书的 Hash 值 H1；
- 通常浏览器和操作系统中集成了 CA 的公钥信息，浏览器收到证书后可以使⽤ CA 的公钥解密 Certificate Signature 内容，得到⼀个 Hash 值 H2 ；
- 最后⽐较 H1 和 H2，如果值相同，则为可信赖的证书，否则则认为证书不可信

###### 问题一：如何保证公钥不被篡改和信任度？

- 这⾥就需要借助第三⽅权威机构 CA （数字证书认证机构），将服务器公钥放在数字证书（由数字证书认证机构颁发）中，只要证书是可信的，公钥就是可信的。



#### 3.2、SSL

##### 1、SSL/TLS协议基本流程

- 客户端向服务器索要并验证服务器的公钥。

- 双⽅协商⽣产「会话秘钥」。

- 双⽅采⽤「会话秘钥」进⾏加密通信。

##### 2、SSL握手过程

<img src="总结面试题.assets/image-20210828205822042.png" alt="image-20210828205822042" style="zoom:67%;" />

SSL/TLS 协议建⽴的详细流程：

###### 1）ClientHello

​		⾸先，由客户端向服务器发起加密通信请求，也就是 ClientHello 请求。在这⼀步，客户端主要向服务器发送以下信息：

- 客户端⽀持的 SSL/TLS 协议版本，如 TLS 1.2 版本。

- 客户端⽣产的随机数（ Client Random ），后⾯⽤于⽣产「会话秘钥」。

- 客户端⽀持的密码套件列表，如 RSA 加密算法。

###### 2）SeverHello

​		服务器收到客户端请求后，向客户端发出响应，也就是 SeverHello 。服务器回应的内容有如下内容：

- 确认 SSL/ TLS 协议版本，如果浏览器不⽀持，则关闭加密通信。

- 服务器⽣产的随机数（ Server Random ），后⾯⽤于⽣产「会话秘钥」。

- 确认的密码套件列表，如 RSA 加密算法。

- 服务器的数字证书。

###### 3）客户端回应

​		客户端收到服务器的回应之后，⾸先通过浏览器或者操作系统中的 CA 公钥，确认服务器的数字证书的真实性。

​		如果证书没有问题，客户端会从数字证书中取出服务器的公钥，然后使⽤它加密报⽂，向服务器发送如下信息：

- ⼀个随机数（ pre-master key ）。该随机数会被服务器公钥加密。

- 加密通信算法改变通知，表示随后的信息都将⽤「会话秘钥」加密通信。

- 客户端握⼿结束通知，表示客户端的握⼿阶段已经结束。这⼀项同时把之前所有内容的发⽣的数据做个摘要，⽤来供服务端校验。上⾯第⼀项的随机数是整个握⼿阶段的第三个随机数，这样服务器和客户端就同时有三个随机数，接着就⽤双⽅协商的加密算法，各⾃⽣成本次通信的「会话秘钥」。

###### 4）服务器的最后回应

​		服务器收到客户端的第三个随机数（ pre-master key ）之后，通过协商的加密算法，计算出本次通信的「会话秘钥」。然后，向客户端发⽣最后的信息：

- 加密通信算法改变通知，表示随后的信息都将⽤「会话秘钥」加密通信。

- 服务器握⼿结束通知，表示服务器的握⼿阶段已经结束。这⼀项同时把之前所有内容的发⽣的数据做个摘要，⽤来供客户端校验。

⾄此，整个 SSL/TLS 的握⼿阶段全部结束。接下来，客户端与服务器进⼊加密通信，就完全是使⽤普通的 HTTP协议，只不过⽤「会话秘钥」加密内容。

<img src="总结面试题.assets/Image.png" alt="Image" style="zoom: 67%;" />

#### 3.3、对称加密和非对称加密

HTTPS 采⽤的是**对称加密**和**⾮对称加密**结合的「混合加密」⽅式：

- 在通信建⽴前采⽤非对称加密的⽅式交换「会话秘钥」，后续就不再使⽤⾮对称加密。**（非对称加密--密钥）**
- 在通信过程中全部使⽤对称加密的「会话秘钥」的⽅式加密明⽂数据。**（对称加密--明文）**

对称加密就是发送双发使用相同的密钥对消息进行加解密，常见的对称加密为**DES、3DES,AES**等。

非对称加密是发送双方各自拥有一对公钥私钥，其中公钥是公开的，私钥是保密的。当发送方向接收方发送消息时，发送方利用接收方的公钥对消息进行加密，接收方收到消息后，利用自己的私钥解密就能得到消息的明文。其中非对称加密方法有**RSA、Elgamal、ECC**等

##### 1、对称加密



##### 2、非对称加密



#### 3.4、相关算法

##### 1、RSA

​		传统的 TLS 握⼿基本都是使⽤ RSA 算法来实现密钥交换的，在将 TLS 证书部署服务端时，证书⽂件中包含⼀对公私钥，其中公钥会在 TLS 握⼿阶段传递给客户端，私钥则⼀直留在服务端，⼀定要确保私钥不能被窃取。

​		在 RSA 密钥协商算法中，客户端会⽣成随机密钥，并使⽤服务端的公钥加密后再传给服务端。根据⾮对称加密算法，公钥加密的消息仅能通过私钥解密，这样服务端解密后，双⽅就得到了相同的密钥，再⽤它加密应⽤消息。

##### 2、ECDHE算法

#### 3.5、中间人攻击：

​		针对SSL的中间人攻击主要分为：SSL劫持攻击和SSL剥离攻击。

###### 1）SSL劫持攻击：

- 攻击者在传输过程中伪造服务器的证书，将服务器的公钥替换成自己的公钥；但是对于客户端来说，如果中间人伪造了证书，在校验证书过程中会提示证书错误。

###### 2）SSL剥离攻击：

- 中间人和服务器之间仍然保持HTTPS服务器；之后将HTTPS范文替换为HTTP返回给浏览器。



##### http和https连接时有多少个rtt

##### 断点续传如何实现的



### 4、OSI模型

#### 4.1、OSI七层模型

<img src="总结面试题.assets/image-20210827104629777.png" alt="image-20210827104629777" style="zoom:67%;" />

!(总结面试题.assets/image-20210826212301871.png)

![image-20210826212400025](总结面试题.assets/image-20210826212400025.png)

#### 4.2、七层模型功能

​		物理层：利用传输介质为数据链路层提供物理连接，实现比特流的透明传输，如网线；网卡标准。

​		数据链路层：接收来自物理层的位流形式的数据，并封装成帧，传送到上一层，定义数据的基本格式，如何传输，如何标识，MAC

​		网络层：将网络地址翻译成对应的物理地址，并通过路由选择算法为分组通过通信子网选择最适当的路径，如不同设备的数据转发。

​		传输层：端到端传输数据的基本功能；如 TCP、UDP。

​		会话层：负责在网络中的两节点之间建立、维持和终止通信；如不同软件数据分发给不同软件。

​		表示层：处理用户信息的表示问题，数据的编码，压缩和解压缩，数据的加密和解密。

​		应用层：为用户的应用进程提供网络通信服务以及各种应用软件，包括 Web 应用。

**==说明==：**

​		在四层，既传输层数据被称作**段**（Segments）；

​		三层网络层数据被称做**包**（Packages）；

​		二层数据链路层时数据被称为**帧**（Frames）；

​		一层物理层时数据被称为**比特流**（Bits）。

**==总结==**

​	网络七层模型是一个标准，而非实现，网络四层模型是一个实现的应用模型，网络四层模型由七层模型简化合并而来。

#### 4.3、网络模型相关协议

##### 1、应用层协议

- TCP对应的应用层协议

| FTP ：定义了文件传输协议，21 （20传输，21连接） |
| ----------------------------------------------- |
| Telnet：它是一种用于远程登陆的端口，23          |
| SMTP：定义了简单邮件传送协议，服务器开放  ，25  |
| POP3：它是和SMTP对应，POP3用于接收邮件，110     |
| HTTP：超文本传输协议，80                        |
| HTTPS：超文本安全协议，443                      |

- UDP对应的应用层协议

| DNS：用于域名解析服务，53  （服务器传输TCP，客户端查询服务器UDP） |
| ------------------------------------------------------------ |
| SNMP：简单网络管理协议，161                                  |
| TFTP(Trival File Transfer Protocal)：简单文件传输协议，69    |

##### 2、传输层协议

| TCP： |
| ----- |
| UDP： |

##### 3、网络层协议

| ARP：地址解析协议 ，根据IP地址获取物理MAC地址                |
| ------------------------------------------------------------ |
| IP：TCP/IP协议簇中的核心协议，也是TCP/IP的载体，IP提供不可靠的，无连接的数据传送服务 |
| ICMP：网络控制报文协议，确认IP包是否成功达到目标地址，通知IP包丢失的原因（目标不可达、原点抑制、重定向、改变路由、时间戳） |
| IGMP：组管理协议，让一个物理网络上的所有系统知道主机当前所在的多播组 |
|                                                              |
| DHCP：动态主机配置协议，自动的给子网内新增主机结点分配IP地址，避免手动管理IP |
| OSPF：开放式最短路径优先，                                   |
| BGP：边界网关协议，用来连接Internet上独立系统的路由选择协议  |
|                                                              |

##### 4、数据链路层协议

| ARP ：地址解析协议 ，根据IP地址获取物理MAC地址               |
| ------------------------------------------------------------ |
| RARP：反向地址转换协议，根据物理MAC地址获取IP地址            |
| PPP：点对点协议，主要是用来通过拨号或专线方式建立点对点连接发送数据，使其成为各种主 |



### 5、TCP

#### 5.1、TCP/UDP基本认识

TCP是面向连接的（一对一）、可靠的、基于字节流的传输层通信协议。

**TCP连接：用于保证可靠性和流量控制维护的某些状态信息，包括Socket（IP+port）、序列号（解决乱序）和窗口大小（流量控制**）

- ⾯向连接：⼀定是「⼀对⼀」才能连接，不能像 UDP 协议可以⼀个主机同时向多个主机发送消息，也就是⼀对多是⽆法做到的；
- 可靠的：⽆论的⽹络链路中出现了怎样的链路变化，TCP 都可以保证⼀个报⽂⼀定能够到达接收端；

- 字节流：消息是「没有边界」的，所以⽆论我们消息有多⼤都可以进⾏传输。并且消息是「有序的」，当「前⼀个」消息没有收到的时候，即使它先收到了后⾯的字节，那么也不能扔给应⽤层去处理，同时对「重复」的报⽂会⾃动丢弃。

UDP是不可靠、基于报文的、可实现多个连接的传输层通信协议。

#### 5.2、TCP/UDP报头格式

##### 1、TCP报头格式

<img src="总结面试题.assets/image-20210825222936514.png" alt="image-20210825222936514" style="zoom:50%;" />

​		**Seq序列号：**在建⽴连接时由计算机⽣成的随机数作为其初始值，通过 SYN 包传给接收端主机，每发送⼀次数据，就「累加」⼀次该「数据字节数」的⼤⼩。**⽤来解决⽹络包乱序问题**。

​		**Ack确认应答号：**指下⼀次「期望」收到的数据的序列号，发送端收到这个确认应答以后可以认为在这个序号以前的数据都已经被正常接收。**⽤来解决不丢包的问题**。

​		**窗口大小：**(window size)滑动窗口，用于告知对方（发送方）本方的缓冲还能接收多少字节数据，主要进行流量控制。

​		**校验和**：接收端用CRC检验整个报文段有无损坏。

**标志位**：

- **ACK**：该位为 1 时，「确认应答」的字段变为有效，TCP 规定除了最初建⽴连接时的 SYN 包之外该位必须设置为 1 。
- **RST**：该位为 1 时，表示 TCP 连接中出现异常必须强制断开连接。
- **SYN**：该位为 1 时，表示希望建⽴连接，并在其「序列号」的字段进⾏序列号初始值的设定（连接报文段）。
- **FIN**：该位为 1 时，表示今后不会再有数据发送，希望断开连接。当通信结束希望断开连接时，通信双⽅的主机之间就可以相互交换 FIN 位为 1 的 TCP 段。
- **PSH**：提示接收端立刻从缓冲读走数据。
- **RST**：表示要求对方重新建立连接（复位报文段）。

##### 2、UDP报头格式

<img src="总结面试题.assets/image-20210825223559839.png" alt="image-20210825223559839" style="zoom:50%;" />

​		**⽬标和源端⼝**：主要是告诉 UDP 协议应该把报⽂发给哪个进程。

​		**包⻓度**：该字段保存了 UDP ⾸部的⻓度跟数据的⻓度之和。

​		**校验和**：校验和是为了提供可靠的 UDP ⾸部和数据⽽设计。

##### 3、IP报头格式



#### 5.3、TCP和UDP区别

###### **1）连接**

​		TCP 是⾯向连接的传输层协议，传输数据前先要建⽴连接。

​		UDP 是不需要连接，即刻传输数据。

###### **2）服务对象**

​		TCP 是⼀对⼀的两点服务，即⼀条连接只有两个端点。

​		UDP ⽀持⼀对⼀、⼀对多、多对多的交互通信

###### **3）可靠性**

​		TCP 是可靠交付数据的，数据可以⽆差错、不丢失、不᯿复、按需到达。

​		UDP 是尽最⼤努⼒交付，不保证可靠交付数据。

###### **4）拥塞控制、流量控制**

​		TCP 有拥塞控制和流量控制机制，保证数据传输的安全性。UDP 则没有，即使⽹络⾮常拥堵了，也不会影响 UDP 的发送速率。

###### **5）⾸部开销**

​		TCP ⾸部⻓度较⻓，会有⼀定的开销，⾸部在没有使⽤「选项」字段时是 **20** 个字节，如果使⽤了「选项」字段则会变⻓的。

​		UDP ⾸部只有 **8** 个字节，并且是固定不变的，开销较⼩。

###### **6）传输⽅式**

​		TCP 是流式传输，没有边界，但保证顺序和可靠。

​		UDP 是⼀个包⼀个包的发送，是有边界的，但可能会丢包和乱序。

###### **7）分片不同**

​		TCP 的数据⼤⼩如果⼤于 MSS ⼤⼩，则会在传输层进⾏分⽚，⽬标主机收到后，也同样在传输层组装 TCP数据包，如果中途丢失了⼀个分⽚，只需要传输丢失的这个分⽚。

​		UDP 的数据⼤⼩如果⼤于 MTU ⼤⼩，则会在 IP 层进⾏分⽚，⽬标主机收到后，在 IP 层组装完数据，接着再传给传输层，但是如果中途丢了⼀个分⽚，在实现可靠传输的 UDP 时则就需要重传所有的数据包，这样传输效率⾮常差，所以通常 UDP 的报⽂应该⼩于 MTU。

###### **问题一：为什么 UDP 头部没有「⾸部⻓度」字段，⽽ TCP 头部有「⾸部⻓度」字段呢？**

​		TCP 有可变⻓的「选项」字段，⽽ UDP 头部⻓度则是不会变化的，⽆需多⼀个字段去记录 UDP 的⾸部⻓度

###### **问题二：为什么 UDP 头部有「包⻓度」字段，⽽ TCP 头部则没有「包⻓度」字段呢？**

​		TCP数据长度 = IP总长度 - IP首部长度 - TCP首部长度，因此TCP数据长度是可以计算出来的。虽然UDP头部有包长度字段看起来有点冗余，但是它主要是为了网络硬件设备的设计和处理的方便，首部长度需要是4bity的整数倍。所以，包长度有可能是为了补全UDP首部长度是4bity的整数倍。

###### **问题三：UDP和TCP数据包最大值的确定？**

​		MTU最大传输单元，这个传输单元实际上和数据链路层有密切的关系，由于以太网传输方面的限制，每个以太网帧有最小64bytes和最大1518bytes，超过大小限制（过大或者过小的）都视为错误的数据帧，那以太网转发设备就会丢弃这些数据帧。以太网最大的数据帧是1518bytes，所以刨去以太网的帧头14bytes和帧尾4bytes，剩下1500bytes就是MTU。

- UDP包的大小为：1500 - IP头（20）- UDP头（8） = 1472 
- TCP包的大小为：1500 - IP头（20）- TCP头（20） = 1460

#### 5.4、**TCP 和 UDP 应用场景：**

由于 TCP 是⾯向连接，能保证数据的可靠性交付，因此经常⽤于：

- FTP ⽂件传输

- HTTP / HTTPS

由于 UDP ⾯向⽆连接，它可以随时发送数据，再加上UDP本身的处理既简单⼜⾼效，因此经常⽤于：

- 包总量较少的通信，如 DNS 、 SNMP 等

- 视频、⾳频等多媒体通信

- ⼴播通信

#### 5.5、如何唯一确定一个TCP连接？

​		TCP是四元组（IP+port）

#### 5.6、TCP最大连接数？

​		一般服务器固定在某个本地端口上监听，等待客户端的链接请求，因此客户端IP和port可变的。

​		理论上：max(TCP连接数) = 客户端IP * 客户端port

​		对 IPv4，客户端的 IP 数最多为 2 的 32 次⽅，客户端的端⼝数最多为 2 的 16 次⽅，也就是服务端单机最⼤ TCP 连接数，约为 2 的 48 次⽅。当然，服务端最⼤并发 TCP 连接数远**不能达到理论上限**。⾸先主要是**⽂件描述符限制**，Socket 都是⽂件，所以⾸先要通过 ulimit 配置⽂件描述符的数⽬；另⼀个是**内存限制**，每个 TCP 连接都要占⽤⼀定内存，操作系统的内存是有限的

- **⽂件描述符**：Socket 实际上是⼀个⽂件，也就会对应⼀个⽂件描述符。在 Linux 下，单个进程打开的⽂件描述符数是有限制的，没有经过修改的值⼀般都是 1024，不过我们可以通过 ulimit 增⼤⽂件描述符的数⽬；
- **系统内存**：每个 TCP 连接在内核中都有对应的数据结构，意味着每个连接都是会占⽤⼀定内存的；



### 6、TCP三次握手

#### 6.1、TCP三次握手

<img src="总结面试题.assets/image-20210826103430358.png" alt="image-20210826103430358" style="zoom:67%;" />

​		三次握手（Three-way Handshake）其实就是指建立一个TCP连接时，需要客户端和服务器总共发送3个包。进行三次握手的主要作用就是为了确认双方的接收能力和发送能力是否正常、指定自己的初始化序列号为后面的可靠性传送做准备。实质上其实就是连接服务器指定端口，建立TCP连接，并**同步连接双方的序列号和确认号，交换 TCP窗口大小** 信息。

**==重点==**

​	**TCP连接：用于保证可靠性和流量控制维护的某些状态信息，包括Socket（IP+port）、序列号（解决乱序）和窗口大小（流量控制**）

#### 6.2、为什么要三次握手才能初始化Socket、序列号和窗口大小并建立TCP连接？

三次握手的原因（三方面）：

- 三次握⼿才可以**阻⽌重复历史连接的初始化**（主要原因）--⾸要原因是为了**防止旧的重复连接初始化造成混乱**
- 三次握⼿才可以**同步双方的初始序列号**
- 三次握⼿才可以**避免资源浪费**

##### 1、防止旧的重复连接初始化造成混乱

​		客户端通过**上下文比较**，发现自己期望收到的Ack num 应该是100 + 1 ，而不是 90 + 1，所以就会向服务器发起**RST**报文终止连接。

​		客户端连续发送**多次 SYN 建立连接**的报⽂，在**⽹络拥堵**情况下：

- ⼀个「旧 SYN 报⽂」⽐「最新的 SYN 」 报⽂早到达了服务端；

- 那么此时服务端就会回⼀个 SYN + ACK 报⽂给客户端；

- 客户端收到后可以根据⾃身的上下⽂，判断这是⼀个历史连接（序列号过期或超时），那么客户端就会发送**RST 报⽂**给服务端，表示中⽌这⼀次连接。

**注**：如果是两次握⼿连接，就不能判断当前连接是否是历史连接，三次握⼿则可以在客户端（发送⽅）准备发送第三次报⽂时，客户端因有足够的上下⽂来判断当前连接是否是历史连接：

- 如果是历史连接（序列号过期或超时），则第三次握⼿发送的报⽂是 RST 报⽂，以此终止历史连接；
- 如果不是历史连接，则第三次发送的报⽂是 ACK 报⽂，通信双⽅就会成功建⽴连接；

##### 2、同步双方初始序列号

TCP 协议的通信双⽅， 都必须维护⼀个「序列号」， 序列号是可靠传输的⼀个关键因素，它的作⽤： 

- 接收⽅可以**去除重复的数据**；

- 接收方可以根据数据包的序列号**按序接收**；

- 可以**标识**发送出去的数据包中， 哪些是已经被对⽅收到的；

**注**：四次握⼿其实也能够可靠的同步双⽅的初始化序号，但由于第⼆步和第三步可以优化成⼀步，所以就成了「三次握⼿」。⽽两次握⼿只保证了⼀⽅的初始序列号能被对⽅成功接收，没办法保证双⽅的初始序列号都能被确认接收。

##### 3、避免资源浪费

​		如果只有「两次握⼿」，当客户端的 SYN 请求连接在⽹络中阻塞，客户端没有接收到 ACK 报⽂，就会重新发送 SYN ，由于没有第三次握⼿，服务器不清楚客户端是否收到了⾃⼰发送的建⽴连接的 ACK 确认信号，所以每收到⼀个 SYN 就只能先主动建⽴⼀个连接，这会造成什么情况呢？如果客户端的 SYN 阻塞了，重复发送多次 SYN 报⽂，那么服务器在收到请求后就会建⽴多个冗余的⽆效链接，造成不必要的资源浪费。**即两次握⼿会造成消息滞留情况下，服务器重复接受⽆⽤的连接请求 SYN 报⽂，⽽造成重复分配资源。**

#### 6.3、==总结==为什么握手是三次？不是两次或者四次？

​		TCP 建⽴连接时，通过三次握⼿能防⽌历史连接的建⽴，能减少双⽅不必要的资源开销，能帮助双⽅同步初始化序列号。序列号能够保证数据包不重复、不丢弃和按序传输。

​		不使⽤「两次握⼿」和「四次握⼿」的原因：

- 「两次握⼿」：⽆法防⽌历史连接的建⽴，会造成双⽅资源的浪费，也⽆法可靠的同步双⽅序列号；

- 「四次握⼿」：三次握⼿就已经理论上最少可靠连接建⽴，所以不需要使⽤更多的通信次数。

#### 6.4、为什么第三次握手是可以携带数据的，前两次握手是不可以携带数据的?

​		其实第三次握手的时候，是可以携带数据的。但是，**第一次、第二次握手不可以携带数据**。

​		为什么这样呢?大家可以想一个问题，假如第一次握手可以携带数据的话，如果有人要恶意攻击服务器，那他每次都在第一次握手中的 SYN 报文中放入大量的数据。因为攻击者根本就不理服务器的接收、发送能力是否正常，然后疯狂着重复发 SYN 报文的话，这会让服务器花费很多时间、内存空间来接收这些报文。

​		也就是说，**第一次握手不可以放数据，其中一个简单的原因就是会让服务器更加容易受到攻击了。而对于第三次的话，此时客户端已经处于ESTABLISHED状态。对于客户端来说，他已经建立起连接了，**并且也已经知道服务器的接收、发送能力是正常的了，所以能携带数据也没啥毛病。

#### 6.5、如何在Linux系统中查看TCP状态？

​		TCP 的连接状态查看，在 Linux 可以通过 **netstat -napt** 命令查看。

![image-20210826104205382](总结面试题.assets/image-20210826104205382.png)

#### 6.6、为什么客户端和服务端的初始序列号ISN是不同的？

​		如果⼀个已经失效的连接被重⽤了，但是该**旧连接**的历史报⽂还残留在⽹络中，如果序列号相同，那么就⽆法分辨出该报⽂是不是历史报⽂，如果历史报⽂被新的连接接收了，则会产⽣数据错乱。所以，每次建⽴连接前重新初始化⼀个序列号主要是为了通信双⽅能够根据序号将不属于本连接的报⽂段丢弃。另⼀⽅⾯是为了**安全性**，防⽌⿊客伪造的相同序列号的 TCP 报⽂被对⽅接收。

#### 6.7、初始序列号ISN是如何随机产生的？

$$
ISN = M + F(localhost,localport,remotehost,remoteport)
$$

​		M是一个计数器，F是一个hash算法，根据四元组生成一个随意数值，一般使用MD5算法。

#### 6.8、既然IP层会分片，为什么TCP还需要MSS?

<img src="总结面试题.assets/image-20210826112400580.png" alt="image-20210826112400580" style="zoom:67%;" />

​		MTU ：⼀个⽹络包的最⼤⻓度，以太⽹中⼀般为 1500 字节；

​		MSS ：除去 IP 和 TCP 头部之后，⼀个⽹络包所能容纳的 TCP 数据的最⼤⻓度；

​		当 IP 层有⼀个超过 MTU ⼤⼩的数据（TCP 头部 + TCP 数据）要发送，那么 IP 层就要进⾏分⽚，把数据分⽚成若⼲⽚，保证每⼀个分⽚都⼩于 MTU。把⼀份 IP 数据报进⾏分⽚以后，由⽬标主机的 IP 层来进⾏重新组装后，再交给上⼀层 TCP 传输层。这看起来井然有序，但这存在隐患的，那么当如果⼀个 **IP** 分⽚丢失，整个 **IP** 报⽂的所有分⽚都得重传。

​		因为 IP 层本身没有超时重传机制，它由传输层的 TCP 来负责超时和重传。

​		当接收⽅发现 TCP 报⽂（头部 + 数据）的某⼀⽚丢失后，则不会响应 ACK 给对⽅，那么发送⽅的 TCP 在超时后，就会重发「整个 TCP 报⽂（头部 + 数据）」。因此，可以得知由 IP 层进⾏分⽚传输，是⾮常没有效率的。所以，为了达到最佳的传输效能 TCP 协议在建⽴连接的时候通常要协商双⽅的 **MSS** 值，当 TCP 层发现数据超过MSS 时，则就先会进⾏分⽚，当然由它形成的 IP 包的⻓度也就不会⼤于 MTU ，⾃然也就不⽤ IP 分⽚了。经过 TCP 层分⽚后，如果⼀个 TCP 分⽚丢失后，进⾏重发时也是以 **MSS** 为单位，⽽不⽤重传所有的分⽚，⼤⼤增加了重传的效率。

**==总结==**：**IP按MTU分⽚，如果某⼀⽚丢失则需要所有分⽚都重传；（2）IP没有重传机制，所以需要等TCP发送⽅超时才能重传；**

###### **问题⼀**：**MSS跟IP的MTU分⽚相⽐，只是多了⼀步协商MSS值的过程，⽽IP的MTU可以看作是默认协商好就是1500字节，所以为什么协商后的MSS可以做到丢失后只发丢失的这⼀⽚来提⾼效率，⽽默认协商好1500字节的IP分⽚就需要所有⽚都重传呢？**

- 如果⼀个⼤的 TCP 报⽂是被 **MTU 分⽚**，那么**只有「第⼀个分⽚」才具有 TCP 头部**，后⾯的分⽚则没有TCP 头部，接收⽅ IP 层只有重组了这些分⽚，才会认为是⼀个 TCP 报⽂，那么丢失了其中⼀个分⽚，接收⽅ IP 层就不会把 TCP 报⽂丢给 TCP 层，那么就会等待对⽅超时重传这⼀整个 TCP 报⽂。

- 如果⼀个⼤的 TCP 报⽂被 **MSS 分⽚**，那么**所有「分⽚都具有 TCP 头部」**，因为每个 MSS 分⽚的是具有TCP 头部的TCP报⽂，那么其中⼀个 MSS 分⽚丢失，就只需要重传这⼀个分⽚就可以。

###### **问题⼆**：**TCP MSS分⽚如果丢失了⼀⽚，是不是也需要发送⽅等待超时再重传？如果不是，MSS的协商如何能在超时前就直到丢了分⽚从⽽提⾼效率的呢？**

- TCP MSS分⽚如果丢失了⼀⽚，发送⽅没收到对⽅ACK应答，也是会触发超时重传的，因为TCP层是会保证数据的可靠交付。

#### 6.9、SYN攻击是什么？如何避免？

​		**服务器端的资源分配是在二次握手时分配的，而客户端的资源是在完成三次握手时分配的**，所以服务器容易受到SYN洪泛攻击。SYN攻击就是Client在短时间内伪造大量不存在的IP地址，并向Server不断地发送SYN包，Server则回复确认包，并等待Client确认，由于源地址不存在，因此Server需要不断重发直至超时，这些伪造的SYN包将长时间**占用未连接队列**，导致正常的SYN请求因为队列满而被丢弃，从而引起网络拥塞甚至系统瘫痪。SYN 攻击是一种典型的 DoS/DDoS 攻击。

​		检测 SYN 攻击非常的方便，当你在服务器上看到大量的半连接状态时，特别是源IP地址是随机的，基本上可以断定这是一次SYN攻击。在 Linux/Unix 上可以使用系统自带的 netstats 命令来检测 SYN 攻击。

```
netstat -n -p TCP | grep SYN_RECV
```

常见的防御 SYN 攻击的方法有如下几种：

- 缩短超时（SYN Timeout）时间

- 增加最大半连接数

- 过滤网关防护

- SYN cookies技术

其中⼀种解决⽅式是通过修改 Linux 内核参数，控制队列⼤⼩和当队列满时应做什么处理。
当⽹卡接收数据包的速度⼤于内核处理的速度时，会有⼀个队列保存这些数据包。控制该队列的最⼤值如下参数：

```
net.core.netdev_max_backlog
```

SYN_RCVD 状态连接的最⼤个数：

```
net.ipv4.tcp_max_syn_backlog
```

超出处理能时，对新的 SYN 直接回报 RST，丢弃连接：

```
net.ipv4.tcp_abort_on_overflow
```

当SYN队列占满，重新启动cookies

```
net.ipv4.tcp_syncookies = 1
```

- 当 「 SYN 队列」满之后，后续服务器收到 SYN 包，不进⼊「 SYN 队列」；

- 计算出⼀个 cookie 值，再以 SYN + ACK 中的「序列号」返回客户端，服务端接收到客户端的应答报⽂时，服务器会检查这个 ACK 包的合法性。如果合法，直接放⼊到「 Accept 队列」。

- 最后应⽤通过调⽤ accpet() socket 接⼝，从「 Accept 队列」取出的连接。

### 7、TCP四次挥手

<img src="总结面试题.assets/image-20210826111744017.png" alt="image-20210826111744017" style="zoom:67%;" />

#### 7.1、为什么挥手需要四次？

- 关闭连接时，客户端向服务端发送 FIN 时，仅仅表示客户端不再发送数据了但是还能接收数据。

- 服务器收到客户端的 FIN 报⽂时，先回⼀个 ACK 应答报⽂，⽽服务端可能还有数据需要处理和发送，等服务端不再发送数据时，才发送 FIN 报⽂给客户端来表示同意现在关闭连接。

**另一种回答：**

​		因为当服务端收到客户端的SYN连接请求报文后，可以直接发送SYN+ACK报文。其中**ACK报文是用来应答的，SYN报文是用来同步的**。但是关闭连接时，当服务端收到FIN报文时，很可能并不会立即关闭SOCKET，所以只能先回复一个ACK报文，告诉客户端，"你发的FIN报文我收到了"。只有等到我服务端所有的报文都发送完了，我才能发送FIN报文，因此不能一起发送。故需要四次挥手。

#### 7.2、为什么Time_wait等待时间是2MSL?

​		MSL 是 Maximum Segment Lifetime，报⽂最⼤⽣存时间，它是任何报⽂在⽹络上存在的最⻓时间，超过这个时间报⽂将被丢弃。因为 TCP 报⽂基于是 IP 协议的，⽽ IP 头中有⼀个 TTL 字段，是 IP 数据报可以经过的最⼤路由数，每经过⼀个处理他的路由器此值就减 1，当此值为 0 则数据报将被丢弃，同时发送 ICMP 报⽂通知源主机。

​		MSL 与 TTL 的区别： MSL 的单位是时间，⽽ TTL 是经过路由跳数。所以 **MSL** 应该要⼤于等于 **TTL** 消耗为 **0** 的时间，以确保报⽂已被⾃然消亡。

​		2MSL 的时间是从客户端接收到 **FIN** 后发送 **ACK** 开始计时的。如果在 TIME-WAIT 时间内，因为客户端的 ACK没有传输到服务端，客户端⼜接收到了服务端᯿发的 FIN 报⽂，那么 **2MSL** 时间将重新计时。 在 Linux 系统⾥ 2MSL 默认是 60 秒，那么⼀个 MSL 也就是 30 秒。**Linux** 系统停留在 **TIME_WAIT** 的时间为固定的 **60** 秒。

```
#define TCP_TIMEWAIT_LEN (60*HZ) //最长等待时间
```

#### 7.3、为什么需要Time_wait状态？

- 防⽌具有相同「四元组」的「旧」数据包被收到；

- 保证「被动关闭连接」的一方能被正确的关闭，即保证最后的 ACK 能让被动关闭⽅接收，从而帮助其正常关闭；

##### 1、防止旧连接的数据包

​		如果发生网络延迟或者存在服务器关闭之前的报文，那么如果有相同端口的TCP连接被复用，该延迟的报文抵达客户端，客户端仍然能够正常接收这个过期的报文，就会导致最后接收到的数据错乱。

##### 2、保证连接正确关闭

​		客户端四次挥⼿的最后⼀个 ACK 报⽂如果在⽹络中被丢失了，此时如果客户端 TIME-WAIT 过短或没有，则就直接进⼊了 CLOSED 状态了，那么服务端则会⼀直处在 LASE_ACK 状态。当客户端发起建⽴连接的 SYN 请求报⽂后，服务端会发送 RST 报⽂给客户端，连接建⽴的过程就会被终⽌。

#### **7.4、Time_wait过多怎么处理？**

过多的Time_wait状态主要危害有两种：

- 内存资源占用

- 对端口资源的占用，一个TCP连接至少会消耗一个本地端口。

端口数量是有限的，一般为32768~61000（max=65535），如果端口资源占用过多的话，会导致无法创建新的连接。

```
net.ipv4.ip_local_port_range
```

##### **问题一**：**如果客户端第四次挥⼿ack丢失，服务端超时重发的fin报⽂也丢失，客户端timewait时间超过了2msl，这个时候会发⽣什么？认为连接已经关闭吗？**

- 当客户端 timewait 时间超过了 2MSL，则客户端就直接进⼊**关闭**状态。服务端超时重发 fin 报⽂的次数如果超过 **tcp_orphan_retries** 大小后，服务端也会关闭 TCP 连接。

##### **问题二**：**如果是服务提供方发起的 close ，然后引起过多的 time_wait 状态的 tcp 链接，time_wait 会影响服务端的端⼝吗？**

- 不会，如果发起连接⼀⽅（客户端）的 TIME_WAIT 状态过多，占满了所有端⼝资源，则会导致⽆法创建新连接

  

  客户端受端⼝资源限制：

  - 客户端TIME_WAIT过多，就会导致端⼝资源被占⽤，因为端⼝就65536个，被占满就会导致⽆法创建新连接。

  服务端受系统资源限制：

  - 由于⼀个 TCP 四元组表示 TCP 连接，理论上服务端可以建⽴很多连接，服务端只监听⼀个端⼝，但是会把连接扔给处理线程，所以理论上监听的端⼝可以继续监听。但是**线程池**处理不了那么多⼀直不断的连接了。所以当服务端出现大量 TIMEWAIT 时，系统资源容易被耗尽。

##### **问题三：服务端设置 SO_REUSEADDR 选项，这样服务器程序在重启后，可以⽴刻使⽤。这⾥设置SO_REUSEADDR 是不是就等价于对这个 socket 设置了内核中的net.ipv4.tcp_tw_reuse=1 这个选项？**

- tcp_tw_reuse 是内核选项，主要⽤在连接的发起⽅（客户端）。TIME_WAIT 状态的连接创建时间超过 1 秒后，新的连接才可以被复⽤，注意，这⾥是「连接的发起⽅」；

- SO_REUSEADDR 是⽤户态的选项，⽤于「连接的服务⽅」，⽤来告诉操作系统内核，如果端⼝已被占⽤，但是 TCP 连接状态位于 TIME_WAIT ，可以重⽤端⼝。如果端⼝忙，⽽ TCP 处于其他状态，重⽤会有“Address already in use” 的错误信息。

tcp_tw_reuse 是为了缩短 time_wait 的时间，避免出现大量的 time_wait 连接⽽占⽤系统资源，解决的是 accept后的问题。

SO_REUSEADDR 是为了解决 time_wait 状态带来的端⼝占⽤问题，以及⽀持同⼀个 port 对应多个 ip，解决的是bind 时的问题。

#### 7.5、如何优化Time_wait?

```
打开 net.ipv4.tcp_tw_reuse 和 net.ipv4.tcp_timestamps 选项；
net.ipv4.tcp_max_tw_buckets
程序中使⽤ SO_LINGER ，应⽤强制使⽤ RST 关闭
```

1）net.ipv4.tcp_tw_reuse 和 net.ipv4.tcp_timestamps

​		作用：可以复⽤处于 **TIME_WAIT** 的 **socket** 为新的连接所⽤。但需要注意，**tcp_tw_reuse** 功能只能⽤客户端（连接发起⽅），因为开启了该功能，在调⽤ **connect()**函数时，内核会随机找⼀个 **time_wait** 状态超过 **1** 秒的连接给新的连接复⽤。（但需要对TCP 时间戳的⽀持）

```
net.ipv4.tcp_timestamps=1（默认即为 1）
```

2）net.ipv4.tcp_max_tw_buckets

​		这个值默认为 18000，当系统中处于 TIME_WAIT 的连接⼀旦超过这个值时，系统就会将后⾯的 **TIME_WAIT** 连接状态重置（但引入的问题会更多）

3）程序中使⽤ **SO_LINGER**，应⽤强制使⽤ RST 关闭

​		相当于通过设置socket选项，来设置调用close关闭连接的行为。调用close之后，会立刻发送一个RST标志给对端，直接跳过四次挥手，跳过time_wait，直接关闭。

#### 7.6、如果已经建立了连接，但是client突然发生故障怎么办？

​		TCP有一个保活机制（keep_alive）：

​		原理：定义⼀个时间段，在这个时间段内，如果没有任何连接相关的活动，TCP 保活机制会开始作⽤，每隔⼀个时间间隔，发送⼀个探测报⽂，该探测报⽂包含的数据⾮常少，如果连续⼏个探测报⽂都没有得到响应，则认为当前的TCP 连接已经死亡，系统内核将错误信息通知给上层应⽤程序。

​		在 Linux 内核可以有对应的参数可以设置保活时间、保活探测的次数、保活探测的时间间隔，以下都为默认值：

```
net.ipv4.tcp_keepalive_time=7200 //~2小时，两小时内如果没有任何连接相关的活动，则会启动保活机制
net.ipv4.tcp_keepalive_intvl=75  //每次检测间隔75s
net.ipv4.tcp_keepalive_probes=9  //检测响应次数最大9次，如果检测9次无响应，则认为对方不可达，从而中断本次连接
```

**==注意==**开启TCP保活机制，需要注意一下情况：

- 第⼀种，对端程序是正常⼯作的。当 TCP 保活的探测报⽂发送给对端, 对端会正常响应，这样 **TCP** 保活时间会被重置，等待下⼀个 TCP 保活时间的到来。

- 第⼆种，对端程序崩溃并重启。当 TCP 保活的探测报⽂发送给对端后，对端是可以响应的，但由于没有该连接的有效信息，会产⽣⼀个 **RST** 报⽂，这样很快就会发现 TCP 连接已经被重置。
- 第三种，是对端程序崩溃，或对端由于其他原因导致报⽂不可达。当 TCP 保活的探测报⽂发送给对端后，⽯沉⼤海，没有响应，连续⼏次，达到保活探测次数后，**TCP** 会报告该 **TCP** 连接已经死亡。

#### 7.7、服务器出现大量close_wait的连接的原因是什么？有什么解决方法？

close_wait状态是在TCP四次挥手的时候收到FIN但是没有发送自己的FIN时出现的，服务器出现大量close_wait状态的原因有两种：

- 服务器内部业务处理占用了过多时间，都没能处理完业务；或者还有数据需要发送；或者服务器的业务逻辑有问题，没有执行close()方法

- 服务器的父进程派生出子进程，子进程继承了socket，收到FIN的时候子进程处理但父进程没有处理该信号，导致socket的引用不为0无法回收

处理方法：

- 停止应用程序

- 修改程序里的bug



### 8、TCP如何保证可靠传输？

​		**校验和、确认机制（确认应答+序列号）、重传机制、连接管理（挥手和握手）、流量控制（滑动窗口）、拥塞控制**

#### 8.1、TCP可靠的原因？

​		每个TCP的socket在内核中都有一个**发送缓冲区**和**接收缓冲区**，TCP协议要求在对端接收到TCP数据报之后，对其序号进行ACK，只有当接收到一个TCP数据报的ACK之后，才可以把这个TCP数据报从socket的发送缓冲区清除，另外，TCP还有一个**流量控制**功能，TCP的socket接收缓冲区接收到网络上来的数据缓存后，如果应用程序一直没有读取，那接收缓冲区满了之后，就会通知对端TCP协议中的窗口关闭，就是**滑动窗口**实现流量控制，保证TCP的接收缓冲区不会溢出，因为对方不允许发送超过所通知窗口大小的数据，要是无视窗口大小而发送了超出窗口大小的数据，则接受发TCP将丢弃它。综上来说，TCP有三次握手、四次挥手，除此之外还有**超时重传机制**，对于每份报文也存在**校验和**，保证每份报文可靠性。

### 9、TCP重传、滑动窗口、拥塞控制、流量控制

#### 9.1、重传机制（丢包）

​		重传机制主要有四种：超时重传、快速重传、SACK、D-SACK

##### **1、超时重传**

在发送数据时，设定⼀个**定时器**，当超过指定的时间后，没有收到对⽅的 ACK确认应答报⽂，就会重发该数据。

- 应用场景：数据包丢失、确认应答丢失。

- 超时时间的设置：RTO > RTT

  **超时间隔加倍**：每当遇到⼀次超时重传的时候，都会将下⼀次超时时间间隔设为先前值的两倍。两次超时，就说明⽹络环境差，不宜频繁反复发送。

###### **问题一：超时重传、RTO与RTT区别是什么？**

- 超时重传：发送端发送报文后若长时间未收到确认的报文则需要重发该报文。可能有以下几种情况：

  - 发送的数据没能到达接收端，所以对方没有响应。

  - 接收端接收到数据，但是ACK报文在返回过程中丢失。

  - 接收端拒绝或丢弃数据。

- RTO（Retransmission Timeout 超时重传时间）：从上一次发送数据，因为长期没有收到ACK响应，到下一次重发之间的时间，即就是重传间隔。

  - 通常每次重传RTO是前一次重传间隔的两倍，计量单位通常是RTT。例：1RTT，2RTT，4RTT，8RTT......
  - 重传次数到达上限之后停止重传。

- RTT（Round-Trip Time 往返时延）：就是数据从网络一端传送到另一端所需的时间，即包的往返时间。

###### **问题二**：**如果RTO较长或较短时，会发生什么事情呢？**

- RTO较长：网路的空隙时间增大，降低了网络传输效率。

- RTO较短：产生不必要的重传（可能没有丢包但重发了），会导致网络负荷增大，造成网络拥塞。

###### **问题三：如何计算RTO?**

<img src="总结面试题.assets/image-20210827112415549.png" alt="image-20210827112415549" style="zoom:67%;" />

​		其中 SRTT 是计算平滑的RTT ， DevRTR 是计算平滑的RTT 与 最新 RTT 的差距。

​		在 Linux 下，**α = 0.125**，**β = 0.25**， **μ = 1**，**∂ = 4**（实验结论）

##### **2、快速重传**

​		不以时间为驱动，⽽是以数据驱动重传（**3次同样的ACK**触发快速重传机制）

​		但是，快速重传机制只解决了超时时间的问题，但是重传过程中存在一个问题，是重传之前的一个，还是重传所有？（SACK解决该问题）。

##### **3、SACK**

​		TCP头部[选项]字段里加SACK，就可以将缓存的地图发送给发送方，这样就可以知道哪些数据收到了，哪些数据没有收到，因此只需要重新传丢包的数据。

```
net.ipv4.tcp_sack
```

##### **4、D-SACK**

​	Duplicate SACK ，使用了SACK来告诉发送方有哪些数据被重复接收了。

​	D-SACK优势：

- 可以让「发送⽅」知道，是发出去的包丢了，还是接收方回应的 ACK 包丢了;

- 可以知道是不是「发送⽅」的数据包被⽹络延迟了;

- 可以知道⽹络中是不是把「发送⽅」的数据包给复制了;

```
net.ipv4.tcp_dsack
```

#### 9.2、滑动窗口

​		引言：TCP每发送一次数据，就需要应答一次，然后再发送下一个，这样就存在一个问题，如果应答时间较长的话，就会导致网络的吞吐量较低。所以为了解决数据包的往返时间越长，通信效率越低的问题，引入**窗口**。

​		窗口的实现实际上是操作系统开辟的一个缓存空间，发送方主机在等待确认应答返回之前，必须在缓冲区中保留已经发送的数据。如果已经确认应答，则可以删除缓存中的数据。

​		TCP头部有一个**window**字段，该字段主要是**接收端告诉发送端**自己还有多少缓冲区可以接收数据。于是发送端就可以根据这个接收端的处理能力来发送数据，而不会导致接收端处理不过来。

​		窗口大小：指不需要等待确认应答，而可以继续发送数据的最大值。

​		窗口的大小一般都是由**接收方**的窗口大小来决定。

###### **问题一：程序是如何表示发送方的四个部分呢？**

​		TCP 滑动窗⼝⽅案使⽤三个指针来跟踪在四个传输类别中的每⼀个类别中的字节。其中两个指针是绝对指针（指特定的序列号），⼀个是相对指针（需要做偏移）。

**发送窗口**：

**接收窗口**：

#### 9.3、流量控制

​		为了解决网络浪费的情况，引入流量控制，让发送方根据接收方的实际接收能力控制发送的数据量。

##### **1**、操作系统缓存区与滑动窗口的关系

​		当服务端系统资源⾮常紧张的时候，操⼼系统可能会直接减少了接收缓冲区⼤⼩，这时应⽤程序⼜⽆法及时读取缓存数据，那么这时候就有严重的事情发⽣了，会出现数据包丢失的现象。

- **TCP** 规定是不允许同时减少缓存⼜收缩窗⼝的，⽽是采⽤先收缩窗⼝，过段时间再减少缓存，这样就可以避免了丢包情况

##### **2、窗口关闭**：

​		窗口关闭：如果窗⼝⼤⼩为 **0** 时，就会阻⽌发送⽅给接收⽅传递数据，直到窗⼝变为⾮ **0** 为⽌，这就是窗⼝关闭。

###### **问题一：窗口关闭存在的问题？**

- 接收⽅向发送⽅通告窗⼝⼤⼩时，是通过 ACK 报⽂来通告的，那么，当发⽣窗⼝关闭时，接收⽅处理完数据后，会向发送⽅通告⼀个窗⼝⾮ 0 的 ACK 报⽂，如果这个通告窗⼝的 ACK 报⽂在⽹络中丢失了，那麻烦就⼤了。
- 这会导致发送⽅⼀直等待接收⽅的⾮ 0 窗⼝通知，接收⽅也⼀直等待发送⽅的数据，如不采取措施，这种相互等待的过程，会造成了死锁的现象。

###### **问题二：如何解决窗口关闭时，潜在的死锁现象？**

- TCP 为每个连接设有⼀个持续定时器，只要 **TCP** 连接⼀⽅**收到**对⽅的**零窗⼝**通知，就**启动持续计时器**
- 如果计时器超时，就会发送**窗口探测报文**，而对方在确认这个探测报文时，给出自己现在的接收窗口大小。
  - 如果窗口仍然为0，则又重新启动持续计时器；
  - 如果接收窗口不是0，那么接触死锁。

- 窗⼝探测的次数⼀般为 **3 次**，每次⼤约 30-60 秒（不同的实现可能会不⼀样）。如果 3 次过后接收窗⼝还是 0 的话，有的 TCP 实现就会发 **RST** 报⽂来中断连接

##### **3、糊涂窗口综合征**

​		如果接收⽅太忙了，来不及取⾛接收窗⼝⾥的数据，那么就会导致发送⽅的发送窗⼝越来越⼩。到最后，如果接收⽅腾出⼏个字节并告诉发送⽅现在有⼏个字节的窗⼝，⽽发送⽅会义⽆反顾地发送这⼏个字节，这就是糊涂窗⼝综合症。（一般针对小窗口问题）

###### **问题一：怎么让接收方不通告小窗口呢？**

- 当「窗⼝⼤⼩」⼩于 min( MSS，缓存空间/2 ) ，也就是⼩于 MSS 与 1/2 缓存⼤⼩中的最⼩值时，就会向发送⽅通告窗⼝为 0 ，也就阻⽌了发送⽅再发数据过来
- 等到接收⽅处理了⼀些数据后，窗⼝⼤⼩ >= MSS，或者接收⽅缓存空间有⼀半可以使⽤，就可以把窗⼝打开让发送⽅发送数据过来

###### **问题二：怎么让发送方避免发送小数据呢？**

- 使⽤ **Nagle 算法**，该算法的思路是**延时处理**，它满⾜以下两个条件中的⼀条才可以发送数据：

  - 要等到窗⼝⼤⼩ >= MSS 或是 数据⼤⼩ >= MSS

  - 收到之前发送数据的 ack 回包

只要没满⾜上⾯条件中的⼀条，发送⽅⼀直在囤积数据，直到满⾜上⾯的发送条件。

```
TCP_NODELAY //TCP通过设置该选项来关闭Nagle算法，一般默认打开，但是对于交互性比较强的程序，如telnet或ssh则需要关闭
setsockopt(sock_fd, IPPROTO_TCP, TCP_NODELAY, (char *)&value, sizeof(int));
```

#### 9.4、拥塞控制

​		拥塞控制目的是**避免「发送⽅」的数据填满整个⽹络**。

​		拥塞窗口：cwnd是发送方维护的一个状态变量，会根据网络的拥塞程度实现动态变化。

​		发送窗⼝ swnd 近似等于接收窗⼝ rwnd，引入拥塞窗口之后，此时发发送窗口swnd = min(cwnd, rwnd)。

​		拥塞窗口cwnd变化规则：如果未曾出现网络拥塞，则cwnd就会增大；一旦出现网络拥塞，cwnd就会减小。此时的网络拥塞的判断是，是否发生了超时重传，一旦发生了超时重传，即只要发送方没有在规定的时间内收到接收方ACK应答报文，则认为网络拥塞。

​		**==总述拥塞控制==**在刚开始传输就发送大量的数据，网络可能在一开始就很拥堵，持续发送就会越来越堵，拥堵的加剧会产生大量的丢包，大量的超时重传，严重影响传输。所以TCP引入**a)慢启动**机制，在开始发送数据的时候，先发送少量的数据探明当前网络的状况，再决定多大的速度进行传输，这时有种拥塞窗口的概念，发送刚开始定义拥塞窗口位1，每次收到ACK应答，拥塞窗口增加，发送数据前，将拥塞窗口与接收端反馈的窗口大小比对，取较小的值做为实际发送的窗口。慢启动只是说一开始发送的少，但是拥塞窗口的增加是指数级别的，为了控制拥塞窗口的增长，**b)拥塞避免**，设置拥塞窗口阙值，当拥塞窗口的大小超过阙值时，将不会按照原来的指数增长而是线性的增长。在慢启动开始的时候，慢启动的阙值等于窗口的最大值，一旦造成网络拥塞，发生超时重传，就会到**d) 快重传**接收方在收到一个失序的报文段就发出重复确认，发送方只要一连收到三个重复确认就应当立即重传对方未接受到的报文段，而不必继续等待设置重传计时器时间到期。**e) 快恢复**当收到3个重复的确认后，说明网络不那么糟糕，可以快速恢复，又进行慢启动，窗口阙值会降为发生网络拥塞时窗口大小的一半，同时拥塞窗口重置为1。

<img src="总结面试题.assets/image-20210828101654834.png" alt="image-20210828101654834" style="zoom:67%;" />

##### **1、慢启动**：

​		慢启动：也就是⼀点⼀点的提⾼发送数据包的数量。

​		慢启动**规则**：当发送⽅每收到⼀个 **ACK**，拥塞窗⼝ **cwnd** 的⼤⼩就会加 **1**，但是慢启动算法其发包的个数是指数性的增长。当到达慢启动门限ssthresh状态变量时，就要开始使用拥塞避免算法。

- 当cwnd < ssthresh 时，使⽤慢启动算法。

- 当 cwnd >= ssthresh 时，就会使⽤「拥塞避免算法」。

##### **2、拥塞避免**

​		当cwnd >= ssthresh时，就使用拥塞避免算法，⼀般来说 ssthresh 的⼤⼩是 65535 字节。

​		拥塞避免规则：

- 每当收到⼀个 **ACK** 时，**cwnd** 增加 **1/cwnd**

- 每当过了一个往返延迟时间RTT，cwnd大小加一。

​		目的是将慢启动算法中的指数增长变成了**线性**增长，但仍然处于增长状态，只是增长的速度更缓慢一些。但，随着数据包一直增加，也会导致网路拥塞，于是就存在丢包现象，就需要对丢包的数据进行重传，**触发重传机制，也就进入了「拥塞发生算法」**。

##### **3、拥塞发生**

​		一般来说，TCP拥塞控制默认认为网络丢包是由于网络拥塞导致的，所以一般的TCP拥塞控制算法以丢包为网络进入拥塞状态的信号。对于丢包有两种判定方式，一种是超时重传**RTO**[Retransmission Timeout]超时，另一个是收到**三**个重复确认**ACK**。

​		超时重传RTO是TCP协议保证数据可靠性的一个重要机制，其原理是在发送一个数据以后就开启一个**计时器**，在一定时间内如果没有得到发送数据报的ACK报文，那么就重新发送数据，直到发送成功为止。但是如果发送端接收到3个以上的重复ACK，TCP就意识到数据发生丢失，需要重传。这个机制不需要等到重传定时器超时，所以叫做**快速重传**，而快速重传后没有使用慢启动算法，而是拥塞避免算法，所以这又叫做**快速恢复**算法。

- 超时重传RTO[Retransmission Timeout]超时，TCP会重传数据包。（重新从慢启动开始，会造成网路卡顿情况）
  - 由于发生丢包，将慢启动阈值ssthresh设置为当前cwnd的一半，即**ssthresh = cwnd / 2**.
  - cwnd重置为1
  - 进入**慢启动**过程

- 快速重传：3次重复ACK，不用等到RTO超时再进行重传
  - cwnd大小缩小为当前的一半，**cwnd = cwnd / 2**；
  - ssthresh设置为缩小后的cwnd大小，**ssthresh = cwnd**；
  - 然后进入**快速恢复**算法Fast Recovery。

##### **4、快重传、快恢复**

- cwnd = cwnd + 3 *MSS*，加*3* MSS的原因是因为收到3个重复的ACK。

- 重传DACKs指定的数据包。

- 如果再收到DACKs，那么cwnd大小增加一。

- 如果收到新的ACK，表明重传的包成功了，那么退出快速恢复算法。将cwnd设置为ssthresh，然后进入拥塞避免算法。

###### **问题一：为什么快速重传是选择三次ACK，而不是两次或者四次？**

- 主要的考虑还是要区分包的丢失是由于链路故障还是乱序等其他因素引发。
- 两次duplicated ACK时很可能是乱序造成的！三次duplicated ACK时很可能是丢包造成的！四次duplicated ACK更更更可能是丢包造成的，但是这样的响应策略太慢。丢包肯定会造成三次duplicated ACK!综上是选择收到三个重复确认时窗口减半效果最好，这是实践经验。

###### **问题二：丢包原因有哪些？**

- 在没有fast retransmit / recovery 算法之前，重传依靠发送方的retransmit timeout，就是在timeout内如果没有接收到对方的ACK，默认包丢了，发送方就重传，包的丢失原因：
  - 包checksum 出错
  - 网络拥塞
  - 网络断，包括路由重收敛，但是发送方无法判断是哪一种情况，于是采用最笨的办法，就是将自己的发送速率减半，即CWND 减为1/2，这样的方法对2是有效的，可以缓解网络拥塞，3则无所谓，反正网络断了，无论发快发慢都会被丢；但对于1来说，丢包是因为偶尔的出错引起，一丢包就对半减速不合理。

- 于是有了fast retransmit 算法，基于在反向还可以接收到ACK，可以认为网络并没有断，否则也接收不到ACK，如果在timeout 时间内没有接收到> 2 的duplicated ACK，则概率大事件为乱序，乱序无需重传，接收方会进行排序工作；而如果接收到三个或三个以上的duplicated ACK，则大概率是丢包，可以逻辑推理，发送方可以接收ACK，则网络是通的，可能是1、2造成的，先不降速，重传一次，如果接收到正确的ACK，则一切OK，流速依然（包出错被丢）。而如果依然接收到duplicated ACK，也就是DACK，则认为是网络拥塞造成的，此时降速则比较合理。



### 10、Nagle算法&&延迟ACK

#### 10.1、Nagle算法：

​		Nagle算法是**为了减少广域网的小分组数目**，从而减小网络拥塞的出现；

- Nagle算法策略：
  - 没有已发送为确认的报文时，立即发送数据
  - 存在未确认报文时，直到「没有已发送未确认报⽂」或「数据⻓度达到 MSS ⼤⼩」时，再发送数据。

​		**该算法要求一个tcp连接上最多只能有一个未被确认的未完成的小分组，在该分组ack到达之前不能发送其他的小分组，tcp需要收集这些少量的分组，并在ack到来时以一个分组的方式发送出去；其中小分组的定义是小于MSS的任何分组；**

- Nagle算法优点：
  - 自适应的，确认到达的越快，数据也就发送的越快；
  - 在希望减少微小分组数目的低速广域网上，则会发送更少的分组；

```
TCP_NODELAY //TCP通过设置该选项来关闭Nagle算法，一般默认打开，但是对于交互性比较强的程序，如telnet或ssh则需要关闭
setsockopt(sock_fd, IPPROTO_TCP, TCP_NODELAY, (char *)&value, sizeof(int));
```

#### 10.2、延迟ACK：

- 延迟ACK策略：
  - 当有响应数据要发送时，ACK会随着响应数据一起立刻发送给对方；
  - 当没有响应数据要发送时，ACK会延迟一段时间，以等待是否有响应数据可以一起发送；
  - 如果在延迟等待发送ACK期间，对方的第二个数据报文到达了，则立即发送ACK。

​		**如果tcp对每个数据包都发送一个ack确认，那么只是一个单独的数据包为了发送一个ack代价比较高，所以tcp会延迟一段时间，如果这段时间内有数据发送到对端，则捎带发送ack，如果在延迟ack定时器触发时候，发现ack尚未发送，则立即单独发送；**

- 延迟ACK好处：
  - 避免糊涂窗口综合症；
  - 发送数据的时候将ack捎带发送，不必单独发送ack；
  - 如果延迟时间内有多个数据段到达，那么允许协议栈发送一个ack确认多个报文段；

```
//关闭TCP延迟ACK
//通过在socket设置TCP_QUICKACK来关闭这个算法
setsockeopt(sock_fd, IPPROTO_TCP, TCP_QUICKACK, (char*)& value, sizeof(int));
```

#### 10.3、当Nagle遇上延迟ACK：

​		试想如下典型操作，写-写-读，即通过多个写小片数据向对端发送单个逻辑的操作，两次写数据长度小于MSS，当第一次写数据到达对端后，对端延迟ack，不发送ack，而本端因为要发送的数据长度小于MSS，所以nagle算法起作用，数据并不会立即发送，而是等待对端发送的第一次数据确认ack；这样的情况下，需要等待对端超时发送ack，然后本段才能发送第二次写的数据，从而造成延迟；

#### 10.4、关闭Nagle算法：

​		使用TCP套接字选项**TCP_NODELAY**可以关闭套接字选项;

​		如下场景考虑关闭Nagle算法：

- 对端不向本端发送数据，并且对延时比较敏感的操作；这种操作没法捎带ack；


-  如上写-写-读操作；对于此种情况，优先使用其他方式，而不是关闭Nagle算法：
  - 使用writev，而不是两次调用write，单个writev调用会使tcp输出一次而不是两次，只产生一个tcp分节，这是首选方法；
  - 把两次写操作的数据复制到单个缓冲区，然后对缓冲区调用一次write；
  - 关闭Nagle算法，调用write两次；有损于网络，通常不考虑；

#### 10.5、禁止Nagle和开启Nagle算法发送数据与确认示意图：



### 11 、TCP异常分析

#### 11.1、TCP第一次握手的SYN丢包了，会发生什么？

​		客户端发起SYN包后，如果一直没有收到服务端的ACK，就会触发超时重传RTO机制。在Linux中，第一次捂手的SYN超时重传次数是由内核参数指定，**tcp_syn_retires**默认重传5次。因此，当客户端TCP第一次握手发生SYN包，在超过时间内没有收到服务端的ACK报文，就会超时重传SYN数据包，每次超时重传RTO是成倍增加的，直到超过SYN包重传次数，则客户端不再发送SYN包。

#### 11.2、TCP第二次握手的SYN、ACK丢包了，会发生什么？

​		当第二次握手的SYN和ACK丢包时，客户端会超时重发SYN包，服务端会超时重发SYN + ACK包。在Linux中，第二次捂手的SYN + ACK 超时重传次数是由内核参数指定，**tcp_synack_retires**默认重传5次。超过重传次数之后，**服务端的TCP连接主动断开**，但是客户端仍然处于established状态。

#### 11.3、TCP第三次握手的ACK丢包了，会发生什么？

​		由于服务端已经断开连接，此时客户端再次向服务端发送数据报文，则会一直处于超时重传状态，每重传一次，RTO翻倍增长，所以持续一段时间之后，共重传15次之后，客户端的talent才报错退出。最⼤超时重传次数是由 **tcp_retries2** 指定，默认值是 15 次。

#### 11.4、如果客户端不发送数据，什么时候才会断开处于established状态的连接？

​		核心：保活机制**keeping_alive**

​		定义⼀个时间段，在这个时间段内，如果没有任何连接相关的活动，TCP 保活机制会开始作⽤，每隔⼀个时间间隔，发送⼀个「探测报⽂」，该探测报⽂包含的数据⾮常少，如果连续⼏个探测报⽂都没有得到响应，则认为当前的 TCP 连接已经死亡，系统内核将错误信息通知给上层应⽤程序。

#### **==总结==**

​		在建⽴ TCP 连接时，如果第三次握⼿的 ACK，服务端⽆法收到，则服务端就会短暂处于 SYN_RECV 状态，⽽客户端会处于 ESTABLISHED 状态。

​		由于服务端⼀直收不到 TCP 第三次握⼿的 ACK，则会⼀直重传 SYN、ACK 包，直到重传次数超过tcp_synack_retries 值（默认值 5 次）后，服务端就会断开 TCP 连接。

​		⽽客户端则会有两种情况：

- 如果客户端没发送数据包，⼀直处于 ESTABLISHED 状态，然后经过 （保活机制时间）2 ⼩时 11 分 15 秒才可以发现⼀个「死亡」连接，于是客户端连接就会断开连接。

- 如果客户端发送了数据包，⼀直没有收到服务端对该数据包的确认报⽂，则会⼀直重传该数据包，直到重传次数超过 tcp_retries2 值（默认值 15 次）后，客户端就会断开 TCP 连接。



### 12、拆包和粘包

#### 12.1、TCP和UDP哪个会发生粘包？

​    只有TCP会产生粘包，UDP不会。首先，TCP采用的SOCKET是SOCK_STREAM (流式套接字) ，UDP是SOCK_DGRAM（数据报套接字）。TCP基于字节流，虽然应用层和TCP传输层之间的数据交互是大小不等的数据块，但是TCP把这些数据块仅仅看成一串无结构的字节流，没有边界，并且TCP首部没有表示数据长度的字段。UDP是基于数据报发送，从UDP的帧结构可以看出，UDP的首部采用了16bits来指示UDP报文的长度，所以在应用层可以很好的将不同的数据报文区分开。

#### 12.2、粘包、拆包的可能情况

​      粘包：接收端只收到一个数据包，但是TCP是不会出现丢包，所以就会出现一个数据包中包含了发送端发送的两个数据包的信息，由于接收端不知道这两个数据包的界限，就是粘包现象。

​      拆包和粘包：接收端接收到了两个数据包，但是这两个数据包要么是不完整的，要么就是多出来一块，就发生了拆包和粘包。

#### 12.3、粘包、拆包发生的原因

- 发送的数据大于TCP发送缓冲区剩余空间大小，将会发生拆包；
- 待发送数据大于MSS（最大报文长度），TCP在传输前将进行拆包；
- 要发送的数据小于TCP发送缓冲区的大小，TCP将多次写入缓冲区的数据一次性发送出去，将会发生粘包；
- 接收数据端的应用层没有及时读取接收缓冲区中的数据，将发生粘包。

#### 12.4、解决办法

关键在于给每个数据包添加边界信息，一般有如下几种处理方式：

- 发送端给每个数据包添加包头，头部包含数据包的长度信息，这样接收端在接收到数据之后，可以通过包头的长度字段，来知道每个包的实际长度；

- 发送端将每个数据包封装成固定长度（不够的补0），这样接收端每次从接收缓冲区读取固定长度的数据，就可以把每个数据包拆分开来；

- 或者在数据包之间设置边界，如添加特殊符号等，接收端就可以通过这个边界将不同的数据包拆分开。这种方式需要保证，选择开始符和结束符时需要确保每条数据的内部不包含开始符和结束符。

### 13、UDP

#### 13.1、UDP报文格式

<img src="总结面试题.assets/image-20210825223559839.png" alt="image-20210825223559839" style="zoom:50%;" />

​		**⽬标和源端⼝**：主要是告诉 UDP 协议应该把报⽂发给哪个进程。

​		**包⻓度**：该字段保存了 UDP ⾸部的⻓度跟数据的⻓度之和。

​		**校验和**：校验和是为了提供可靠的 UDP ⾸部和数据⽽设计。

#### 13.2、UDP使用connect

##### 1、UDP可以使用connect系统调用

​		UDP中的connect与TCP中的由本质的区别，TCP调用connect会引发三次握手，client与server建立连接。UDP是面向无连接的，调用connect是把对端IP和port记录下来；

#####  2、UDP可以多次调用connect，TCP只能调用一次

​		UDP多次调用connect主要是希望指定一个新的IP和port连接，以及断开以前的IP和port连接。指定新连接直接设施connect的第二个参数（sockaddr_in sin），断开连接，需要将connect中第二个参数中的sin_family设置成 AF_UNSPEC；

#####  3、UDP使用connect可以提高效率

​		LINUX系统有用户空间和内核空间之分，接收数据，数据从网卡上收上来，需要先交给系统内核，然后内核再交给上层应用程序（处于用户空间）。发送数据也是一样，数据需要从用户空间拷贝到内核，内核处理完之后，再交给网卡发出去。在用户态和内核态进行切换，非常耗时，对于高性能的服务器来说，其实应该减少这种耗时，但是如果切换无法避免，就尽量减少切换时拷贝的数据，那调用connect之后的UDP，内核相当于维护了一个“连接”，就可以调用send来发送数据了，那send对比于sendto其实参数少得多，那每次调用的时候就会少拷贝一些数据到内核空间。从另一个方面来讲，sendto的参数到内核空间以后，内核需要分配内存来存储这些参数值，当数据包发送出去之后，内核还需要释放掉这块内存，下次再调用sendto的时候，内核就需要再次分配内存存放这些临时的数据，就会形成一个不断地分配和释放临时内存的过程。那connect之后可以使用send，相当于维护了这个连接，所以后面每次进行发送数据，内核就不需要再分配删除内存了。

##### 4、UDP使用connect可以得到错误信息的提示

​		在使用connect编写UDP SOCKET的时候，会遇到连接错误的提示（ECONNREFUSED），可以本来UDP是无连接的，报连接错误其实是ICMP带来的。当一个UDP socket去connect对端是，并没有发送任何数据包，仅仅只是在内核建立了一个映射，该映射的作用是为了把UCP和ICMP（IP协议的补充，检测网络连接）通道捆绑在一起，调用了connect之后，内核协议栈就维护了一个从源目的地的单向连接，当下层有ICMP错误信息返回时，内核就可以根据这个映射找到是哪个UDP的socket发的包失败了，进而可以把得到该错误信息了，要是没有connect，是得不到该错误信息的。

#### 13.3、UDP使用bind

#### 13.4、为什么UDP不可靠？如何实现UDP可靠传输？

#### 13.5、



### 14、Socket编程

#### 14.1、针对TCP应该如何Socket编程？

#### 14.2、listen时候参数backlog意义？

Linux内核中会维护两个队列：

- 未完成连接队列（SYN 队列）：接收到⼀个 SYN 建⽴连接请求，处于 SYN_RCVD 状态；

- 已完成连接队列（Accpet 队列）：已完成 TCP 三次握⼿过程，处于 ESTABLISHED 状态；

现在通常认为**backlog** 是 **accept** 队列。

但是上限值是内核参数 **somaxconn** 的⼤⼩，也就说 **accpet** 队列⻓度 **= min(backlog, somaxconn)**。

#### 14.3、accept发生在三次握手那个阶段？

<img src="总结面试题.assets/image-20210826165945813.png" alt="image-20210826165945813" style="zoom:67%;" />

- 客户端的协议栈向服务器端发送了 SYN 包，并告诉服务器端当前发送序列号 client_isn，客户端进⼊SYN_SENT 状态；

- 服务器端的协议栈收到这个包之后，和客户端进⾏ ACK 应答，应答的值为 client_isn+1，表示对 SYN 包client_isn 的确认，同时服务器也发送⼀个 SYN 包，告诉客户端当前我的发送序列号为 server_isn，服务器端进⼊ SYN_RCVD 状态；
- 客户端协议栈收到 ACK 之后，使得应⽤程序从 connect 调⽤返回，表示客户端到服务器端的单向连接建⽴成功，客户端的状态为 ESTABLISHED，同时客户端协议栈也会对服务器端的 SYN 包进⾏应答，应答数据为server_isn+1；

- 应答包到达服务器端后，服务器端协议栈使得 accept 阻塞调⽤返回，这个时候服务器端到客户端的单向连接也建⽴成功，服务器端也进⼊ ESTABLISHED 状态。		

**==总结==客户端 connect 成功返回是在第⼆次握⼿，服务端 accept 成功返回是在三次握⼿成功之后。**

#### 14.4、客户端调用了close，连接时断开的流程是什么？

<img src="总结面试题.assets/image-20210826170250775.png" alt="image-20210826170250775" style="zoom:67%;" />

- 客户端调⽤ close ，表明客户端没有数据需要发送了，则此时会向服务端发送 FIN 报⽂，进⼊ FIN_WAIT_1状态；
- 服务端接收到了 FIN 报⽂，TCP 协议栈会为 FIN 包插⼊⼀个⽂件结束符 EOF 到接收缓冲区中，应⽤程序可以通过 read 调⽤来感知这个 FIN 包。这个 EOF 会被放在已排队等候的其他已接收的数据之后，这就意味着服务端需要处理这种异常情况，因为 EOF 表示在该连接上再⽆额外数据到达。此时，服务端进⼊CLOSE_WAIT 状态；
- 接着，当处理完数据后，⾃然就会读到 EOF ，于是也调⽤ close 关闭它的套接字，这会使得客户端会发出⼀个 FIN 包，之后处于 LAST_ACK 状态；
- 客户端接收到服务端的 FIN 包，并发送 ACK 确认包给服务端，此时客户端将进⼊ TIME_WAIT 状态；
- 服务端收到 ACK 确认包后，就进⼊了最后的 CLOSE 状态；客户端经过 2MSL 时间之后，也进⼊ CLOSE 状态；

#### 14.5、Socket的三种类型

- SOCK_STREAM (流式套接字) 提供可靠的、面向连接的通讯流。通过流式套接字发送了顺序的数据，数据到达时候的也是顺序的。数据流，一般是tcp/ip协议的编程；

- SOCK_DGRAM（数据报套接字）无连接的服务，数据通过相互独立的报文进行传输，是无序的，并且不保证可靠、无差错。数据包，是UDP协议的编程；

-  SOCK_RAW（原始套接字）：用于一些协议的开发，功能强大，可以读写内核没有处理的IP数据包，而流套接字只能读取TCP协议的数据，数据报套接字只能读取UDP协议的数据。

#### 14.6、Socket同步与异步

​     主要针对C端，数据访问的时候进程是否阻塞

##### 1、**同步：

​		同步就是在C端发出了一个功能调用时，没有得到结果之前，该调用就不返回。必须一件一件事情做，前一件做完了才开始下一件。

​		提交请求 -> 等待服务器处理 -> 处理完毕返回  ，在这个期间客户端不能干任何事

##### 2、**异步**

​		异步调用发出后，调用者不能立刻得到结果，那服务器通过状态、通知和回调来通知客户端。

​		请求通过事件触发 -> 服务器处理（客户端依然可以做其他事情） -> 处理完毕

#### 14.7、Socket阻塞和非阻塞

​        主要针对S端，应用程序的调用是否立即返回

#####  1、**阻塞**

​		阻塞是指调用结果返回之前，当前线程会被挂起（CPU不会分给线程时间片，线程暂停运行），函数只有在得到结果后才会返回。

##### 2、非阻塞

​		要是不能得到结果，不会阻塞当前线程，就立即返回。

​         忙轮询的方法，每隔一段时间查看是否有消息。

==默认设置的套接字是阻塞的，可以通过调用ioctlsocket()函数，将套接字设置为非阻塞==





### 15、C/S和B/S架构

#### 15.1、C/S架构（客户/服务）

​		一般是客户端进行用户界面/事物处理，服务器进行数据处理。一般是小范围里的网络环境，局域网之间通过专门服务器提供链接和数据交换服务。C/S一般面向相对固定并且相同区域，对信息安全的控制能力很强，一般高度机密的信息系统采用C/S结构适宜。C/S的客户端由于是本地程序，因此和本地硬件，程序的交互性很强，比如可以控制本机的其他程序，可以读写本地磁盘文件，可以与硬件交互。

#### 15.2、B/S架构（浏览器/服务）

​		Web兴起后的一种网络结构模式，Web浏览器是客户端最主要的应用软件。这种模式统一了客户端，将系统功能实现的核心部分集中到服务器上，简化了系统的开发、维护和使用。建立在广域网上，不是专门的网络硬件环境，一般有操作系统和浏览器就行。B/S建立在广域网之上，对安全的控制能力相对弱，可能面向不可知的用户。B/S建立在广域网上，面向不同的用户群，分在地域，这是C/S无法做到的，与操作系统平台关系最小，正因为如此B/S很难和本地硬件、程序、文件进行交互。

### 16、IP

#### 16.1、IP基本知识

##### 1、IP的作用

​		实现主机与主机之间的通信，也叫点对点通信。

##### 2、IP与MAC

​		IP主要作用是实现主机之间的通信，而MAC的作用是实现**直连**的两个设备之间的通信；IP负责**非直连**的两个网络之间的信息传输。网络在传输过程中源地址和目标地址不会变化，但是MAC的地址和目标MAC一直在变化。

#### 16.2、IP地址的基本知识

##### 1、IP地址的定义

IP地址（IPv4）由32位整数来表示。

##### 2、IP地址的分类

IP 地址分类成了 5 种类型，分别是 A 类、B 类、C 类、D 类、E 类。下图黄色部分为分类号，用以区分IP地址类别。

<img src="总结面试题.assets/image-20210830093236022.png" alt="image-20210830093236022" style="zoom:80%;" />

###### 1）如何计算ABC分类地址最大主机个数？

- 最大主机个数，就是看主机号的位数，比如C类，主机号是8位，即最大主机个数 = 2^8 - 2 = 254；

###### 2）为什么要减2？

- 因为在IP地址中有两个IP是特殊的，分别是主机号全为1和全为0地址。
  - 主机号全为 1 指定某个⽹络下的所有主机，⽤于⼴播
  - 主机号全为 0 指定某个⽹络

###### 3）广播地址用于什么？

- 广播地址用于在同一链路中相互连接的主机之间发送数据包。
- 广播地址有分为本地广播和直接广播
  - 本地广播：在本网络内的广播，主要是本地广播地址的IP包会被路由器屏蔽，因此不会到达其他连路上
  - 直接广播：在不同网络之间的广播，存在一定安全问题，多数情况下会在路由器上设置为不转发

###### 4）多播

- 多播⽤于将包发送给特定组内的所有主机。

###### 5）IP分类优缺点

- 优点

  - 分类地址简单明了，基于网络地址简单

- 缺点（由CIDR无分类IP地址解决缺点）

  - **同⼀⽹络下没有地址层次**，⽐如⼀个公司⾥⽤了 B 类地址，但是可能需要根据⽣产环境、测试环境、开发环境来划分地址层次，⽽这种 IP 分类是没有地址层次划分的功能，所以这就**缺少地址的灵活性**。

  - **不能很好的与现实⽹络匹配**，比如说C的主机只有254，B的主机有6万多

##### 3、无分类IP地址（CIDR）

###### 1）CIDR

- 无分类IP地址（CIDR）：也是由网络号 + 主机号，由**a.b.c.d/x** 表示，其中**/x** 表示**前x位属于网络号**（x : 0~32），使得IP地址更加灵活。
  - ⽐如 10.100.122.2/24，这种地址表示形式就是 CIDR，/24 表示前 24 位是⽹络号，剩余的 8 位是主机号。

###### 2)子网掩码

- 还有另⼀种划分⽹络号与主机号形式，那就是**⼦⽹掩码**，掩码的意思就是掩盖掉主机号，剩余的就是⽹络号。
  - 将⼦⽹掩码和 **IP** 地址按位计算 **AND**，就可得到⽹络号。

###### 3）子网划分

- 通过⼦⽹掩码划分出⽹络号和主机号，那实际上⼦⽹掩码还有⼀个作⽤，那就是划分⼦⽹。
  - ⼦⽹划分实际上是将主机地址分为两个部分：**⼦⽹⽹络地址和⼦⽹主机地址**。
    - 子网网络地址2位：00、01、10、11
    - 子网主机地址6位：000000~111111（2^6 - 1 = 63）

<img src="总结面试题.assets/image-20210830102007429.png" alt="image-20210830102007429" style="zoom:67%;" />

##### 4、公有IP地址和私有IP地址

###### 1）公有IP

- 公有 IP 地址是由 ICANN 组织管理，中⽂叫「互联⽹名称与数字地址分配机构」

###### 2）私有IP

- 私有 IP 地址通常是内部的 IT ⼈员管理

#### 16.3、IP地址与路由控制

- IP地址的**⽹络地址**这⼀部分是⽤于进⾏路由控制。

- 路由控制表中记录着⽹络地址与下⼀步应该发送⾄路由器的地址。在主机和路由器上都会有各⾃的路由器控制表。

- 在发送 IP 包时，⾸先要确定 IP 包⾸部中的⽬标地址，再从路由控制表中找到与该地址具有**相同⽹络地址**的记录，根据该记录将 IP 包转发给相应的下⼀个路由器。如果路由控制表中存在多条相同⽹络地址的记录，就选择相同位数最多的⽹络地址，也就是最⻓匹配。

#### 16.4、IP分片与重组

##### 1、既然IP层会分片，为什么TCP还需要MSS?

<img src="总结面试题.assets/image-20210826112400580.png" alt="image-20210826112400580" style="zoom:67%;" />

​		MTU ：⼀个⽹络包的最⼤⻓度，以太⽹中⼀般为 1500 字节；

​		MSS ：除去 IP 和 TCP 头部之后，⼀个⽹络包所能容纳的 TCP 数据的最⼤⻓度；

​		当 IP 层有⼀个超过 MTU ⼤⼩的数据（TCP 头部 + TCP 数据）要发送，那么 IP 层就要进⾏分⽚，把数据分⽚成若⼲⽚，保证每⼀个分⽚都⼩于 MTU。把⼀份 IP 数据报进⾏分⽚以后，由⽬标主机的 IP 层来进⾏重新组装后，再交给上⼀层 TCP 传输层。这看起来井然有序，但这存在隐患的，那么当如果⼀个 **IP** 分⽚丢失，整个 **IP** 报⽂的所有分⽚都得重传。

​		因为 IP 层本身没有超时重传机制，它由传输层的 TCP 来负责超时和重传。

​		当接收⽅发现 TCP 报⽂（头部 + 数据）的某⼀⽚丢失后，则不会响应 ACK 给对⽅，那么发送⽅的 TCP 在超时后，就会重发「整个 TCP 报⽂（头部 + 数据）」。因此，可以得知由 IP 层进⾏分⽚传输，是⾮常没有效率的。所以，为了达到最佳的传输效能 TCP 协议在建⽴连接的时候通常要协商双⽅的 **MSS** 值，当 TCP 层发现数据超过MSS 时，则就先会进⾏分⽚，当然由它形成的 IP 包的⻓度也就不会⼤于 MTU ，⾃然也就不⽤ IP 分⽚了。经过 TCP 层分⽚后，如果⼀个 TCP 分⽚丢失后，进⾏重发时也是以 **MSS** 为单位，⽽不⽤重传所有的分⽚，⼤⼤增加了重传的效率。

##### 2、**==总结==**：

- **IP按MTU分⽚，如果某⼀⽚丢失则需要所有分⽚都重传；**
- **IP没有重传机制，所以需要等TCP发送⽅超时才能重传；**

###### **问题⼀**：**MSS跟IP的MTU分⽚相⽐，只是多了⼀步协商MSS值的过程，⽽IP的MTU可以看作是默认协商好就是1500字节，所以为什么协商后的MSS可以做到丢失后只发丢失的这⼀⽚来提⾼效率，⽽默认协商好1500字节的IP分⽚就需要所有⽚都重传呢？**

- 如果⼀个⼤的 TCP 报⽂是被 **MTU 分⽚**，那么**只有「第⼀个分⽚」才具有 TCP 头部**，后⾯的分⽚则没有TCP 头部，接收⽅ IP 层只有重组了这些分⽚，才会认为是⼀个 TCP 报⽂，那么丢失了其中⼀个分⽚，接收⽅ IP 层就不会把 TCP 报⽂丢给 TCP 层，那么就会等待对⽅超时重传这⼀整个 TCP 报⽂。

- 如果⼀个⼤的 TCP 报⽂被 **MSS 分⽚**，那么**所有「分⽚都具有 TCP 头部」**，因为每个 MSS 分⽚的是具有TCP 头部的TCP报⽂，那么其中⼀个 MSS 分⽚丢失，就只需要重传这⼀个分⽚就可以。

###### **问题⼆**：**TCP MSS分⽚如果丢失了⼀⽚，是不是也需要发送⽅等待超时再重传？如果不是，MSS的协商如何能在超时前就直到丢了分⽚从⽽提⾼效率的呢？**

- TCP MSS分⽚如果丢失了⼀⽚，发送⽅没收到对⽅ACK应答，也是会触发超时重传的，因为TCP层是会保证数据的可靠交付。

#### 16.5、IPv4和IPv6

##### 1、IPv4

​	IPv4 的地址是 **32** 位的。

##### 2、IPv6

######  1）IPv6优缺点

​	IPv6的地址是 **128** 位的。

- 优点：
  - IPv6 可**自动配置**，即使没有 DHCP 服务器也可以实现⾃动分配IP地址，真是便捷到即插即⽤啊。
  - IPv6 包头包**⾸部**⻓度采⽤**固定**的值 **40** 字节，去掉了包头校验和，简化了⾸部结构，减轻了路由器负荷，⼤⼤**提⾼了传输的性能**。
  - IPv6 有应对伪造 IP 地址的网络安全功能以及防⽌线路窃听的功能，⼤⼤**提升了安全性**
  - ...
- 缺点

###### 2）Pv6地址结构

- 单播地址，1对1

  对于⼀对⼀通信的 IPv6 地址，主要划分了三类单播地址，每类地址的有效范围都不同。

  - 在同⼀链路单播通信，不经过路由器，可以使⽤**链路本地单播地址**，IPv4 没有此类型**（特有）**

  - 在内⽹⾥单播通信，可以使⽤**唯⼀本地地址**，相当于 IPv4 的私有 IP

  - 在互联⽹通信，可以使⽤**全局单播地址**，相当于 IPv4 的公有 IP

- 组播地址，1对多

- 任播地址，用于通信最近的节点，最近的节点是由路由协议决定

- 没有广播地址

##### 3、IPv4和IPv6区别

###### 1） IPv4 和 IPv6 不能相互兼容

###### 2）标识方法不同

- IPv4 地址⻓度共 **32 位（无符号整型）**，是以每 8 位作为⼀组，并⽤点分⼗进制的表示⽅式。

<img src="总结面试题.assets/image-20210830104537101.png" alt="image-20210830104537101" style="zoom:67%;" />

- IPv6 地址⻓度是 128 位，是以每 16 位作为⼀组，每组⽤冒号 「:」 隔开。

![image-20210830104342302](总结面试题.assets/image-20210830104342302.png)

​		**注：**如果出现连续的 0 时还可以将这些 0 省略，并⽤两个冒号 **「::」**隔开。但是，⼀个 IP 地址中只允许出现⼀次两个连续的冒号。

![image-20210830104426852](总结面试题.assets/image-20210830104426852.png)

###### 3）首部不同

<img src="总结面试题.assets/image-20210830110053078.png" alt="image-20210830110053078" style="zoom:80%;" />

IPv6 相⽐ IPv4 的⾸部改进：

- **取消了⾸部校验和字段**。 因为在数据链路层和传输层都会校验，因此 IPv6 直接取消了 IP 的校验。

- **取消了分片/重新组装相关字段**。 分⽚与重组是耗时的过程，IPv6 不允许在中间路由器进⾏分⽚与重组，这种操作只能在源与⽬标主机，这将⼤⼤提⾼了路由器转发的速度。

- **取消选项字段**。 选项字段不再是标准 IP ⾸部的⼀部分了，但它并没有消失，⽽是可能出现在 IPv6 ⾸部中的「下⼀个⾸部」指出的位置上。删除该选项字段使的 **IPv6 的⾸部成为固定长度的 40 字节**。



### 17、IP相关协议

#### 17.1、DNS域名解析

​		将主机域名转换为ip地址，属于**应用层**协议，使用UDP传输。

​		总结： 浏览器缓存，系统缓存，路由器缓存，IPS服务器缓存，根域名服务器缓存，顶级域名服务器缓存，主域名服务器缓存。

​		**浏览器⾸先看⼀下⾃⼰的缓存⾥有没有，如果没有就向操作系统的缓存要，还没有就检查本机域名解析⽂件hosts ，如果还是没有，就会 DNS 服务器进⾏查询**，查询过程如下：

- 主机向本地域名服务器的查询一般都是采用**递归**查询。

- 本地域名服务器向根域名服务器的查询的**迭代**查询。

  1）当用户输入域名时，浏览器**先检查自己的缓存**中是否这个域名映射的ip地址，有解析结束。

  2）若没命中，则检查操作系统缓存（如Windows的hosts）中有没有解析过的结果，有解析结束。

  3）若无命中，则请求**本地**域名服务器解析（ LDNS）。

  4）若LDNS没有命中就直接跳到根域名服务器请求解析。根域名服务器返回给LDNS一个主域名服务器地址。

  5） 此时LDNS再发送请求给上一步返回的gTLD（ 通用顶级域）， 接受请求的gTLD查找并返回这个域名对应的Name Server的地址

  6） Name Server根据映射关系表找到目标ip，返回给LDNS

  7） LDNS缓存这个域名和对应的ip， 把解析的结果返回给用户，用户根据TTL值缓存到本地系统缓存中，域名解析过程至此结束

#### 17.2、ARP协议

##### 1、ARP定义（IP -> MAC）

​		地址解析协议（Address Resolution Protocol），其基本功能为透过目标设备的IP地址，查询目标设备的MAC地址，以保证通信的顺利进行。

​		在传输⼀个 IP 数据报的时候，确定了源 IP 地址和⽬标 IP 地址后，就会通过主机「路由表」确定 IP 数据包下⼀跳。然而，⽹络层的下⼀层是数据链路层，所以我们还要知道「下⼀跳」的 MAC 地址。由于主机的路由表中可以找到下⼀跳的 IP 地址，所以可以通过 **ARP** 协议，求得下⼀跳的 MAC 地址。

##### 2、ARP工作流程：

ARP借助**ARP请求**和**ARP响应**两种类型的包确定MAC地址。

假设主机A和B在同一个网段，主机A要向主机B发送信息，具体的**地址解析**过程如下：

- 主机A首先**查看**自己的**ARP表**，确定其中是否包含有主机B对应的ARP表项。如果找到了对应的MAC地址，则主机A直接利用ARP表中的MAC地址，对IP数据包进行帧封装，并将数据包发送给主机B。

-  如果主机A在ARP表中找不到对应的MAC地址，则将缓存该数据报文，然后以**广播**方式发送一个**ARP请求报文**。ARP请求报文中的发送端IP地址和发送端MAC地址为主机A的IP地址和MAC地址，目标IP地址和目标MAC地址为主机B的IP地址和全0的MAC地址。由于ARP请求报文以广播方式发送，该网段上的所有主机都可以接收到该请求，但只有被请求的主机（即主机B）会对该请求进行处理。

- 主机B比较自己的IP地址和ARP请求报文中的目标IP地址，当两者相同时进行如下处理：将ARP请求报文中的发送端（即主机A）的IP地址和MAC地址存入自己的ARP表中。之后以单播方式发送**ARP响应报文**给主机A，其中包含了自己的MAC地址。

- 主机A收到ARP响应报文后，将主机B的MAC地址加入到自己的ARP表中以用于后续报文的转发，同时将IP数据包进行封装后发送出去。

##### 3、ARP报文格式：

![image-20210828201305257](总结面试题.assets/image-20210828201305257.png)

##### 4、ARP表：

​		设备通过ARP解析到目的MAC地址后，将会在自己的ARP表中增加IP地址到MAC地址的映射表项，以用于后续到同一目的地报文的转发。

###### 1）动态ARP表：

​		动态ARP表项由ARP协议通过ARP报文自动生成和维护，可以被老化，可以被新的ARP报文更新，可以被静态ARP表项覆盖。当到达老化时间、接口down时会删除相应的动态ARP表项

###### 2）静态ARP表：

​		静态ARP表项通过手工配置和维护，不会被老化，不会被动态ARP表项覆盖。
​		配置静态ARP表项可以增加通信的安全性。静态ARP表项可以限制和指定IP地址的设备通信时只使用指定的MAC地址，此时攻击报文无法修改此表项的IP地址和MAC地址的映射关系，从而保护了本设备和指定设备间的正常通信

##### 5、免费ARP

​		免费ARP指主机发送ARP查找自己的IP地址，通常发生在系统引导期间进行接口配置时。与标准ARP的区别就是免费ARP分组的目的IP地址字段封装的是自己的IP地址，即向所在网络请求自己的MAC地址。

​	免费ARP作用：

​		1）一个主机可以通过它来确定另一个主机是否设置了相同的 IP地址。

　　　正常情况下发送免费ARP请求不会收到ARP应答，如果收到了一个ARP应答，则说明网络中存在与本机相同的IP地址的主机，发生了地址冲突。

　　2）更新其他主机高速缓存中旧的硬件地址信息。

　　　如果发送免费ARP的主机正好改变了硬件地址，如更换了接口卡。

　　　其他主机接收到这个ARP请求的时候，发现自己的ARP高速缓存表中存在对应的IP地址，但是MAC地址不匹配，那么就需要利用接收的ARP请求来更新本地的ARP高速缓存表表项。

　　3）网关利用免费ARP防止ARP攻击

　　有些网关设备在一定的时间间隔内向网络主动发送免费ARP报文，让网络内的其他主机更新ARP表项中的网关MAC地址信息，以达到防止或缓解ARP攻击的效果。

　　4）利用免费ARP进行ARP攻击

　　ARP协议并不只在发送了ARP请求才接收ARP应答，计算机只要接收到ARP应答数据包，就会使用应答中的IP和MAC地址对本地的ARP缓存进行更新。

　　**主机可以构造虚假的免费ARP应答，将ARP的源MAC地址设为错误的MAC地址，并把这个虚假的免费ARP应答发送到网络中，那么所有接收到这个免费ARP应答的主机都会更新本地ARP表项中相应IP地址对应的MAC地址。更新成功后，这些主机的数据报文就会被转发到错误的MAC地址，从而实现了ARP欺骗的攻击**。

##### 6、ARP攻击（ARP欺骗）

​		ARP协议的基本功能就是通过目标设备的IP地址，查询目标设备的MAC地址，以保证通信的进行。 基于ARP协议的这一工作特性，黑客向对方计算机不断发送有欺诈性质的ARP数据包，数据包内包含有与当前设备重复的Mac地址，使对方在回应报文时，由于简单的地址重复错误而导致不能进行正常的网络通信。

**ARP攻击：**

- 攻击者可以仿冒用户、仿冒网关发送伪造的ARP报文，使网关或主机的ARP表项不正确，从而对网络进行攻击

-  攻击者通过向设备发送大量目标IP地址不能解析的IP报文，使得设备试图反复地对目标IP地址进行解析，导致CPU负荷过重及网络流量过大。

- 攻击者向设备发送大量ARP报文，对设备的CPU形成冲击。

因为这种攻击是利用ARP请求报文进行“欺骗”的，所以防火墙会误以为是正常的请求数据包，不予拦截。因此普通的防火墙很难抵挡这种攻击。

原文链接：https://blog.csdn.net/lm409/article/details/80299823

##### 7、如何解决ARP攻击



#### 17.3、RARP协议

RARP：通过MAC地址求IP地址



#### 17.4、DHCP

##### 1、概念

​		应用层协议，就是将客户主机IP设置为动态获取方式时，DHCP就会给客户端分配IP，使得客户机可以根据这个上网。

​		DHCP进程监听客户端---68端口号，服务端---67端口号。

##### 2、实现步骤

- clinet在局域网发起一个discover包，由于客户端没有 IP 地址，也不知道DHCP 服务器的地址，所以使⽤的是 **UDP ⼴播通信**来探索有没有能够给它提供IP的server；

- server接收到discover包之后，通过发送offer包给予client端应答，告诉client可以提供IP地址；

- client收到offer包之后，发送request包请求分配IP；

- server发送ACK，确认信息。



#### 17.5、NAT网络地址转换

​		提出了⼀种⽹络地址转换 **NAT** 的⽅法，再次缓解了 IPv4 地址耗尽的问题（IPv4 的地址是⾮常紧缺的，在前⾯我们也提到可以通过⽆分类地址来减缓 IPv4 地址耗尽的速度，但是互联⽹的⽤户增速是⾮常惊⼈的，所以 IPv4 地址依然有被耗尽的危险）。

​		简单的来说 NAT 就是同个公司、家庭、教室内的主机对外部通信时，把私有 IP 地址转换成公有 IP 地址。

​		但是，普通的NAT转换没有实际意义，因为大多数网络应用都是使用传输层协议TCP或UDP来传输数据，因此，需要将IP + Port 一起转换--**网络地址与端口转换NAPT**



#### 17.6、ICMP互联网控制报文协议

##### 1、ICMP简介

​		ICMP(Internet Control Message Protocol)：因特网控制报文协议

##### 2、ICMP功能

​		ICMP 主要的功能包括：确认 **IP** 包是否成功送达⽬标地址、报告发送过程中 **IP** 包被废弃的原因和改善⽹络设置等。

​		在 IP 通信中如果某个 IP 包因为某种原因未能达到⽬标地址，那么这个具体的原因将由 **ICMP** 负责通知。

###### 1）差错通知

​		差错通知是给送信者的错误通知，是到IP 数据包被对方的计算机处理的过程中，发生了什么错误时被使用。不仅传送发生了错误这个事实，也传送错误原因等消息。

###### 2）信息查询

​		信息查询是给送信者的信息查询。是在送信方的计算机向对方计算机询问信息时被使用。被询问内容的种类非常丰富，他们有目标IP 地址的机器是否存在这种基本确认，调查自己网络的子网掩码，取得对方机器的时间信息等。

##### 3、ICMP类型

<img src="总结面试题.assets/image-20210830114530260.png" alt="image-20210830114530260" style="zoom:67%;" />

###### 1）查询报文类型：回送消息，类型 **0** 和 **8**

​		回送消息⽤于进⾏通信的主机或路由器之间，判断所发送的数据包是否已经成功到达对端的⼀种消息， ping 命令就是利⽤这个消息实现的。可以向对端主机发送回送请求的消息（ ICMP Echo Request Message ，类型 8 ），也可以接收对端主机发回来的回送应答消息（ ICMP Echo Reply Message ，类型 0 ）。

###### 2）差错报文类型：

- **目标不可达**，类型 **3**

  - IP 路由器⽆法将 IP 数据包发送给⽬标地址时，会给发送端主机返回⼀个⽬标不可达的 ICMP 消息，并在这个消息中显示不可达的具体原因，原因记录在 ICMP 包头的代码字段。由此，根据 ICMP 不可达的具体消息，发送端主机也就可以了解此次发送不可达的具体原因

  - 常见的ICMP目标不可达代码号：
    - 网络不可达 **0**
    - 主机不可达 **1**
    - 协议不可达 **2**
    - 端口不可达 **3**
    - 需要分片但设置了不分片 **4**

- **原点抑制信息**，类型 **4**：

  - 为了缓和网络拥堵（在使⽤低速⼴域线路的情况下，连接 WAN 的路由器可能会遇到⽹络拥堵的问题）情况。
  - 当路由器向低速线路发送数据时，其**发送队列**的缓存变为零⽽⽆法发送出去时，可以向 IP 包的源地址发送⼀个ICMP 原点抑制消息

- **重定向消息**，类型 **5**

  - 如果路由器发现发送端主机使⽤了「不是最优」的路径发送数据，那么它会返回⼀个 ICMP 重定向消息给这个主机。

  - 在这个消息中包含了**最合适的路由信息和源数据**。这主要发⽣在路由器持有更好的路由信息的情况下。路由器会通

    过这样的 ICMP 消息告知发送端，让它下次发给另外⼀个路由器

- **超时消息**，类型 **11**

  - IP 包中有⼀个字段叫做 **TTL** （ Time To Live ，⽣存周期），它的值随着每经过⼀次路由器就会减 **1**，直到减到**0** 时该 **IP** 包会被丢弃。
  - 此时，路由器将会发送⼀个 ICMP 超时消息给发送端主机，并通知该包已被丢弃。
  - 设置 IP 包⽣存周期的主要⽬的，是为了在路由控制遇到问题发⽣循环状况时，避免 IP 包⽆休⽌地在⽹络上被转发。



#### 17.7、IGMP因特网组管理协议



### 18、Ping

#### 18.1、Ping作用

​		ping (Packet Internet Groper)，因特网包探索器，用于测试网络连接量的程序。Ping发送一个ICMP；回声请求消息给目的地并报告是否收到所希望的ICMP echo （ICMP回声应答）。它是用来检查网络是否通畅或者网络连接速度的命令。

​		ping命令通常用来作为网络可用性的检查。ping命令可以对一个网络地址发送测试数据包，看该网络地址是否有响应并统计响应时间，以此测试网络。

​		ping命令发送数据使用的是**ICMP**协议。

#### 18.2、Ping的原理：

​		举个栗子：同一子网下，两个主机：主机A和主机B，当主机A执行 **ping** 主机B后，会发生什么？

- ping 命令执⾏的时候，源主机⾸先会构建⼀个 **ICMP** 回送**请求**消息数据包
  - ICMP数据包包含多字段，最重要的两个：

    - 第⼀个是**类型**，对于回送请求消息⽽⾔该字段为 **8**
    - 第二个是**序号**，主要⽤于**区分**连续 ping 的时候发出的多个数据包

    每发出⼀个请求数据包，序号会⾃动加 1 。为了能够计算往返时间 RTT ，它会在报⽂的数据部分插⼊发送时间。

- 然后，由 ICMP 协议将这个数据包连同地址 192.168.1.2 ⼀起交给 IP 层。IP 层将以 192.168.1.2 作为⽬的地址，本机 IP 地址作为源地址，协议字段设置为 1 表示是 ICMP 协议，再加上⼀些其他控制信息，构建⼀个 IP 数据包。
- 接下来，需要**加⼊ MAC 头**。如果在本地 ARP 映射表中查找出 IP 地址 192.168.1.2 所对应的 MAC 地址，则可以直接使⽤；如果没有，则需要发送 ARP 协议查询 MAC 地址，获得 MAC 地址后，由数据链路层构建⼀个数据帧，⽬的地址是 IP 层传过来的 MAC 地址，源地址则是本机的 MAC 地址；还要附加上⼀些控制信息，依据以太⽹的介质访问规则，将它们传送出去。
- 主机 B 收到这个数据帧后，先检查它的⽬的 MAC 地址，并和本机的 MAC 地址对⽐，如符合，则接收，否则就丢弃。接收后检查该数据帧，将 IP 数据包从帧中提取出来，交给本机的 IP 层。同样，IP 层检查后，将有⽤的信息提取后交给 ICMP 协议。
- 主机 B 会构建⼀个 **ICMP** 回送响应消息数据包，回送**响应**数据包的类型字段为 0 ，序号为接收到的请求数据包中的序号，然后再发送出去给主机 A。
- 在规定的时候间内，源主机如果没有接到 ICMP 的应答包，则说明⽬标主机不可达；如果接收到了 ICMP 回送响应消息，则说明⽬标主机可达。此时，源主机会检查，⽤当前时刻减去该数据包最初从源主机上发出的时刻，就是 ICMP 数据包的时间延迟。

**==总结==** **ping 这个程序是使⽤了 ICMP ⾥⾯的 ECHO REQUEST（类型为 8 ） 和 ECHO REPLY（类型为 0）**



#### 18.3、TTL

##### 1、什么是域名TTL值？

​		TTL(Time-To-Live)，就是一条**域名解析记录在DNS服务器中的存留时间**。当各地的DNS服务器接受到解析请求时，就会向域名指定的NS服务器发出解析请求从而获得解析记录；在获得这个记录之后，记录会在DNS服务器中保存一段时间，这段时间内如果再接到这个域名的解析请求，DNS服务器将不再向NS服务器发出请求，而是直接返回刚才获得的记录；而这个记录在DNS服务器上保留的时间，就是TTL值。
​		原文链接：https://blog.csdn.net/u010098331/article/details/50855815

		域名DNS分两种，一种是权威域名服务器，域名注册商的服务器都为权威域名服务器，TTL值只能在权威服务器修改，还有一种域名解析服务器就是缓存DNS服务器，比如各地ISP上网设置的DNS服务器，它的作用主要是把域名解析结果缓存到本地，方便你查询。域名DNS的TTL值实际上就是各地的DNS缓存服务器多久去你的权威域名解析服务器（NS)获取一次你域名的解析IP。
##### 2、TTL值的应用

​		1）增大TTL值，以节约域名解析时间，给网站访问加速

​		一般情况下，域名的各种记录是极少更改的，很可能几个月、几年内都不会有什么变化。我们完全可以增大域名记录的TTL值让记录在各地DNS服务器中缓存的时间加长，这样在更长的一段时间内，我们访问这个网站时，本地ISP的DNS服务器就不需要向域名的NS服务器发出解析请求，而直接从缓存中返回域名解析记录。国内和国际上很多平台的TTL值都是以秒为单位的，很多的默认值都是3600，也就是默认缓存1小时，这个值实在有点小了，也就是说不可能一个小时更改一次域名记录。因此可以根据自己的需要，把这个值适当增大。

​		2）减小TTL值，以减少更换空间时的不可访问时间

​		更换空间99.9%会有DNS记录更改的问题，因为**缓存的问题**，新的域名记录在有的地方可能生效了，但在有的地方可能等上一两天甚至更久才生效。结果就是有的人可能访问到了新服务器，有的人访问到了旧服务器。仅仅是访问的话，这也不是什么大问题，但如果涉及到了邮件发送，这个就有点麻烦了，说不定哪封重要信件就被发送到了那已经停掉的旧服务器上。

​		3）返回结果PING命令，修改其TTL值来防护安全

​		在一般情况下我们通过ping对方让对方返回给您的TTL值大小，通常Windows系列的系统返回的TTL值在100-130之间，而UNIX/Linux系列的系统返回的TTL值在240-255之间，例如PING www.ieeye.com返回的TTL是240，对方的系统很可能是Linux，而另外一个目标的TTL是120，那么说明它使用的系统也许是Windows



#### 18.4、traceroute命令（路由跟踪）

​		traceroute —— 差错报⽂类型的使⽤（在Windows中对等的命令叫做 tracert ）。

##### 1、traceroute作用：

​		traceroute是用来检测发出数据包的主机到目标主机之间所经过的网关数量的工具。traceroute的原理是试图以最小的TTL（存活时间）发出探测包来跟踪数据包到达目标主机所经过的网关，然后监听一个来自网关ICMP的应答。发送数据包的大小默认为38个字节。

###### 1）故意设置特殊的 **TTL**，来追踪去往⽬的地时沿途经过的路由器

- traceroute 的参数指向某个⽬的 **IP** 地址：

  ```
  traceroute 192.168.1.100
  ```

###### 2）故意设置不分片，从⽽确定路径的 MTU

- 是为了路径**MTU**发现，因为大多数情况MTU是不可知的

  **工作原理**：

  - ⾸先在发送端主机发送 IP 数据报时，将 IP 包⾸部的分⽚禁⽌标志位设置为 **1**。根据这个标志位，途中的路由器不会对⼤数据包进⾏分⽚，⽽是将包丢弃。
  - 随后，通过⼀个 ICMP 的不可达消息将数据链路上 **MTU** 的值⼀起给发送主机，不可达消息的类型为「需要进⾏分⽚但设置了不分⽚位」。
  - 发送主机端每次收到 ICMP 差错报⽂时就减少包的⼤⼩，以此来定位⼀个合适的 MTU 值，以便能到达⽬标主机。

  **工作过程**：

  - 发送时IP首部的分片标志位设置为不分片。路由器丢包
  - 由ICMP通知下一次MTU的大小
  - 由于UDP中没有重发处理，应用在发送下一个消息时才会被分片。具体来说，就是值UDP传过来的UDP首部 + UDP数据在IP层被分片。对于IP，它并不区分UDP首部和应用的数据。
  - 所有分片达到目标主机后被重组，再传给接收主机的UDP层。

##### 2、traceroute原理：

​		程序利用增加存活时间（TTL）来实现其功能。每当数据包(3个数据包包括源地址，目的地址和包发出的时间标签)经过一个路由器，其存活时间就会减1。当其存活时间是0时，主机便取消数据包，并传送一个ICMP的TTL数据包给原数据包的发出者。

​		ICMP：Internet控制报文协议。它是TCP/IP协议族的一个子协议，用于在IP主机、路由器之间传递控制消息。控制消息是指网络通不通、主机是否可达、路由是否可用等网络本身的消息。这些控制消息虽然并不传输用户数据，但是对于用户数据的传递起着重要的作用。

##### 3、traceroute过程：

​		首先它发送一份TTL字段为1的IP数据包给目的主机，处理这个数据包的第一个路由器将TTL值减1，然后丢弃该数据报，并给源主机发送一个ICMP报文（“超时”信息，这个报文包含了路由器的IP地址，这样就得到了第一个路由器的地址），然后traceroute发送一个TTL为2的数据报来得到第二个路由器的IP地址，继续这个过程，直至这个数据报到达目的主机。

##### 4、命令参数

```
-d 使用Socket层级的排错功能。
-f 设置第一个检测数据包的存活数值TTL的大小。
-F 设置勿离断位。
-g 设置来源路由网关，最多可设置8个。
-i 使用指定的网络界面送出数据包。
-I 使用ICMP回应取代UDP资料信息。
-m 设置检测数据包的最大存活数值TTL的大小。
-n 直接使用IP地址而非主机名称。
-p 设置UDP传输协议的通信端口。
-r 忽略普通的Routing Table，直接将数据包送到远端主机上。
-s 设置本地主机送出数据包的IP地址。
-t 设置检测数据包的TOS数值。
-v 详细显示指令的执行过程。
-w 设置等待远端主机回报的时间。
-x 开启或关闭数据包的正确性检验。
```

##### 问题一：程序如何判断是否已经达到目的主机？

- 在Linux下，traceroute程序发送一个UDP数据报给目的主机，但是它选择一个**不可能**的值作为**UDP端口号**(大于30000)，使目的主机的任何一个应用程序都不可能使用该端口，因此该数据报到达目的主机时，目的主机会产生一个“**端口不可达**”错误的ICMP报文，这样traceroute程序要做的就是区分接收到的ICMP报文是超时还是端口不可达，从而来区分是路由器还是目的主机。
  

## 五、Linux网络编程

### 1、高性能服务器框架程序框架

#### 	1、服务器模型

​	1.1、C/S（客户端／服务器）模型：所有客户端都通过访问服务器来获取所需的资源，模型如下：



![image-20220415092025603](F:/%E6%88%91%E7%9A%84%E6%96%87%E4%BB%B6_%E5%BC%A0%E5%85%B5/%E6%89%BE%E5%B7%A5%E4%BD%9C/%E5%9B%BE%E7%89%87/image-20220415092025603.png)

C/S模型的逻辑很简单。 服务器启动后， 首先创建一个（或多个）监听socket, 并调用bind函数将其绑定到服务器感兴趣的端口上， 然后调用listen函数等待客户连接。 服务器稳定运行之后， 客户端就可以湖用connect函数向服务器发起连接了。 由 千客户连接诗求是随机到达的异步事件， 服务器需要使用某种1/0模观来监听这一事件．**当监听到连 接请求后， 服务器就调用accept函数接受它， 并分配一个逻辑单元为新的连接服务。 逻辑单 元可以是新创建的子进程、 子线程或者其他．**然后逻辑单元读取客户需求，处理该请求，然后将处理结果返回给客户端。

1.2、P2P模型：使得每台机器在消耗服务的同时也给别人提供服务，这样资源能够充分、自由 地共享。云计算机群可以用作P2P模型的一个典范。P2P模型存在的显著的问题就是主机之间很难互相发现。所以实际使用的P2P模型通常带有一个专门的发现服务器。该发现服务器还提供查找服务，使得每个客户都能尽快找到自己需要的资源。从编程角度来讲， P2P换型可以毛作C/S模我的扩展：每台主机既是客户端， 又是服务 器。如图：

![image-20220415094010417](F:/%E6%88%91%E7%9A%84%E6%96%87%E4%BB%B6_%E5%BC%A0%E5%85%B5/%E6%89%BE%E5%B7%A5%E4%BD%9C/%E5%9B%BE%E7%89%87/image-20220415094010417.png)

#### 2、服务器编程框架

服务器的基本框架都一样，不同之处在于逻辑处理，服务器基本框架如图：

![image-20220415094541640](F:/%E6%88%91%E7%9A%84%E6%96%87%E4%BB%B6_%E5%BC%A0%E5%85%B5/%E6%89%BE%E5%B7%A5%E4%BD%9C/%E5%9B%BE%E7%89%87/image-20220415094541640.png)

**I/O处理单元**：是服务器管理客户连接的模块。 它通常要完成以下工作： 等待并接受新的 客户连接， 接收客户数据， 将服务器响应数据返回给客户端。 但是，   数据的收发不一定在I/O处理单元中执行， 也可能在逻辑单元中执行， 具体在何处执行取决于事件处理模式

**逻辑单元**：一个逻辑单元通常是一个进程或线程 。 它分析并处理客户数据， 然后将结果传递给IO处理单元或者直接发送给客户端（具体使用哪种方式取决于事件处理模式）

**网络存储单元：**网络存储单元可以是数据库、 缓存和文件， 甚至是一台独立的服务器。 但它不是必须的， 比如ssh、 telnet等登录服务就不需要这个单元。

#### 3、IO模型

阻塞IO：针对阻塞IO执行的系统调用可能因为无法立即完成而被操作系统挂起， 直到等待的事件发生为止。socket 的基础API中． 可能被阻塞的系统调用包括accept、 send、 recv和connect .

非阻塞IO：针对非阻塞I/0执行的系统调用则总是立即返回， 而不管事件是否已经发生。 如果事件没有立即发生， 这些系统调用就返回－I, 和出错的情况一样。 此时我们必须根据erron来区 分这两种情况。可能被非阻塞的系统调用包括accept、 send、 recv和connect .

IO通知机制：比如IO复用和SIGIO信号．IO复用是最常使用的IO通知机制。它指的是，应用程序通过 IO复用函数向内核注册一组事件，内核通过IO复用函数把其中就绪的事件通知给应用程序。Linux上常用的IO复用函数是select、poll和epoll_wait。**IO复用 函数本身是阻塞的，它们能提高程序效率的原因在于它们具有同时监听多个IO事件的能力**

#### 4、两种高效的事件处理模式

**Reactor模式**：它要求主线程(IO处理单元，下同）只负责监听文件描述上 是否有事件发生，有的话就立即将该事件通知工作线程（逻辑单元，下同）。除此之外，主线程不做任何其他实质性的工作。读写数据，接受新的连接，以及处理客户请求均在工作线程中完成。

使用**同步I/O模型**（以epoll_wait为例）实现的Reactor模式的工作流程是：

1)主线程往epoll内核事件表中注册socket上的读就绪事件（连接成功）

2）主线程调用epoll_wait等待socket上有数据可读。

3）当socket上有数据可读时，epoll_wait通知主线程。主线程则将socket可读事件放入请求队列

4）睡眠在请求队列上的某个工作线程被唤醒，它从socket读取数据，并处理客户请求， 然后往epoll内核事件表中注册该socket上的写就绪事件。

5）主线程调用epoll_wait等待socket可写．

6）当socket可写时，epoll_wait通知主线程。主线程将socket可写事件放入请求队列．

7）睡眠在诸求队列上的某个工作线程被唤醒，它往socket上写人服务器处理客户诸求的结果

![image-20220415111522837](F:/%E6%88%91%E7%9A%84%E6%96%87%E4%BB%B6_%E5%BC%A0%E5%85%B5/%E6%89%BE%E5%B7%A5%E4%BD%9C/%E5%9B%BE%E7%89%87/image-20220415111522837.png)

**Proactor模式：**与Reactor模式不同，Proactor模式将所有IO操作都交给主线程和内核来处理，工作线程仅仅负责业务逻辑

使用异步IO模型（以aio_rcad和aio_writc为例）实现的Proactor模式的工作流程是：

1)主线程调用aio_read函数向内核注册socket上的读完成事件， 并告诉内核用户读缓冲区的位置， 以及读操作完成时如何通知应用程序

2）主线程继续处理其他逻辑．

3）当socket上的数据被读入用户缓冲区后， 内核将向应用程序发送一个倌号， 以通知应用程序数据已经可用．

4）应用程序预先定义好的信号处理函数选择一个工作线程来处理客户请求 。 工作线程 处理完客户请求之后， 调用aio_write函数向内核注册socket上的写完成事件， 并告诉内核用 户写缓冲区的位堂， 以及写操作完成时如何通知应用程序

5）主线程继续处理其他逻辑．

6）当用户缓冲区的数据被写人socket之后， 内核将向应用程序发送一个信号， 以通知应用程 序数据已经发送完毕．

7）应用程序预先定义好的倌号处理函数选择一个工作线程来做善后处理， 比如决定是 否关闭socket。



![image-20220415112606780](F:/%E6%88%91%E7%9A%84%E6%96%87%E4%BB%B6_%E5%BC%A0%E5%85%B5/%E6%89%BE%E5%B7%A5%E4%BD%9C/%E5%9B%BE%E7%89%87/image-20220415112606780.png)

#### 5、两种高效的并发模式

##### 1、半同步半异步模式

并发模式中，同步指程序完全按照代码序列的顺序执行，异步指程序的执行需要系统事件来驱动。常见的系统事件有中断、信号。按照同步方式运行的线程称为同步线程，按照异步方式运行的线程称为异步线程．显然，异步线程的执行效率高，实时性强，这是很多嵌入式程序采用的模型。但编写以异步方 式执行的程序相对复杂，难以调试和扩展，而且不适合于大量的并发。而同步线程则相反， 它虽然效率相对较低，实时性较差，但逻辑简单。因此，对于像服务器这种既要求较好的实时性，又要求能同时处理多个客户诘求的应用程序，我们就应该同时使用同步线程和异步线程来实现，即采用半同步／半异步模式来实现。

​		半同步／半异步模式中，同步线程用于处理客户逻辑，异 步线程用于处理IO事件，异步线程监听到客户请求后， 就将其封装成请求对象并插人请求队列中。请求队列将通知某个工作在同步模式式的工作线程来读取并处理该请求对象。

​		

​        如果结合考虑两种事件处理模式和几种IO模型， 则半同步／半异步模式就存在多种变体。 其中有一种变体称为半同步／半反应堆 (half-sync/haIf-reactive) 模式：

1、异步线程只有一个，由主线程来充当，它负责监听所有 socket 上的事件。

2、所有工作线程都睡眠在请求队列上， 当有任务到来时， 它们将通过竞争（比 如申诸互斥锁）获得任务的接管权。 这种竞争机制使得只有空闲的工作线程才有机会来处理新任务， 

半同步／半反应堆模式存在如下缺点：
1、主线程和工作线程共享请求队列．主线程往请求队列中添加任务，或者工作线程从请求队列中取出任务，都需要对请求队列加锁保护，从而白白耗费CPU时间。
2、每个工作线程在同一时间只能处理一个客户诸求。如果客户数证较多，而工作线程较少，则请求队列中将堆积很多任务对象，客户端的响应速度将越来越慢。如果通过增加工作线程来解决这一问题，则工作线程的切换也将耗费大量CPU时间。

##### 2、领导者/追随者模式

领导者／追随者模式是多个工作线程轮流获得事件源集合，轮流监听分发并处理事件。

#### 6、有限状态机

逻辑单元内部一种高效的编程方法：有限状态机。

#### 7、高性能服务器需要注意的其他几个方面：池、数据复制、上下文切换和锁。

 池：提高服务器性能的一个很直接的方法就是以空间换时间， 即 “ 浪费 ” 服务器的硬件资源， 以换取其运行效率。 这就是池(pool)的概念。 池 是一组资源的集合， 这组资源在服务器启动之初就被完全创建好并初始化， 这称为静态资源分配。 当服务器进人正式运行阶段， 即开始处理客户请求的时候， 如果它需要相关的资源， 就可以直接从池中获取， 无须动态分配。**直接从池中取得所需资源比动态分配资源的速度要快得多， 因为分配系统资源的系统词用都是很耗时的。当服务器处理完一个客户连接后， 可以把相关的资源放回池中， 无须执行系统调用来释放资源。**从最终的效果来君， 池相当千服务器管理系统资源的应用层设施， 它避免了服务器对内核的频繁访问。

数据复制：高性能服务器应该避免不必要的数据复制，尤其是当数据复制发生在用户代码和内核之间的时候。此外，用户代码内部（不访问内核）的数据复制也是应该避免的

上下文切换：并发程序必须考虑上下文切换(contextswitch)的问题，即进程切换或线程切换导致的的系统开销。即使是IO密集型的服务器，也不应该使用过多的工作线程（或工作进程，下同），否则线程间的切换将占用大量的CPU时间。

锁：并发程序需要考虑的另外一个问题是共享资源的加锁保护。锁通常被认为是导致服务器 效率低下的一个因素，因为由它引入的代码不仅不处理任何业务逻辑，而且需要访问内核资源。因此，服务器如果有更好的解决方案，就应该避免使用锁。

### 2、IO复用

#### 1、select系统调用

#### 2、epoll

epoll是Linux特有的l/0复用函数。它在实现和使用上与select、poll有很大差异。首 先，epoll使用一组函数来完成任务，而不是单个函数。其次，epoll把用户关心的文件描述符上的事件件放在内核里的一个事件表中，从而无须像select和poll那样每次调用都要重复传入文件描述符集或事件集。但epoll需要使用一个额外的文件描述符，来唯一标识内核中的这个事件表。这个文件描述符使用如下epoll_create函数来创建。

具体见项目中的webserver项目介绍。

### 3、多线程编程

#### 1、创建线程和结束线程

```c++
int pthread_create(pthread_t * thread,const pthread_attr_t* attr,void* (*start_routine)(void* ),void * arg);
```

thread参数是新线程的标识符，后续pthread_＊函数通过它来引用新线程.

attr参数用千设罢新线程的展性。给它传递NULL表示使用默认线程属性。

start_routine和arg参数分别指定新线程将运行的函数及其参数．

pthread _ create成功时返回0,失败时返回错误码。

**线程一旦被创建好，内核就可以调度内核线程来执行start_routine函数指针所指向的函数**

```c++
void pthreacl_exit(void* retval);
```

pthread_ exit函数通过retval参数向线程的回收者传递其退出信息。它执行完之后不会返 回到调用者，而且永远不会失败。

#### 2、线程同步的方式：信号量、互斥锁、条件变量

##### 信号量：

在Linux上，信号量API有两组。一组是System V IPC信号量，另外一组是POSIX信号量.POSIX信号量函数的名字都以sem_开头，并不像大多数线程函数 那样以pthread_开头。常用的POSIX信号量函数是下面5个:

```c++
#include＜semaphore.h＞
int sem_init(sem_t*sem,int pshared,unsigned int value);//value为信号量的初始值，初始值为0一般用作线程同步，初始值为1则为互斥信号量
int sem_destroy(sem_t*sem);//用于销毁信号量，以释放其占用的内核资源。
int sem_wait(sem_t*sem);//以原子操作的方式将信号量的值减1。如果信号量的值为0，则sem_wait将被阻塞，直到这个信号量具有非0值。
int sem_trywait(sem_t*sem);//与sem_wait函数相似，不过它始终立即返回，而不论被操作的信号量是否具有非0值，相当于sem_wait的非阻塞版本
int sem_post(sem_t*sem);//以原子操作的方式将信号量的值加1。当信号量的值大于0时，其他正在调用sem_wait等待信号量的线程将被唤醒

```

##### 互斥锁：

POSIX互斥锁的相关函数主要有如下5个：

```c++
#include＜pthread.h＞
//这些函数的第一个参数mutex指向要操作的目标互斥锁，互斥锁的类型是pthread_mutex_t结构体。
int pthread_mutex_init(pthread_mutex_t*mutex,const pthread_mutexattr_t*mutexattr);//用于初始化互斥锁。mutexattr参数指定互斥锁的属性。如果将它设																					置为NULL，则表示使用默认属性
int pthread_mutex_destroy(pthread_mutex_t*mutex);//用于初始化互斥锁。mutexattr参数指定互斥锁的属性。如果将它设置为NULL，则表示使用默认属性
int pthread_mutex_lock(pthread_mutex_t*mutex);//以原子操作的方式给一个互斥锁加锁。如果目标互斥锁已经被锁上，则pthread_mutex_lock调用将阻塞，直到该											互斥锁的占有者将其解锁。
int pthread_mutex_trylock(pthread_mutex_t*mutex);//它始终立即返回，而不论被操作的互斥锁是否已经被加锁，相当于pthread_mutex_lock的非阻塞版本。
int pthread_mutex_unlock(pthread_mutex_t*mutex);//以原子操作的方式给一个互斥锁解锁.如果此时有其他线程正在等待这个互斥锁，则这些线程中的某一个将获得它。

```

##### 条件变量：

互斥锁是用于同步线程对共享数据的访问的话，那么条件 变量则是用于在线程之间同步共享数据的值。条件变量提供了一种线 程间的通知机制：当某个共享数据达到某个值的时候，唤醒等待这个 共享数据的线程。条件变量的相关函数主要有如下5个：

```c++
#include＜pthread.h＞
//这些函数的第一个参数cond指向要操作的目标条件变量，条件变量的类型是pthread_cond_t结构体。
int pthread_cond_init(pthread_cond_t*cond,const pthread_condattr_t*cond_attr);//函数用于初始化条件变量。cond_attr参数指定条																						件变量的属性。如果将它设置为NULL，则表示使用默认属性
int pthread_cond_destroy(pthread_cond_t*cond);//用于销毁条件变量
int pthread_cond_broadcast(pthread_cond_t*cond);//数以广播的方式唤醒所有等待目标条件变量的线程
int pthread_cond_signal(pthread_cond_t*cond);
int pthread_cond_wait(pthread_cond_t*cond,pthread_mutex_t*mutex);//用于等待目标条件变量

```



## 六、leetcode算法

#### 1、排序算法

##### 1.1、快速排序

```c++
//快速排序
void quickSort(vector<int>&nums,int first,int end){//快读排序
        int left=first;
        int right=end;
        //结束标志
        if(first>=end)return;
        int i = rand() % (right- left + 1) + left; //生成随机数
        swap(nums[i],nums[left]);
        int key=nums[first];//比较的值，随机的那个
        while(first<end){
            //从后往前走
            while(first<end&&nums[end]>=key)//一定要有等于号
                end--;
            nums[first]=nums[end];//将较小的值换到比较值的位置
            //从前往后走
            while(first<end&&nums[first]<=key)
                first++;
            nums[end]=nums[first];//将较大值换到了后面,end位置现在是空闲可以放较大值   
        }
        nums[first]=key;
        quickSort(nums,left,first-1);//前半部分递归
        quickSort(nums,first+1,right);//后半部分递归
    }
```

##### 1.2、归并排序

```c++
//归并排序
vector<int> sortArray(vector<int>& nums){
        int len=nums.size();
        vector<int>tmp(len,0);
        mergeSort(nums,tmp,0,len-1);
        return nums;
    }
    void  mergeSort(vector<int>&nums,vector<int>&tmp,int low,int high){
        if(low>=high)return;
        int mid=(high+low)/2;
        int start1=low,end1=mid;
        int start2=mid+1,end2=high;
        //递归左子数组
        mergeSort(nums,tmp,start1,end1);
        //递归右子数组
        mergeSort(nums,tmp,start2,end2);
        //两两归并子数组
        int index=low;
        
        //分别比较两数组的首元素大小，知道一个数组全部比完
        while(start1<=end1&&start2<=end2){
            tmp[index++]=nums[start1]<nums[start2]?nums[start1++]:nums[start2++];
        }
        //若第一个数组没有比完，则直接将该数组后续部分全部拼接到tmp中
        while(start1<=end1){
            tmp[index++]=nums[start1++];
        }
        //若第一个数组没有比完，则直接将该数组后续部分全部拼接到tmp中
        while(start2<=end2){
         tmp[index++]=nums[start2++];
        }
        //比完之后要将排好序的数组填入之前的数组，一边更大的两个有序数组进行比较
        for(int i=low;i<=high;i++){
            nums[i]=tmp[i];
        }
    }

```

##### 1.3、堆排序

```c++
 //堆排序，top k问题一般都用堆排序，比其他排序算法要快
    //大顶堆：是一个完全二叉树，每个节点的值大于或等于其左右孩子节点的值
    //小顶堆：是一个完全二叉树，每个节点的值小于或者等于左右孩子节点的值
    void heapify_sort(vector<int>&nums,int n){
        //建立大根堆，从树的最后一个非叶子节点开始，
        //对每个结点进行heapify操作，然后向上走
        int tmp=(n-2)/2;//完全二叉树的最后一个非叶子节点为n-2/2，序号从0开始，n为节点个数
        for(int i=tmp;i>=0;i--){//向上构建大顶堆
            heapify(nums,n,i);
        }
        //建立大根堆之后，每次交换最后一个结点和根节点
        for(int i=0;i<n;i++){
            swap(nums.front(),nums[n-i-1]);
            heapify(nums,n-i-1,0);//交换之后，节点数量减少1个，并且继续构建大顶堆,交换了顶节点，所以从顶节点开始构建大顶堆
        }
    }
    void heapify(vector<int>&nums,int n,int i){//向下更新大顶堆
        int l=2*i+1,r=2*i+2;//l为i的左孩子，r为i的右孩子
        int max=i;
        //若左孩子存在
        if(l<n&&nums[l]>nums[max])max=l;
        //若右孩子存在
        if(r<n&&nums[r]>nums[max])max=r;
        //若最大值不是该节点
        if(max!=i){
            swap(nums[i],nums[max]);
            heapify(nums,n,max);
        }
    }
```

##### 1.4、计数排序

```c++
//计数排序
//找取数组中最大元素和最小元素作为重新分配的区间
int getMaxValue(vector<int>& num) {
	int maxValue = 0;
	for (auto& i : num) {
		if (i > maxValue) {
			maxValue = i;
		}
	}
	return maxValue;
}

int getMinValue(vector<int>& num) {
	int minValue = 0;
	for (auto& i : num) {
		if (i < minValue) {
			minValue = i;
		}
	}
	return minValue;
}

//方法1：直接根据原数组的最大值确定新数组空间大小
vector<int> countSort1(vector<int>& num) {
	int maxValue = getMaxValue(num);
	//计数数组
	vector<int>count(maxValue,0);
	//遍历原数组，统计出现次数
	for (auto& i : num) {
		count[num[i]]++;
	}
	
	//根据整数出现的次数排序
	int index = 0;//索引位置
	for (int i = 0; i < count.size(); ++i) {
		while (count[i]--) {
			num[index++] = i;
		}
	}
	return num;
}

//方法2：节约内存空间
vector<int> countSort2(vector<int>& num) {
	int maxValue = getMaxValue(num);
	int minValue = getMinValue(num);

	//创建一个用于计数的数组
	vector<int> counts((maxValue - minValue + 1), 0);
	for (int i = 0; i < num.size(); ++i) {
		counts[num[i] - minValue]++;
	}

	//
	for (int i = 1; i < counts.size(); ++i) {
		counts[i] += counts[i - 1];
	}

	//创建一个用于排好序的数组
	vector<int> out(num.size(), 0);
	for (int i = counts.size() - 1; i >= 0; --i) {
		out[--counts[num[i] - minValue]] = num[i];
	}

	//将排序好的数组复制到原数组
	for (int i = 0; i < num.size(); ++i) {
		num[i] = out[i];
	}
}
```



## 七、智力题

### 7.1、相机辨圆盘方向

一个圆盘被涂上了黑白二色，两种颜色各占一个半圆。圆盘以一个未知的速度、按一个未知的方向旋转。你有一种特殊的相机可以让你即时观察到圆上的一个点的颜色。你需要多少个相机才能确定圆盘旋转的方向？

解答 ：你可以把两个相机放在圆盘上相近的两点，然后观察哪个点先变色。事实上，只需要一个相机就够了。控制相机绕圆盘中心顺时针移动，观察颜色多久变一次；然后让相机以相同的速度逆时针绕着圆盘中心移动，再次观察变色的频率。可以断定，变色频率较慢的那一次，相机的转动方向是和圆盘相同的。

### 7.2、用香确定15分钟

有两根不均匀分布的香，香烧完的时间是一个小时，你能用什么方法来确定一段15分钟的时间

解答：先点燃一根香的一端，同时点燃另一根香的两端，当两端点燃的香燃尽时，便是半小时的时间；在两端点燃的香燃尽时，点燃剩下那根香的另外一端，这样，从剩下那根香的另一端开始点燃，到最终燃尽，便是15分钟的时间。

### 7.3、一个3L和5L的水杯，水无限，需要得到4L的水

### 7.4、8个球，有个球略重，一个天平，需要多少次可以找出来那个重的

### 7.5、赛马问题



## 八、Linux指令

#### 1、磁盘相关指令：

df：用于显示Linux系统中各文件系统的硬盘使用情况，包括文件系统所在硬盘分区的总容量、已使用的容量、剩余容量等

```
df [选项] 目录或文件
1 -a：显示所有文件系统信息，包括系统特有的/proc、/sysfs等文件系统。
2 -k：以KB为单位显示容量，默认。
3 -m：以MB为单位显示容量。
4 -h：使用人们习惯的KB、MB或GB等单位自行显示容量。
5 -H：以M=1000K取代M=1024K的进位方式显示容量。
6 -T：显示该分区的文件系统名称（例如xfs）。
7 -i：不用硬盘容量显示，而是以含有inode的数量来显示。
```

du：统计目录或文件所占磁盘空间大小的命令

```
1 -a：显示每个子文件的磁盘占用量。默认只统计子目录的磁盘占用量。
2 -h：使用习惯单位显示磁盘占用量，如KB、MB或GB等。
3 -s：统计总磁盘占用量，而不列出子目录和子文件的磁盘占量。
```

#### 2、挂载命令

mount：挂载命令是用来将硬件设备的文件系统和Linux系统中的文件系统，通过指定目录（作为挂载点）进行关联

umount：用于卸载已经挂载的硬件设备

#### 3、free命令

free： free指令会显示内存的使用情况，包括实体内存，虚拟的交换文件内存，共享内存区段，以及系统核心使用的缓冲区等。

#### 4、top命令

top命令是Linux下常用的**性能分析工具**，能够**实时显示**系统中各个**进程**的**资源占用状况**，类似于Windows的任务管理器。

#### 5、ps命令

Linux中的ps命令是Process Status的缩写。ps命令用来列出系统中当前运行的那些进程。ps命令列出的是当前那些进程的快照，就是执行ps命令的那个时刻的那些进程，如果想要动态的显示进程信息，就可以使用top命令。使用ps命令可以确定有哪些进程正在运行和运行的状态、进程是否结束、进程有没有僵死、哪些进程占用了过多的资源等等，总之大部分信息都是可以通过执行该命令得到的。

#### 6、统计文件有多少行

```
wc [-clw][--help][--version][filename...]
```

- -c或--bytes或--chars 只显示Bytes数。
- -l或--lines 显示行数。
- -w或--words 只显示字数。
- --help 在线帮助。
- --version 显示版本信息

#### 7、ln命令

ln命令是建立链接，ln的链接有[软链接](https://baike.baidu.com/item/软链接)和[硬链接](https://baike.baidu.com/item/硬链接)两种，软链接就是ln –s ** **，它只会在你选定的位置上生成一个文件的[镜像](https://baike.baidu.com/item/镜像)，不会占用磁盘空间，硬链接ln ** **，没有参数-s，

#### 8、cat命令

cat 命令将文件内容显示到屏幕上。Cat 命令将标准输入连接到标准输出。

#### 9、rm、cp、mv命令的底层实现

**rm命令是删除数据的工具，在rm命令执行过程中；数据链接数递减，从而释放inode号,并且inode号可以被重用，把数据块放在空闲列表中，删除目录项，数据实际上不会马上被删除，但当另一个文件使用数据块时将被会被覆盖。**

 **cp命令是用来拷贝数据，在cp命令执行过程中：分配一个空闲的inode号，在inode表中生成新条目，在目录中创建一个目录项，将名称与inode编号关联，拷贝数据生成新的文件。**(目录项是目录文件下的哈希表中记录该目录下的一个文件)

mv命令：

​		**第一种是mv命令的目标和源在相同的文件系统，可以理解为同一分区，mv命令在执行过程中用新的文件名创建对应新的目录项，删除旧目录条目对应的旧的文件名，并不影响inode表（除时间戳）或磁盘上的数据位置，也就是说没有数据被移动。**

 	**第二种如果目标和源不在一个文件系统，也就是不在一个分区，那么 mv就相当于cp和rm。即改变了inode表的条目，也发生了数据移动。**

## 九、面经算法

1、算法：一个碟子上有很多层乱序排列大小不一的蛋糕，只用一只手从顶端去拿任意块的蛋糕，并且能把蛋糕翻转过来再放进去，只能把拿出来的整体颠倒，使排序后的蛋糕成金字塔型（每次从头翻转数组的一部分排序数组

2、给定a、b两个文件，各存放50亿个url，每个url各占用64字节，内存限制是4G，如何找出a、b文件共同的url？

利用分而治之、哈希或布隆过滤器之类的知识点。遍历文件a，对每个url求取hash(url)%1000，然后根据所得值将url分别存储到1000个小文件（设为a0,a1,...a999）当中。这样每个小文件的大小约为300M。遍历文件b，采取和a相同的方法将url分别存储到1000个小文件(b0,b1....b999)中。这样处理后，所有可能相同的url都在对应的小文件(a0 vs b0, a1 vs b1....a999 vs b999)当中，不对应的小文件（比如a0 vs b99）不可能有相同的url。然后我们只要求出1000对小文件中相同的url即可。 比如对于a0 vs b0，我们可以遍历a0，将其中的url存储到hash_map当中。然后遍历b0，如果url在hash_map中，则说明此url在a和b中同时存在，保存到文件中即可。 如果分成的小文件不均匀，导致有些小文件太大（比如大于2G），可以考虑将这些太大的小文件再按类似的方法分成小小文件即可

### 3、会议室leetcode 253

​	这类问题是区间调度问题。**对于区间问题的处理，一般来说第一步都是排序**，相当于预处理降低后续的操作难度。

```c++
int meeting(vector<vector<int>> &num)
{
    int n = num.size();
    vector<int> begin(n);
    vector<int> end(n);
    for (int i = 0; i < n; i++)
    {
        begin[i] = num[i][0];
        end[i] = num[i][1];
    }
    sort(begin.begin(), begin.end());
    sort(end.begin(), end.end());
    //开始计数
    int res = 0, count = 0;
    int i = 0, j = 0;
    while (i < n && j < n)
    {
        if (begin[i] < end[j])
        { //遇到开始点，count需要加1
            count++;
            i++;
        }
        else//遇到结束点，count需要减1
        {
            count--;
            j++;
        }
        res = max(res, count);
    }
    return res;
}
```



## 十、数据库

### 一、MySQL

#### 1、逻辑架构

![image-20220505101602220](F:/%E6%88%91%E7%9A%84%E6%96%87%E4%BB%B6_%E5%BC%A0%E5%85%B5/%E6%89%BE%E5%B7%A5%E4%BD%9C/image-20220505101602220.png)

MySQL是典型的C/S结构，即Client/Server架构，服务端程序使用的mysqld。实现的效果都是客户端进程向服务端进程发送一段文本（SQL）语句，服务端进程处理后再向客户端进程发送一段文本（处理结果）。

##### 1、  Connectors

Connectors，指的是不同语言与SQL的交互。MySQL首先是一个网络程序，在TCP之上定义了自己的应用层协议。所以要使用MySQL，可以编写代码，跟MySQL   Server建立TCP连接，之后按照定义好的协议进行交互。或者调用SDK，比如各个语言的MySQL Connector。但通过SDK访问MySQL本质还是在TCP连接上通过MySQL协议跟MySQL进行交互。

MySQL Server结构可以分为如下三层：

1）第一层：连接层

系统（客户端）访问MySQL服务之前，做的第一件事就是建立TCP连接。经过三次握手建立连接成功之后，MySQL服务器对TCP传输过来的账号密码做身份认证、权限获取。多个系统都可以和MySQL建立连接，各个系统建立的连接不止一个。所以，为了解决TCP无限创建和频繁创建销毁带来的资源耗尽、性能下降问题。MySQL服务器有专门的TCP连接池限制连接数，采用长连接模式复用TCP连接，来解决上述问题.

TCP连接收到请求后，必须要分配一个线程专门与这个客户端交互。所以还会有线程池，去走后面的流程。每一个连接从线程池中获取线程，省去了创建和销毁线程的开销。所以**连接管理**的职责就是负责认证、管理连接、获取权限信息。

2）第二层：服务层

服务层主要完成大多数的核心服务功能。

- SQL接口
  - 接收用户的SQL命令，并且返回用户需要查询的结果
  - MySQL支持DML(数据操作语言)、存储过程、视图、触发器、自定义函数等多种SQL语言接口
-  解析器
  - 对SQL语句进行语法分析、语义分析
  - 创建语法树
- 查询优化器
- 查询缓存组件
  - 内部维持一些Cache和Buffer，不必进行查询解析、优化和执行，直接将结果反馈
  - 在MySQL8.0之后删除（命中率比较低）

3）第三层：引擎层

真正负责了MySQL中数据的存储和提取，对物理层服务器级别维护的底层数据执行操作

##### 2、SQL执行流程

![image-20220505142234970](F:/%E6%88%91%E7%9A%84%E6%96%87%E4%BB%B6_%E5%BC%A0%E5%85%B5/%E6%89%BE%E5%B7%A5%E4%BD%9C/image-20220505142234970.png)

MySQL8已经删除了查询缓存。

总之，SQL语句在MySQL中的流程是：

![image-20220505144238640](F:/%E6%88%91%E7%9A%84%E6%96%87%E4%BB%B6_%E5%BC%A0%E5%85%B5/%E6%89%BE%E5%B7%A5%E4%BD%9C/image-20220505144238640.png)



#### 2、索引及调优篇

##### 1、MyISAM和InnoDB

![image-20220504151124418](F:/%E6%88%91%E7%9A%84%E6%96%87%E4%BB%B6_%E5%BC%A0%E5%85%B5/%E6%89%BE%E5%B7%A5%E4%BD%9C/image-20220504151124418.png)

##### 2、索引概述

MySQL官方对索引的定义为：索引（Index）是帮助MySQL高效获取数据的数据结构。索引的本质：索引是数据结构。你可以简单理解为“排好序的快速查找数据结构”，满足特定查找算法。这些数据结构以某种方式指向数据， 这样就可以在这些数据结构的基础上实现高级查找算法。

索引的优点：

​	（1）提高数据检索的效率，**降低数据库的IO成本，这也是创建索引最主要的原因。** 

​	（2）通过创建唯一索引，可以保证数据库表中每一行数据的唯一性。 

​	（3）在实现数据的参考完整性方面，可以加速表和表之间的连接。换句话说，对于有依赖关系的子表和父表联合查询时，可以提高查询速度。 

（4）在使用分组和排序子句进行数据查询时，可以显著减少查询中分组和排序的时间，降低了CPU的消耗。

索引的缺点：

​	（1）创建索引和维护索引要耗费时间，并且随着数据量的增加，所耗费的时间也会增加。 

​	（2）索引需要占磁盘空间，除了数据表占数据空间之外，每一个索引还要占一定的物理空间， 存储在磁盘上，如果有大量的索引，索引文件就可能比数据文件更快达到最大文件尺寸。 

​	（3）虽然索引大大提高了查询速度，同时却会降低更新表的速度。当对表中的数据进行增加、删除和修改的时候，索引也要动态地维护，这样就降低了数据的维护速度。

##### 3、B+树



![image-20220504152027700](F:/%E6%88%91%E7%9A%84%E6%96%87%E4%BB%B6_%E5%BC%A0%E5%85%B5/%E6%89%BE%E5%B7%A5%E4%BD%9C/image-20220504152027700.png)

一个B+树的节点其实可以分成好多层，规定最下边的那层，也就是存放我们用户记录的那层为第0 层。一般情况下，我们用到的B+树都不会超过4层，那我们
通过主键值去查找某条记录最多只需要做4个页面内的查找（查找3个目录项页和一个用户记录页），又因为在每个页面内有所谓的Page Directory （页目录），所以在页面内也可以通过二分法实现快速定位记录（按照主键升序排列的）。

##### 4、常见索引概念

索引按照物理实现方式，索引可以分为 2 种：聚簇（聚集）和非聚簇（非聚集）索引。我们也把非聚集索引称为二级索引或者辅助索引。

###### 1）聚簇索引

特点：

（1）使用记录主键值的大小进行记录和页的排序，这包括三个方面的含义：

- 页内的记录是按照主键的大小顺序排成一个单向链表。（InonoDB存储引擎中页的大小为16KB）
- 各个存放用户记录的页也是根据页中用户记录的主键大小顺序排成一个双向链表。
- 存放目录项记录的页分为不同的层次，在同一层次中的页也是根据页中目录项记录的主键大小顺序排成一个双向链表。

（2）B+树的叶子节点存储的是完整的用户记录。
所谓完整的用户记录，就是指这个记录中存储了所有列的值（包括隐藏列）。

优点：

- 数据访问更快，因为聚簇索引将索引和数据保存在同一个B+树中，因此从聚簇索引中获取数据比非聚簇索引更快
- 聚簇索引对于主键的排序查找和范围查找速度非常快
- 按照聚簇索引排列顺序，查询显示一定范围数据的时候，由于数据都是紧密相连，数据库不用从多个数据块中提取数据，所以节省了大量的io操作。

缺点：

- 插入速度严重依赖于插入顺序，按照主键的顺序插入是最快的方式，否则将会出现页分裂，严重影响性能。因此，对于InnoDB表，我们一般都会定义一个自增的ID列为主键
- 更新主键的代价很高，因为将会导致被更新的行移动。因此，对于InnoDB表，我们一般定义主键为不可更新
- 二级索引访问需要两次索引查找，第一次找到主键值，第二次根据主键值找到行数据

###### 2）二级索引（辅助索引或非聚簇索引）

聚簇索引只能在搜索条件是**主键值**时才能发挥作用，因为B+树中的数据都是按照主键进行排序的。如果想以别的列作为搜索条件，可以多建几棵B+树，不同的B+树中的数据采用不同的排序规则。比如用c2列的大小作为数据页、页中数据的排序规则，再建一棵B+树。（c1列为主键值的列）

![image-20220504155719919](F:/%E6%88%91%E7%9A%84%E6%96%87%E4%BB%B6_%E5%BC%A0%E5%85%B5/%E6%89%BE%E5%B7%A5%E4%BD%9C/image-20220504155719919.png)

这个B+树与聚簇索引的不同有：

1）使用记录c2列的大小进行记录和页的排序，这包含三方面的含义：

- 页内的记录是按照c2列的大小排序排成一个单向链表。
- 各个存放用户记录的页也是按照页中记录的c2列大小排序排成一个双向链表。
- 存放目录项记录的页分为不同的层次，在同一层次的页也是按照页中目录项记录的c2列大小顺序排成一个双向链表。

2）B+树的叶子节点存储的并不是完整的用户记录，而只是**c2列+主键**这两个列的值，所以我们必须再根据主键值去聚簇索引中再查找一遍完整的用户记录。

3）目录项记录的不在是主键+页号的搭配，变成了c2+页号的搭配。

概念：回表 

​    我们根据这个以c2列大小排序的B+树只能确定我们要查找记录的主键值，所以如果我们想根据c2列的值查找到完整的用户记录的话，仍然需要到聚簇索引中再查一遍，这个过程称为回表。也就是根据c2列的值查询一条完整的用户记录需要使用到2 棵B+树！

**非聚簇索引的存在不影响数据在聚簇索引中的组织，所以一张表可以有多个非聚簇索引。但只能有一个聚簇索引。**

| 索引/存储引擎 | MyISAM | InnoDB | Memory |
| ------------- | ------ | ------ | ------ |
| B+Tree索引    | 支持   | 支持   | 支持   |
| hash索引      | 不支持 | 不支持 | 支持   |

Innodb和MyISAM默认的索引是Btree索引；而Memory默认的索引是Hash索引。

##### 5、MyISAM与InnoDB的索引区别

MyISAM的索引方式都是“非聚簇”的，与InnoDB中一定要包含1个聚簇索引，这是不同的：

- 在InnoDB存储引擎中，我们只需要根据主键值对聚簇索引进行一次查找就能找到对应的记录，而在MyISAM 中却需要进行一次回表操作，意味着MyISAM中建立的索引相当于全部都是二级索引。
-  InnoDB的数据文件本身就是索引文件，而MyISAM索引文件和数据文件是分离的，索引文件仅保存数据记录的地址。
- InnoDB的非聚簇索引data域存储相应记录主键的值，而MyISAM索引记录的是地址。换句话说，InnoDB的所有非聚簇索引都引用主键作为data域。
- MyISAM的回表操作是十分快速的，因为是拿着地址偏移量直接到文件中取数据的，反观InnoDB是通过获取主键之后再去聚簇索引里找记录，虽然说也不慢，但还是比不上直接用地址去访问。
- InnoDB要求表必须有主键（ MyISAM可以没有）。如果没有显式指定，则MySQL系统会自动选择一个可以非空且唯一标识数据记录的列作为主键。如果不存在这种列，则MySQL自动为InnoDB表生成一个隐含字段作为主键，这个字段长度为6个字节，类型为长整型。

![image-20220504163551011](F:/%E6%88%91%E7%9A%84%E6%96%87%E4%BB%B6_%E5%BC%A0%E5%85%B5/%E6%89%BE%E5%B7%A5%E4%BD%9C/image-20220504163551011.png)

##### 6、hash结构效率高，为什么索引结构要设计成树形？

MySQL中存储索引用到的数据结构是B+树，B+树的查询时间跟树的高度有关，是log(n)，如果用hash存储，那么查询时间是O(1)。

​		采用Hash来存储确实要更快，但是采用B+树来存储索引的原因主要有以下几点：

- **从内存角度上说**，数据库中的索引一般是在磁盘上，数据量大的情况可能无法一次性装入内存，B+树的设计可以允许数据分批加载。
- **从业务场景上说**，如果只选择一个数据那确实是hash更快，但是数据库中经常会选中多条，这时候由于B+树索引有序，并且又有链表相连，它的查询效率比hash就快很多了。
- hash索引仅满足=、>、<和IN查询。如果进行范围查询，哈希索引的时间复杂度会退化为O（n);而树的有序特性，依然能够保持log(n)的高效率。如果Hash的等值查询中，索引列的重复值很多，效率也会降低。因为开链法需要遍历桶中的元素一个个去对比。

##### 7、B树和B+树

B树：

![image-20220504193658746](F:/%E6%88%91%E7%9A%84%E6%96%87%E4%BB%B6_%E5%BC%A0%E5%85%B5/%E6%89%BE%E5%B7%A5%E4%BD%9C/image-20220504193658746.png)

B-Tree（Balance Tree）,也就是多路平衡查找树，不是二叉树，而是一种自平衡数据结构。它的每一个节点最多可以包含M个子节点，M为B树的阶。每个磁盘块中包括了**关键字**和**子节点的指针**。如果一个磁盘包括了x个关键字，那么指针数就是x+1。一个M阶的B树（M>2)有以下的特性：

- 根节点的 儿子树的范围为[2,M].
- 每个中间节点包括k-1个关键字和k个孩子，孩子的数量=关键字的数量+1，k的范围为[cell(M/2),M]（孩子节点的分布是根据关键字构成的范围确定的，所以孩子节点数是关键字数量+1）
- 叶子节点包括k-1个关键字（叶子节点没有孩子），k的范围为[cell(M/2),M]
- 所有叶子节点位于同一层（自平衡）

小结：

- B树在插入和删除节点的时候如果导致树不平衡。就通过自动调整节点的位置来保持树的自平衡。
- 关键字集合分布在整个树中，即叶子节点和非叶子节点都存档数据。搜索有可能在非叶子节点结束。
- 其搜索性能等价于在关键字全集内做一次二分查找。

B+树：

​	B+树也是一种多路搜索树，基于B树做出了改进。 B+树适合文件索引系统。

B树和B+树的差异如下：

- 有k个孩子的节点就有k个关键字。也就是孩子数量=关键字树，而B树中，孩子数量=关键字数+1.
- 非叶子节点的关键字也同时存在在子节点中，并且在子节点中所有关键字的最大（或最小）
- 非叶子节点仅用于索引，不保存数据记录，跟记录有关的信息都放在叶子节点中。而B+树中，非叶子节点既保存索引，也保存数据记录
- 所有关键字都在叶子节点出现，叶子节点构成有序链表，而且叶子节点本身按照关键字的大小从小到大顺序链接
- B+树比B树查询效率更高。这是因为B+树更矮胖（阶数更低）

##### 8、为了减少IO，索引树会一次性加载吗？

- 数据库索引是存储在磁盘上的，如果数据量很大，必然导致索引的大小也很大，超过几个G
- 当利用索引查询的时候，是不可能将全部几个G的索引都加载进内存的，只能逐一加载每一个磁盘页，因此磁盘页对应着索引树的节点

##### 9、B+树的存储能力如何？为何说一般查找行记录，最多只需1~3次磁盘IO

InnoDB存储引擎中页大小为16kb，主键（8bit）和指针（8bit），也就是一个页可以存除16KB/(8B+8B)=1000个键值。因此在数据库中，B+树的高度一般都在2~4层。MySQL的InnoDB存储引擎在设计时将根节点常驻内存，也就是查找某一键值的行记录最多只需要1到3次磁盘IO操作。

##### 10、为什么说B+树比B-树更适合实际应用中操作系统的文件索引和数据库索引？

- B+树的磁盘读写代价更低
- B+树的查询效率更加稳定
- B+树的查询效率更高

##### 11、索引的分类

- 从功能逻辑上说，索引主要有 4 种，分别是普通索引、唯一索引、主键索引、全文索引。（主键索引是一种特殊的唯一性索引）
- 按照物理实现方式，索引可以分为 2 种：聚簇索引和非聚簇索引。
- 按照作用字段个数进行划分，分成单列索引和联合索引。（联合索引就是多列索引 ）

随着大数据时代的到来，关系型数据库应对全文索引的需求已力不从心，逐渐被solr、ElasticSearch等专门的搜索引擎所替代

##### 12、数据库的数据存储结构（InnoDB）

InonoDB将数据划分若干个页，页默认大小为16KB.以页作为磁盘和内存之间交互的基本单位。在数据库中，不论读多少行，都是将这些行所在的页进行加载，即数据库IO操作的最小单位是页。

页的上层结构如下：

![image-20220505212319152](F:/%E6%88%91%E7%9A%84%E6%96%87%E4%BB%B6_%E5%BC%A0%E5%85%B5/%E6%89%BE%E5%B7%A5%E4%BD%9C/image-20220505212319152.png)

区是比页大一级的存储结构，在InnoDB中，**一个区会分配64个连续的页**。

段有一个或多个区组成，区在文件系统是一个连续分配的空间，在段中不要求区与区是相邻的。段是数据库的分配单位，不同类型的数据库对象以不同的段形式存在。当创建数据表、索引的时候，就会创建对应的段，比如创建一张表时会创建一个表端，创建一个索引时会创建一个索引段。

表空间是一个逻辑容器。表空间存储的的对象是段，在一个表空间中可以有一个或多个段，但是一个段只能属于一个表空间。数据库由一个或多个表组成。

##### 13、视图

-  视图是一种虚拟表，本身不具有数据的，占很少的内存空间，它是SQL的一个重要概念

- 视图建立在已有表的基础上，视图赖以建立的这些表叫**基表**

- 视图的创建和删除只影响视图本身，不影响对应的基表。但是对视图中的数据进行增加、删除和修改操作时，数据表中的数据会相应的发生变化，反之亦然

- 视图是向用户提供基表数据的另一种表现形式

- 向视图提供数据内容的语句是SELECT语句，可以将视图理解为**存储起来的SELECT语句**

  ```mysql
  CREATE VIEW 视图名称 [(字段列表)]
  AS 查询语句
  ```

  

视图一方面可以帮助我们使用表的一部分而不是所有的表，另一方面可以针对不同的用户制定不同的查询视图。

视图的优点：

- 简化查询
- 减少数据冗余
- 控制视图的访问权限，保证数据安全
- 适应灵活多变的需求

视图的缺点：

- ​	如果实际数据表变更了，就需要及时对相关的视图进行相应的维护，即维护成本较高，特别是嵌套的视图

##### 14、游标

虽然我们可以通过筛选条件WHERE和HAVING，或者是限定返回记录的关键字LIMIT返回一条记录，但是无法在结果集中像指针一样，向前定位一条记录、向后定位一条记录，或者是随意定位到某一条记录，并对记录的数据进行处理。**游标**，提供了一种灵活的操作方式，让我们对结果集中的每一条记录进行定位，并对指向的记录中的数据进行操作的**数据结构**。在SQL中，游标是一种临时的数据库对象，可以指向存储在数据库中的数据行指针。这里游标充当了指针的作用，我们可以操作游标来对数据行进行操作。

##### 15、索引的设计原则

- 字段的数值有唯一性的限制 
- 频繁的作为WHERE查询条件的字段  

##### 16、不适合创建索引的情况

- 数据量小的表最好不要使用索引
- 在where中使用不到的段不要设置索引
- 有大量重复数据的列上不要建立索引
- 不建议用无序的值作为索引
- 避免对经常更新的表创建过多的索引

##### 17、数据库调优 

数据库调优的主要维度有以下四个方面：

- 索引失效、没有充分利用到索引——建立索引
- 关联查询太多JOIN（设计缺陷或不得已的需求）——SQL查询优化
- 服务器调优及各个参数设置（缓冲、线程数）——调整my.cnf
- 数据过多——分库分表、数据库中从读写分离

##### 18、索引失效

1）使用联合索引应该满足最佳左前缀法则，否则联合索引将会失效

MySQL可以为多个字段创建索引，一个索引包括16个字段。**对于联合索引，过滤条件要使用索引必须按照索引建立时的时候**，**依次满足**，**一旦跳过某个索引，索引后面的字段都将无法使用。**如果查询条件中没有使用这些字段中的第一个字段，联合索引将不会被使用，即失效。

2）查询语句中对索引字段进行计算、使用函数、类型转换（自动或手动）导致索引失效

​	对索引使用函数导致失效：

```mysql
// name 为二级索引
select * from t_user where length(name)=6;//索引失效
```

因为索引保存的是索引字段的原始值，而不是经过函数计算后的值，自然就没办法走索引了。

​	对索引进行表达式计算：

```mysql
explain select * from t_user where id + 1 = 10;//索引失效
explain select * from t_user where id  = 10-1;//索引不失效
```

因为索引保存的是索引字段的原始值，而不是 id + 1 表达式计算后的值，所以无法走索引，只能通过把索引字段的取值都取出来，然后依次进行表达式的计算来进行条件判断，因此采用的就是全表扫描的方式。

对索引进行隐形类型转换导致失效：

如果索引字段是字符串类型，但是在条件查询中，输入的参数是整型的话，你会在执行计划的结果发现这条语句会走全表扫描。

3）范围条件右边的索引失效

解决办法：建立索引时，将范围查找的字段放在联合索引的最右边

4）不等于（！=或者<>)索引失效

5）is null可以使用索引，is not null无法使用索引  

6）like以通配符%开头索引失效

在使用LIKE关键字进行查询的查询语句时，如果匹配字符串的第一个字符为%，索引就不会起作用。只有%不在第一个位置，索引才会起作用

 7）OR前后存在非索引的列，索引失效

在WHERE子句中，如果OR前的条件列进行了索引，而在OR后的条件列没有进行索引，那么索引就会失效。**也就是说，OR前后的两个条件的列都是索引是，查询中才使用索引**

##### 19、范式概述

在关系型数据库中，关于数据库表设计的基本原则、规则称为范式。目前关系型数据库有常见六种范式，按照范式级别，从低到高分别是：第一范式、第二范式、第三范式、巴斯-科德范式、第四范式和第五范式（完美范式）。 数据库的范式设计越高阶，冗余度越低，同时高阶的范式一定符合低阶范式的要求。

第一范式主要是确保数据表中每个字段的值必须具有原子性，也就是说数据表中每个字段的值不可再拆分的最小数据单元。 第一范式说明字段属性需要是原子的。

第二范式要求在满足第一范式的基础上，还要满足数据表里的每一条数据记录都是**可唯一标识的**。而且所有非主键字段，**都必须完全依赖主键**，**不能只依赖主键的一部分。**第二范式体现了唯一性，一张表就是一个独立的对象。它要求实体的属性完全依赖主关键字。如果存在不完全依赖，那么这个属性和主关键字的这一部分应该分离出来形成一个新的实体

第三范式是在第二范式的基础上，要求数据表中的所有非主键字段不能依赖于其他的非主键字段。

总结：第一范式确保每列保持原子性，第二范式确保每列都和主键完全依赖，第三范式确保每列都和主键列**直接相关**，而不是间接相关

##### 20、键和相关属性的概念

- 超键：能唯一标识元组的属性集叫做超键
- 候选键：如果超键不包括多余的属性，那么这个超键就是候选键
- 主键：用户可以从候选键中选择一个作为主键
- 外键：如果数据表中R1中的某属性集不是R1的主键，而是另一个数据表R2的主键，那么这个属性集就是数据表R1的外键
- 主属性：包含在任一候选键中的属性称为主属性
- 非主属性：与主属性相对，指的是不包含在任意候选键中的属性

#### 3、事务篇

##### 1、事务概述

事务：一组逻辑操作单元，使数据从一个状态转换到另一个状态。

事务处理的原则：保证所有事务都作为**一个工作单元**来执行，即使出现了故障，都不能改变这种执行方式。当在一个事务中执行多个操作时，要么所有的事务都被提交，那么这些修改就永久的保存下来；要么数据库管理系统将**放弃**所作的**所有修改**，整个事务回滚到最初状态。

##### 2、事务的四大特性ACID

原子性：指事务是一个不可分割的工作单位，要么全部提交，要么全部失败回滚。

一致性：指事务执行前后，数据从一个合法性状态变换到另一个合法性状态。

隔离性：指一个事务的执行不能被其他事务干扰，即一个事务内部的操作及使用的数据对并发的其他事务是隔离的，并发执行的各个事务之间不能互相干扰。

持久性：指一个事务一旦被提交，它对数据库中的数据的改变就是永久性的，接下来的其他操作和数据库故障不应该对其有任何影响

这四个特性中，原子性是基础，隔离性是手段，一致性是约束条件，持久性是我们的目的

##### 3、事务的状态

活动的：事务对应的数据库操作正在执行过程中时，我们就说该事务处在活动的状态。

部分提交的：当事务中的最后一个操作执行完成，但由于操作都在内存中执行，所造成的影响并没有刷新到磁盘时，我们就说该事务处在部分提交的状态。

失败的：当事务处在活动的或者部分提交的状态时，可能遇到了某些错误而无法继续执行，或者人为的停止当前事务的执行，我们就说该事务处在失败的状态。

中止的：如果事务执行了一部分而变为失败的状态，就要撤销失败事务对当前数据库造成的影响。当回滚操作执行完毕时，也就是数据库恢复到了执行事务之前的            状态，我们就说该事务处在了中止的状态。

提交的：当一个处在部分提交的状态的事务将修改过的数据都同步到磁盘上之后，我们就可以说该事务处在了提交的状态。

![image-20220508152209894](F:/%E6%88%91%E7%9A%84%E6%96%87%E4%BB%B6_%E5%BC%A0%E5%85%B5/%E6%89%BE%E5%B7%A5%E4%BD%9C/image-20220508152209894.png)

##### 4、数据并发问题

针对数据的隔离性和并发性，访问相同数据的事务在不保证串行执行的情况下可能出现的问题：

脏写：对于两个事务 Session A、Session B，如果事务Session A 修改了另一个未提交事务Session B 修改过的数据，那就意味着发生了脏写

脏读：对于两个事务 Session A、Session B，Session A 读取了已经被 Session B 更新但还没有被提交的字段。之后若 Session B 回滚，Session A 读取的内容就是临时且无效的。

不可重复读：对于两个事务Session A、Session B，Session A 读取了一个字段，然后 Session B 更新了该字段。 之后Session A 再次读取同一个字段， 值就不同了。那就意味着发生了不可重复读。

幻读：对于两个事务Session A、Session B, Session A 从一个表中读取了一个字段, 然后 Session B 在该表中**插入**了一些新的行。 之后, 如果 Session A 再次读取同一个表, 就会多出几行。那就意味着发生了幻读

##### 5、事务的四种隔离级别

并发事务执行中可能遇到的四种问题，这些问题有轻重缓急之分，这些问题按严重性排序如下：

```
脏写 > 脏读 > 不可重复读 > 幻读
```

我们愿意舍弃一部分隔离性来换取一部分并发性能的体现：设立一些隔离级别，隔离级别越低，并发问题发生的就越多。**SQL标准设立了4个隔离级别**：

读未提交：在该隔离级别，所有事务都可以看到其他未提交事务的执行结果。不能避免脏读、不可重复读、幻读。

读已提交：可以避免脏读，但不可重复读、幻读问题仍然存在。

可重复读：可以避免脏读、不可重复读，但幻读问题仍然存在。这是MySQL的默认隔离级别。

可串行化：能避免脏读、不可重复读和幻读。

**四种级别都必须避免脏写，脏写是不能容忍的。**

##### 6、mysql事务日志

事务的四大特性中，事务的隔离性是由锁机制实现的，事务的原子性由事务的redo日志来保证的；一致性和持久性是由事务的undo日志来保证的。

redo log:称为重做日志，提供再写入操作，恢复提交事务修改的页操作，用来保证事务的持久性。redo日志的整体流程如下：

![image-20220509095122592](F:/%E6%88%91%E7%9A%84%E6%96%87%E4%BB%B6_%E5%BC%A0%E5%85%B5/%E6%89%BE%E5%B7%A5%E4%BD%9C/image-20220509095122592.png)

undo log:回滚日志，回滚行记录到某个特定版本，用来保证事务的**原子性、一致性**。在事务中更新数据的前置操作其实是要先写入一个undo log。 即：

当插入一条记录时：要把这条记录的主键值记下来，之后回滚只需要将主键值对应的记录删掉

当删除一条记录时：要把记录中 的内容记录，回滚的时把这些内容组成的记录插入表中

当修改一条记录时：需要把修改前的旧值记录下来，回滚的时候把记录更新为旧值即可

由于查询操作并不会修改任何记录，所以不需要记录相应的undo日志。此为undo日志会产生redo日志，这是因为undo日志也需要持久性的保护。

#### 4、锁篇

 当并发事务访问相同记录的情况大致可以划分为三种：

读-读情况：读操作不会对记录有影响

写-写情况：这种情况会发生**脏写**的问题，任何一种隔离级别都不允许这种问题的发生，需要用锁进行排队实现。

读-写情况：这种情况下可能会发生**脏读、不可重复度、幻读**的问题。

##### 1、并发问题的解决方案

怎么解决脏读、不可重复读、幻读的问题呢？主要由两种可选的解决方案。

方案一：读操作利用多版本并发控制（MVCC),写操作进行加锁.

​		所谓的MVCC就是生成一个ReadView，通过ReadView找到符合条件的记录版本（历史版本由undo日志构建）。查询语句只能读到在生成ReadView之前已经提交事务所作的修改，在生成ReadView之前未提交的事务或者之后开启的事务所作的修改看不到。而写操作肯定针对的是最新版本的记录，读记录的历史版本和改动版本的最新版本本身并不冲突，也就是采用MVCC时，读写操作并不冲突

方案二：读、写操作都采用加锁的方式

##### 2、锁的分类

 ![image-20220510150052679](F:/%E6%88%91%E7%9A%84%E6%96%87%E4%BB%B6_%E5%BC%A0%E5%85%B5/%E6%89%BE%E5%B7%A5%E4%BD%9C/image-20220510150052679.png)

S锁（共享锁）、X锁（排他锁）；也叫读锁和写锁

##### 3、表级锁、页级锁、行锁

为了尽可能提高数据库的并发度，每次锁定的数据范围越小越好，理论上每次只锁定当前操作的数据方案会得到最大的并发度，但是管理锁是很耗资源的事情。因此数据库系统需要在高并发和系统性能两方面进行权衡。

表锁：锁定整张表，它不依赖于存储引擎，表锁是开销最小的策略，可以很好的避免死锁的问题，但并发率大打折扣。

行锁：MySQL服务器层并没有实现锁机制，行级锁旨在存储引擎层实现。可以实现的并发度高，容易出现死锁情况。

##### 4、行锁

记录锁：仅仅把一条记录锁上。

间隙锁：MySQL解决幻读问题的方案有两种：1、可以使用MVCC方案解决。2、使用加锁方案解决。但是在使用加锁方案解决有个问题就是事务第一次执行读取操作时，那些幻影记录是不存在的，无法给幻影记录加上记录锁。InnoDB提出一种间隙锁解决。间隙锁的提出仅仅是为了防止插入幻影记录而提出的。

##### 5、死锁

两个事务都持有对方需要的锁，并且在等待对方释放，并且双方都不会释放自己的锁。

产生死锁的必要条件：

- 两个或两个以上事务
- 两个事务都已经持有锁并且申请新的锁
- 锁资源同时只能被同一个事务持有或不兼容
- 事务之间因为持有锁和申请锁导致彼此循环等待**（死锁的关键在于两个事务加锁的顺序不一致）**

##### 6、如何解决死锁

方式1：等待，直到超时。当一个事务等待超过设置的阈值时，就将其回滚，另外事务继续进行。

方式2：使用死锁检测进行死锁处理。每当加锁请求无法立即满足需要并进入等待时，触发死锁检测。**死锁检测的原理是构建一个以事务为顶点，锁为边的有向图，判断有向图是否有环，存在即有死锁。**一旦检测有死锁，这时候InnoDB存储引擎就会选择回滚undo量最小的事务，让其他事务继续执行。

##### 7、如何避免死锁

- 调整业务逻辑SQL顺序执行，避免update/delete长时间持有锁的SQL在事务前面。
- 避免大事务，尽量将大事务拆分成多个小事务来处理，小事务缩短锁定资源的时间，发生锁冲突的几率也更小
- 降低隔离级别

##### 8、多版本并发控制（MVCC）

MVCC是通过数据行的多个版本管理来实现数据库的**并发控制**。是为了查询一些正在被另一事务更行的行，并且可以看到他们被更新之前的值，这样在做查询的时候就不用等待另一个事务释放锁。MVCC在MysQL InnoDB中的实现主要是为了提高数据库并发性能，MVCC是一种解决读写冲突的无锁并发控制。

快照读，读取的是快照数据。**不加锁的简单SELECT都属于快照读，即不加锁的非阻塞读**，之所以出现快照读，是基于提高并发性能的考虑。快照读的实现是基于MVCC，他在很多情况下，避免了加锁的操作，降低了开销。快照读可能读到的并不一定是数据的最新版本，而有可能是之前的历史版本。

当前读读取的是记录的最新版本。

**MVCC可以不采用锁机制，而是通过乐观锁的方式来解决脏读、不可重复读和幻读问题。**

##### 9、MVCC实现原理

**MVCC实现依赖于：隐藏字段、undo日志、Read View**三个组件来实现的。

**隐藏字段：**对于InnoDB存储引擎的表来说，它的聚簇索引记录中都包含两个必要的隐藏列：

- trx_id:每次一个事务对某条聚簇索引记录进行改动时，都会把该事务的事务id赋值给trx_id隐藏列
- roll_pointer:每次对某条聚簇索引进行改动时，都会把旧的版本写入到undo日志中，然后这个隐藏列就相当于一个指针，可以通过它来找到该记录修改前的信息。

**undo日志版本链：**对该记录每次更新后，都会将旧值放到一条undo日志中，就算是该记录的一个旧版本，随着更新次数的增多，所有的版本都会被roll_pointer属性连接成一个链表，我们把这个链表称之为版本链。版本链的头节点就是当前记录最新的值

**Read View：**在MVCC机制中，多个事务对同一个行记录进行更新会产生多个历史快照，这些历史快照保存在undo log里。如果一个事务想要查询这个行记录，需要读取哪个版本的行记录？这时候就需要ReadView，它帮我们解决了行的可见性问题。 

ReadView就是事务在使用MVCC机制进行快照读操作时产生的读视图。当事务启动时，会生成数据库系统当前的一个快照，InnoDB为每个事务构造一个数组，用来记录并维护系统当前活跃事务的ID（活跃指的就是启动了，但还未提交，undo日志中已经做了修改生成了版本链，但磁盘还未刷新，即未提交）.ReadView会选择不在活跃事务ID数组中的事务版本。**ReadView要解决的问题主要问题就是需要判断版本链中哪个版本是当前事务可见的。**

**MVCC只能在读已提交和可重复读两个隔离级别下工作**。

#### 5、日志与备份篇

##### 1、二进制日志（bin日志）

二进制日志记录所有更改数据的语句，可以用于主从服务器之间的数据同步，以及服务器遇到故障时数据的无损失恢复。

### 二、Redis

- Redis是一个开源的key-value存储系统，是用c语言实现
- 支持存储的value类型相对较多，包括字符串、链表、集合、有序集合、哈希
- 这些数据类型都支持push/pop、add/remove等操作，并且操作时原子性的
- 为了保证效率，数据都是缓存在内存中的
- Redis会周期性的把更新的数据写入磁盘或者把修改操作写入追加的记录文件
- 实现在了主从同步
- 单线程+多路IO复用

#### 1、数据结构篇

Redis的数据类型有字符串对象、List对象、Hash对象、Set对象和ZSet对象。Redis 3.0 的 List 对象在数据量比较少的情况下，会采用「压缩列表」作为底层数据结构的实现，它的优势是节省内存空间，并且是内存紧凑型的数据结构。 Redis 在 3.2 版本设计了新的数据结构 quicklist，并将 List 对象的底层数据结构改由 quicklist 实现。在 Redis 5.0 设计了新的数据结构 listpack，沿用了压缩列表紧凑型的内存布局，最终在最新的 Redis 版本，将 Hash 对象和 Zset 对象的底层数据结构实现之一的压缩列表，替换成由 listpack 实现。

Redis的数据结构主要有：简单动态字符串（SDS）、双端链表、字典、压缩列表、跳表、整数集合、quicklist、listpack。Redis并没有直接使用这些数据结构，而是基于这些数据结构构建了一个对象系统，这个系统包含字符串对象、列表对象、哈希对象、集合对象和有序集合这五种类型的对象，每种对象至少用到一种前面的数据结构。Redis的的对象系统还实现了基于引用计数技术的内存回收机制，当程序不再使用某个对象的时候，这个对象所占用的内存就会被自动释放。另外，Redis还通过引用计数技术实现了对象共享机制，这一机制可以在适当的条件下，通过让多个数据库键共享同一个对象来节约内存。

##### 1、跳表

跳表是一种有序数据结构，跳表支持平均O（logN）、最坏O(N)复杂度的节点查找。跳表作为有序集合的底层实现之一。跳表的效率可以和平衡树相媲美。在跳跃表中，节点按各自所保存的分值（权重）从小到大排列

#### 2、持久化篇

Redis服务器将所有数据库都保存在服务器状态redis.h/redisServer结构的db数组中，db数组的每个项都是一个redis.h/redisDb结构，每个redisDb结构代表一个数据库.在初始化服务器时，程序会根据服务器状态的dbnum属性来决定应该创建多少个数据库.dbnum属性的值由服务器配置的database选项决定，默认情况下，该选项的值为16，所以Redis服务器默认会创建16个数据库

```c
struct redisServer {
//一个数组，保存着服务器中的所有数据库
redisDb *db;
//服务器的数据库数量
int dbnum;
};
```

Redis是一个键值对（key-value pair）数据库服务器，服务器中的每个数据库都由一个redis.h/redisDb结构表示，其中，redisDb结构的dict字典保存了数据库中的所有键值对，我们将这个字典称为键空间(key  space)

```c
typedef struct redisDb {
//数据库键空间，保存着数据库中的所有键值对
dict *dict;
} redisDb;
```

![image-20220517172115187](F:/%E6%88%91%E7%9A%84%E6%96%87%E4%BB%B6_%E5%BC%A0%E5%85%B5/%E6%89%BE%E5%B7%A5%E4%BD%9C/image-20220517172115187.png)

#### 3、集群篇

#### 4、架构篇

# Leetcode



### 1、剑指offer



### 2、Hot100

### 3、Leetcode精选算法200

156、上下翻转二叉树

题目：给定一个二叉树，其中所有的右节点要么是具有兄弟节点（拥有相同父节点的左节点）的叶节点，要么为空，将此二叉树上下翻转并将它变成一棵树， 原来的右节点将转换成左叶节点。返回新的根。

    输入: [1,2,3,4,5]
        1
       / \
      2   3
     / \
    4   5
    输出: 返回二叉树的根 [4,5,2,#,#,3,1]
       4
      / \
     5   2
        / \
       3   1  
    
    说明:
    对 [4,5,2,#,#,3,1] 感到困惑? 下面详细介绍请查看 二叉树是如何被序列化的。
    二叉树的序列化遵循层次遍历规则，当没有节点存在时，'#' 表示路径终止符。
    这里有一个例子:
       1
      / \
     2   3
        /
       4
        \
         5
    上面的二叉树则被序列化为 [1,2,3,#,#,4,#,#,5].
```c++

```





# 面试问题

## 1、阿里实习一面

1、项目和论文。两个论文亮点。

2、智能指针，引用计数器具体怎么实现，

3、优先队列底层实现，堆实现

4、vector的push_back与emplace_back实现区别

5、多线程模型创建套接字实现，IO多路复用

6、linux命令top、ps、free看内存剩余空间

7、锁机制，自旋锁和互斥锁区别

8、右值引用

9、红黑树与AVL树的区别

10、map与unordered_map区别，访问时间复杂度

## 2、字节实习

#### 一面：

1、内核态与用户态区别，为什么要区分内核太与用户态，有什么好处

2、HTTP状态码

3、互斥锁、读写锁，多线程并发具体怎么处理共享资源

4、map底层，查询复杂度，unordered_map复杂度，如何解决hash冲突

5、get方法与post方法区别，如果post方法提交json文件应该怎么做

6、HTTP如何保证客户端状态，cookie与session区别

7、说三次握手，三次握手有什么好处



撕题:两数之和（有重复数字），时间复杂度越低越好

#### 二面：

1、linux用过的命令全说一下，top能看出哪些具体的信息

2、HTTP与HTTPS区别，SSL握手过程，如何优化这个过程

3、挥手为什么是四次，挥手为什么有times_wait,close_wait是什么时候进入

4、webserver实现的流程（做的项目）

5、map与unordered_map区别

6、vector与list区别

7、define与const区别

8、OSI七层模型

撕题：反转链表和最小路径和（稍微变动了一下）

#### 三面：

1、ctrl+cv,操作系统做了什么

2、程序运行的过程

3、两个不在同一个局域网的AB两点通讯过程

4、有了IP地址为什么还要mac地址

​	解释：	https://www.zhihu.com/question/21546408/answer/53576595

为什么有了mac地址还需要IP地址？

由于假如我们只用 MAC 地址的话，我们会发现路由器需求记住每个 MAC 地址地点的子网是哪一个。而国际上有![2^{48}](https://www.zhihu.com/equation?tex=2%5E%7B48%7D)个 MAC 地址，这就意味着即便我们给每个 MAC 地址只留 1 字节的贮存空间，每个路由器也需求 256 TB 的内存！这显然是不能能完成的。这就是我们需求 IP 地址的原因了。和 MAC 不同的是，IP 地址是和地域相关的。关于坐落同一个子网上的设备，我们给他们分配的 IP 地址前缀都是相同的。这个前缀就像邮政编码相同。这样，路由器过 IP 地址的前缀就能知道这个设备在哪个子网上了。现在，路由器只需求记住每个子网的方位即可，大大减少了路由器所需求的内存。

有了IP地址为什么还要mac地址？

一. 全体与部分**
信息传递时分，需求知道的其实是两个地址：

- 结尾地址（Final destination address）
- 下一跳的地址（Next hop address）

IP地址本质上是结尾地址，它在越过路由器（hop）的时候不会改动，而MAC地址则是下一跳的地址，每越过一次路由器都会改动。这就是为什么还要用MAC地址的原因之一，它起到了记载下一跳的信息的效果。

5、手写单例模式

**保证一个类仅有一个实例，并提供一个访问它的全局访问点，该实例被所有程序模块共享**.实现是定义一个单例类，使用类的私有静态指针变量指向类的唯一实例，并用一个公有的静态方法获取该实例。定义如下：

```c++
class CSingleton
{
private:
    CSingleton()   //构造函数是私有的
    {
    }
    static CSingleton *m_pInstance;
public:
    static CSingleton * GetInstance()
    {
        if(m_pInstance == NULL)  //判断是否第一次调用，第一次调用进行new
            m_pInstance = new CSingleton();
        return m_pInstance;
    }
};
```

用户访问唯一实例的方法只有GetInstance()成员函数。如果不通过这个函数，任何创建实例的尝试都将失败，因为类的构造函数是私有的。

6、僵尸进程和孤儿进程

7、智能指针说说，为什么要有unique_ptr呢

8、特例化和偏特化

9、预编译

| **过程** | **生成文件** |
| -------- | ------------ |
| 预编译   | *.i          |
| 编译     | *.s          |
| 汇编     | *.o          |
| 链接     | 可执行文件   |

# 项目

## 1、webServer

**整体功能：**

- 利用IO复用技术Epoll与线程池实现多线程的Reactor高并发模型；
- 利用正则与状态机解析HTTP请求报文，实现静态资源的请求；
- 封装char数组，实现自动增长的缓冲区buffer；
- 基于堆结构实现的定时器，关闭超时的非活动连接
- 使用线程池充分利用多核CPU，并使用线程池避免线程频繁创建销毁的开销
- 为了减少内存泄漏的可能，使用智能指针等RAII机制



### 1、利用标准库封装char，实现自动增长的缓冲区

#### 1.1、buffer缓冲区的介绍

客户端连接发来的HTTP请求以及回复给客户端所请求的资源，都需要缓冲区的存在。其实，在操作系统的内核中就有缓冲区的实现，read()/write()的调用就离不开缓冲区的支持。但是，在这里用缓冲区的实现不太方便。所以，在这个项目中实现了一个符合需要的缓冲区结构。在C++的STL库中，vector容器其实就很适合作为缓冲区。为了能够满足我们的需要，我们以vector容器作为底层实体，在它的上面封装自己所需要的方法来实现一个自己的buffer缓冲区，满足读写的需要。

**该buffer缓冲区实现自动增长的目的是为了避免vector动态扩容开辟新的空间，并且将旧的数据拷贝到新的内存空间中，避免这部分数据拷贝的开销。该buffer不会将旧的数据拷贝到新的内存空间。通过返回的文件描述符以unordered_map作为底层实体，在它的上面封装实现一个自己的buffer缓冲区.unordered_map的键值为buffer缓冲区的ID号， unordered_map的内容为buffer的指针位置，buffer数据存储在堆区。该缓冲区可以根据收到的数据自动增长。同一个客户端读取的数据和要发送的数据放在来连续的存储空间中。**

#### 1.2、buffer缓冲区的接口

缓冲区最重要的就是读写接口，主要可以分为与客户端直接IO交互所需要的读写接口，以及收到客户端HTTP请求后，我们在处理过程中需要对缓冲区的读写接口。

```c++
class Buffer
{
    // size_t类型是一个整型，真实类型与操作系统有关，一个size_t的大小就是一个字节大小，ssize_t是有符号整型
public:
    Buffer();
    ~Buffer();
    // IO操作的读与写接口
    ssize_t readFd(int fd, int *Errno);
    void test();
    string AlltoStr();                           //将读取的数据全部转成字符串，方便后面的解析
    ssize_t m_readLen;                           //总共读取的数据长度
    void append(const string &str);              //存储需要发送的数据，如果超过buffer空间需要扩容
    unordered_map<int, char *> BufferID() const; //返回bufferID
    ssize_t WritePos() const;
    ssize_t LastReadBufferLen() const;
    int ReadBufferLen() const;

private:
    unordered_map<int, char *> m_bufferID; // key：buffer的ID号，value:为buffer对应的首指针
    ssize_t m_lastReadBufferLen;           //最后一个读取buffer缓冲区存储数据
    ssize_t m_writePos;                    //记录写数据的位置
    int m_readBufferLen;                   //记录读到的数据存放到了几个buffer区
};
```

readFd这个功能直接用read（）函数来实现。如果buffer默认的长度小于读取的数据，则需要开辟新的buffer空间。

在[socket](https://so.csdn.net/so/search?q=socket&spm=1001.2101.3001.7020)中服务器与客户端进行通信，当其中一方调用close（即这一方会发送一个fin）关闭套接字之后，另一方read（）会返回一个0。

### 2、解析HTTP请求数据

HTTP的请求包括：请求行(request line)、请求头部(header)、空行 和 请求数据 四个部分组成。将放在自定义Buffer缓冲区的HTTP请求数据进行解析。

#### 2.1.请求行

`GET`为请求类型，`/mix/76.html?name=kelvin&password=123456`为要访问的资源，`HTTP/1.1`是协议版本

#### 2.2.请求头部

从第二行起为请求头部，`Host`指出请求的目的地（主机域名）；`User-Agent`是客户端的信息，它是检测浏览器类型的重要信息，由浏览器定义，并且在每个请求中自动发送。

#### 2.3.空行

请求头后面必须有一个空行

#### 2.4.请求数据

请求的数据也叫请求体，可以添加任意的其它数据。这个例子的请求体为空。

由上述的简单描述可以看出来，我们的主要任务就是解析传进来的buffer里面的请求信息，也就是把各个有用信息分割开来。

具体的实现方法如下：

```c++
class HttpParse
{
public:
    HttpParse();
    enum PARSE_STATE
    {                   //枚举类型，第一个默认0
        REQUEST_LINE,   //请求行
        REQUEST_HEADER, //请求头部信息
        REQUEST_BODY,   //数据体
        FINISH,
    };
    bool Parse(string &buffer);
    ~HttpParse();
    //暴露给外界的接口
    bool isKeepAlive() const;
    string Method() const;
    string Version() const;
    string &Path();
    string DataBody() const;
private:
    bool ParseRequestLine(const string &line);   //解析请求行
    void ParseRequestHeader(const string &line); //解析请求头
    void ParseRequestBody(const string &line);   //解析消息数据体
    //解析请求方法，HTTP版本，数据体，主机IP，URL内容
    unordered_map<string, string> m_header;//保存的请求头数据，key：请求头名称，value:请求头内容
    string m_requestMethod, m_httpVersion, m_httpBody, m_path;
    PARSE_STATE state;
};
```

利用正则与状态机解析HTTP请求报文。

#### 2.5、正则表达式

利用regex类。regex类:表示一个正则表达式。除了初始化和赋值操作，还支持其他的一些操作;

regex_match方法：确定一个给定字符序列与一个给定regex对象是否完全匹配,返回true/false，如果匹配到，将匹配到的内容保存起来;

[特殊字符](https://changkun.de/modern-cpp/zh-cn/06-regex/#特殊字符)

特殊字符是正则表达式里有特殊含义的字符，也是正则表达式的核心匹配语法。参见下表：

| 特别字符 | 描述                                                         |
| :------- | :----------------------------------------------------------- |
| `$`      | 匹配输入字符串的结尾位置。                                   |
| `(`,`)`  | 标记一个子表达式的开始和结束位置。子表达式可以获取供以后使用。 |
| `*`      | 匹配前面的子表达式零次或多次。                               |
| `+`      | 匹配前面的子表达式一次或多次。                               |
| `.`      | 匹配除换行符 `\n` 之外的任何单字符。                         |
| `[`      | 标记一个中括号表达式的开始。                                 |
| `?`      | 匹配前面的子表达式零次或一次，或指明一个非贪婪限定符。       |
| `\`      | 将下一个字符标记为或特殊字符、或原义字符、或向后引用、或八进制转义符。例如， `n` 匹配字符 `n`。`\n` 匹配换行符。序列 `\\` 匹配 `'\'` 字符，而 `\(` 则匹配 `'('` 字符。 |
| `^`      | 匹配输入字符串的开始位置，除非在方括号表达式中使用，此时它表示不接受该字符集合。 |
| `{`      | 标记限定符表达式的开始。                                     |
| `|`      | 指明两项之间的一个选择。                                     |



### 限定符

限定符用来指定正则表达式的一个给定的组件必须要出现多少次才能满足匹配。见下表：

| 字符    | 描述                                                         |
| :------ | :----------------------------------------------------------- |
| `*`     | 匹配前面的子表达式零次或多次。例如，`foo*` 能匹配 `fo` 以及 `foooo`。`*` 等价于`{0,}`。 |
| `+`     | 匹配前面的子表达式一次或多次。例如，`foo+` 能匹配 `foo` 以及 `foooo`，但不能匹配 `fo`。`+` 等价于 `{1,}`。 |
| `?`     | 匹配前面的子表达式零次或一次。例如，`Your(s)?` 可以匹配 `Your` 或 `Yours` 中的`Your` 。`?` 等价于 `{0,1}`。 |
| `{n}`   | `n` 是一个非负整数。匹配确定的 `n` 次。例如，`o{2}` 不能匹配 `for` 中的 `o`，但是能匹配 `foo` 中的两个 `o`。 |
| `{n,}`  | `n` 是一个非负整数。至少匹配 `n` 次。例如，`o{2,}` 不能匹配 `for` 中的 `o`，但能匹配 `foooooo` 中的所有 `o`。`o{1,}` 等价于 `o+`。`o{0,}` 则等价于 `o*`。 |
| `{n,m}` | `m` 和 `n` 均为非负整数，其中 `n` 小于等于 `m`。最少匹配 `n` 次且最多匹配 `m` 次。例如，`o{1,3}` 将匹配 `foooooo` 中的前三个 `o`。`o{0,1}` 等价于 `o?`。注意，在逗号和两个数之间不能有空格。 |

有了这两张表，我们通常就能够读懂几乎所有的正则表达式了

### 3、生成HTTP响应报文

这个类的主要部分就是就是生成相应报文，也就是生成请求行，请求头和数据体，生成响应数据之后调用buffer类的append方法将数据保存在buffer中，然后调用该类的WriteFd方法通过writev()函数将数据进行写入并且发送。

```c++
class HttpResponse
{
public:
    HttpResponse(string &path, bool isKeepAlive);
    ~HttpResponse();
    char *File();//返回mmap映射的文件
    size_t FileLen();
    void MakeResponse(Buffer &buffer);                      //生成响应报文的主函数
    void ErrorContent(Buffer &buffer, std::string message); //在添加数据体的函数中，如果所请求的文件打不开，我们需要返回相应的错误信息
    ssize_t WriteFd(int fd, Buffer &buffer, int *Errno);    // 将存储在buffer中的响应报文数据通过writev函数写入并且发送

private:
    int m_code;                              // HTTP的状态
    void AddResponseLine(Buffer &buffer);    //添加请求行
    void AddResponseHeader(Buffer &buffer);  //添加请求头
    void AddResponseContent(Buffer &buffer); //添加请求数据体
    void ErrorHtml();                        //请求失败的信息
    string GetFileType();//判断文件类型
    string m_path;//通过解析的相对路径+根目录，确定真实路径
    string m_srcDir;//根目录
    bool m_isKeepAlive;
    //使用共享内存
    char *m_mFile;
    struct stat mmFileStat;//struct stat获取文件的信息

    // static成员函数和成员变量只与类关联，不与类的对象关联
    static const unordered_map<string, string> SUFFIX_TYPE; //后缀名到文件类型的映射关系
    static const unordered_map<int, string> CODE_STATUS;    //状态码到相应状态(字符串类型)的映射。
    static const unordered_map<int, string> CODE_PATH;      //状态码到相应发送文件的映射
};
```

该项目中回应头部信息主要有：

```c++
/*
Connection: keep-alive
keep-alive: max=6, timeout=120//删除
Content-type:
```



#### 3.1、添加相应数据体

```c++
void AddResponseContent(Buffer &buffer); //添加请求数据体
```

用open系统调用打开文件, 并返回描述符fd.用mmap建立内存映射（代替了read系统调用）, 并返回映射首地址指针start.其中mmap定义如下：

```c++
 void* mmap(void* start,size_t length,int prot,int flags,int fd,off_t offset);
 // PROT_READ 映射区域可被读取,MAP_PRIVATE 对映射区域的写入操作会产生一个映射文件的复制，
```

 start：映射区的开始地址，设置为0时表示由系统决定映射区的起始地址。

length：映射区的长度。//长度单位是 以字节为单位，不足一内存页按一内存页处理

#### 3.2、写入数据

```c++
ssize_t WriteFd(int fd, Buffer &buffer, int *Errno); 
```

利用writev（）函数将buffer中的相应报文数据写入到建立连接时候accept函数返回的文件描述符。writev函数定义如下。

```c++
ssize_t writev(int fildes, const struct iovec *iov, int iovcnt);
```

参数fildes是文件描述字。iov是一个结构数组，它的每个元素指明存储器中的一个缓冲区。结构类型iovec有下述成员，分别给出缓冲区的起始地址和字节数：

```c++
struct iovec {undefined
  void  *iov_base  /* 数据区的起始地址 */
  size_t iov_len   /* 数据区的大小 */
}
```

参数iovcnt指出数组iov的元素个数，元素个数至多不超过IOV_MAX。[Linux](http://www.2cto.com/os/linux/)中定义IOV_MAX的值为1024。本项目中最后一个iov存储文件数据

### 4、epoller详解

[epoll](https://so.csdn.net/so/search?q=epoll&spm=1001.2101.3001.7020) 是 Linux 内核为处理大批量文件描述符而作了改进的 poll，是 Linux 下多路复用 IO接口 select/poll 的增强版本。epoll 事件触发并发处理操作过程总共需要三个接口，下面详细说明这三个接口的使用。

头文件：

```c++
#include <sys/epoll.h>
```

#### 4.1、epoll 事件触发并发处理操作过程总共需要三个接口

```c++
1、int epoll_create(int size);
```

 epoll 是linux特有的IO复用函数。它的实现与使用上与select、poll有很大差异。首先，epoll使用一组函数来完成任务。而不是单个函数。其次，epoll把用户关心的文件描述符上的事件放在内核中的一个事件表中，从而无需像select和poll那样每次调用都要传入文件描述符集或事件集。但epoll需要使用一个额外的文件描述符，来唯一标识内核中的这个事件表，这个事件表使用epoll_create函数创建。epoll_create 函数就是用来获取内核事件表的特殊文件描述符，该函数返回的文件描述符将用作其他 epoll 系统调用的第一个参数，以指定要访问的内核事件表。

```c++
2、int epoll_ctl(int epfd, int op, int fd, struct epoll_event *event);
```

epoll 的事件注册函数，用来操作内核事件表。它不同与 select() 是在监听事件时告诉内核要监听什么类型的事件，而是在这里先注册要监听的事件类型。

1. epfd： 要操作的内核事件表的文件描述符，即 epoll_create 的返回值
2. op：指定操作类型，操作类型有三种：
   -> EPOLL_CTL_ADD：往内核事件表中注册指定fd 相关的事件
   -> EPOLL_CTL_MOD：修改指定 fd 上的注册事件
   -> EPOLL_CTL_DEL：删除指定 fd 的注册事件
3. fd：所要操作的文件描述符，也就是要内核事件表中监听的 fd
4. event：指定所要监听的事件类型，epoll_event 结构指针类型。struct epoll_event 结构如下：
   
   

```c++
 struct epoll_event {
    __uint32_t events; /* Epoll events epoll事件*/
    epoll_data_t data; /* User data variable用户数据 */
};
```

 其中events表示感兴趣的事件和被触发的事件，可能的取值为：


```
EPOLLIN     //表示对应的文件描述符可以读（包括对端SOCKET正常关闭）；
EPOLLOUT    //表示对应的文件描述符可以写；
EPOLLPRI    //表示对应的文件描述符有紧急的数据可读（这里应该表示有带外数据到来）；
EPOLLERR    //表示对应的文件描述符发生错误；
EPOLLHUP    //表示对应的文件描述符被挂断；
EPOLLET     //将EPOLL设为边缘触发(Edge Triggered)模式，这是相对于水平触发(Level Triggered)来说的。
EPOLLONESHOT//只监听一次事件，当监听完这次事件之后，如果还需要继续监听这个socket的话，需要再次把这个socket加入到EPOLL队列里。
```

epoll_ctl 成功时返回 0，失败则返回 -1，并设置 errno.

```c++
3、int epoll_wait(int epfd, struct epoll_event* events, int maxevents, int timeout);
```

等待事件的发生，它在一段超时时间之内等待一组文件描述符上的事件，epoll_wait 函数如果检测到事件，就将所有就绪的事件从内核事件表(epfd 参数决定)中复制到第二个参数 events 指向的数组中。epoll采用回调方式来检测就绪事件，算法复杂度为o(1).

参数
(1) epfd
要操作的内核事件表的文件描述符，即 epoll_create 的返回值

(2) events
内核事件表中得到的检测事件集合

(3) maxevents & timeout
maxevents 告诉内核 events 的最大 size，指定最多监听多少个事件，它必须大于0，timeout 指定超时时间

返回值
成功时返回就绪的文件描述符的个数，失败返回 -1 并设置 errno

#### 4.2、epoll对文件描述符的操作有两种模式

LT(level triggered，水平触发模式)是缺省的工作方式，并且同时支持 block 和 non-block socket。在这种做法中，内核告诉你一个文件描述符是否就绪了，然后你可以对这个就绪的fd进行IO操作。如果你不作任何操作，内核还是会继续通知你的，直到你处理为止，所以，这种模式编程出错误可能性要小一点。

ET(edge-triggered，边缘触发模式)是高速工作方式，只支持no-block socket（非阻塞）。如果文件描述符是阻塞的，那么读或写操作将会因为没有后续的事件而一直处于阻塞的状态，在这种模式下，当描述符从未就绪变为就绪时，内核通过epoll告诉你。然后它会假设你知道文件描述符已经就绪，并且不会再为那个文件描述符发送更多的就绪通知，等到下次有新的数据进来的时候才会再次出发就绪事件。epoll使用的是边缘触发ET，所以在读结束的时候根据需要改变epoll的事件

接口代码如下：

```c++
class Epoller
{
private:
    int m_epollerFd;                          //这是标志epoll的描述符
    std::vector<struct epoll_event> m_events; //就绪的事件,epoll_event结构体。epoll_wait 函数如果检测到事件，就将所有就绪的事件从内核事件表中复制到该数组中

public:
    Epoller(int maxEvent = 1024);
    ~Epoller();
    bool AddFd(int fd, uint32_t events);     //将描述符fd添加到epoll监控
    bool ModifydFd(int fd, uint32_t events); //修改描述符对应的事件
    bool DeleteFd(int fd);                   //将描述符fd移除epoll的监控
    int Wait(int timewait = -1);             //用于返回监控的结果，成功时返回就绪的文件描述符的个数
    int GetEventFd(size_t i) const;          //获取fd的函数
    uint32_t GetEvents(size_t i) const;      //获取events事件的函数
};
```



### 5、timer详解

为了提高Web服务器的效率，我们考虑给每一个HTTP连接加一个定时器。定时器给每一个HTTP连接设置一个过期时间，然后我们定时清理超过过期时间的连接，会减少服务器的无效资源的耗费，提高服务器的运行效率。我们还需要考虑一下如何管理和组织这些定时器。设置定时器的主要目的是为了清理过期连接，为了方便找到过期连接，首先考虑使用优先队列，按过期时间排序，让过期的排在前面就可以了。但是这样的话，虽然处理过期连接方便了，当时没法更新一个连接的过期时间。最后，选择一个折中的方法。用vector容器存储定时器，然后在这之上实现堆结构，这样各个操作的代价就得到了相对均衡。

#### 5.1、定时器节点

为了实现定时器的功能，我们首先需要辨别每一个HTTP连接，每一个HTTP连接会有一个独有的描述符（socket），我们可以用这个描述符来标记这个连接，记为`id`。同时，我们还需要设置每一个HTTP连接的过期时间。为了后面处理过期连接的方便，我们给每一个定时器里面放置一个回调函数，用来关闭过期连接。为了便于定时器结点的比较，主要是后续堆结构的实现方便，我们还需要重载比较运算符。

```c++
struct TimerNode
{
    int id;                                                //用来标记定时器，每个HTTP连接对应的socket描述符为id
    std::chrono::high_resolution_clock::time_point expire; //设置过期时间
    std::function<void()> cb;                              //设置一个回调函数方便删除定时器时将对应的HTTP连接关闭
    //重载比较节点函数
    bool operator<(const TimerNode &t){
        return expire<t.expire;
    }
};
```

#### 5.2、回调函数

回调函数与function使用，实际项目中，经常有用到回调函数的需求，如：

- 双方通讯中，等待接受对方的数据并处理，如使用socket进行的TCP通信
- 定时器事件，当定时器计时结束后，需要处理某任务
- 信号的触发，需要执行某任务

```c++
std::function<return_type(args_type)>
```

其中return_type 是函数指针的返回值类型，像上面案例中`func`函数的`void`类型。
其中args_type 是函数指针的参数类型，有多个函数参数，就可以有多个数据类型

**其实，提供回调函数就是提供了处理函数的指针地址，事件发生后，会自动调用函数指针达到调用函数的目的。**

### 6、WerServer详解

```c++
class WebServer
{

public:
    WebServer(int port_, int trigMode_, int timeOutMs_, bool optLinger_, int threadNum_);
    ~WebServer();
    void Start();

private:
    bool InitSocket(); //对服务器的socket进行设置，可以得到最终的listenFd
    void InitEventMode(int trigMode);
    void AddClientCon(int cfd, sockaddr_in addr); //添加一个HTTP连接
    void CloseCon(int cfd);                       //关闭一个HTTP连接
    int SetFdNonblock(int fd);                    //设置描述符为非阻塞模式，本次将监听描述符和客户端描述符都设置成非阻塞模式
    void HandleListen();                          //处理监听的新的HTTP连接
    void HandleData(int cfd);                     //处理客户端的数据
    void SendError(int cfd, char *info);
    int m_port;
    int m_timeoutMs; //毫秒，定时器的默认过期时间
    int m_trigMode;
    int m_threadNum;
    int m_isClose;
    int m_listenFd;
    bool m_openLinger;            // tcp连接断开是优雅断开还是强制断开
    uint32_t m_listenEvent;       //监听的事件
    uint32_t m_connectionEvent;   // HTTP连接的事件类型
    std::atomic<int> m_userCount; //连接数
    static const int MAX_FD = 65536;
    std::unique_ptr<Epoller> m_epoller;
    std::unique_ptr<TimerManage> m_time;
};
```

![image-20220416200447924](F:/%E6%88%91%E7%9A%84%E6%96%87%E4%BB%B6_%E5%BC%A0%E5%85%B5/%E6%89%BE%E5%B7%A5%E4%BD%9C/%E5%9B%BE%E7%89%87/image-20220416200447924.png)

异步线程只有一个，由主线程充当，它负责监听所有socket上的事件。如果监听socket由可读事件发生，即有新的连接请求到来，主线程就接受以得到新的socket，然后往 epoll内核事件表中注册该 socket 上的读写事件。 如果连接 socket 上有读 写事件发生， 即有新的客户请求到来或有数据要发送至客户端， 主线程就将该连接 socket 插人请求队列中。 所有工作线程都睡眠在请求队列上， 当有任务到来时， 它们将通过竞争（比 如申请互斥锁）获得任务的接管权。 这种竞争机制使得只有空闲的工作线程才有机会来处理新任务， 这是很合理的。该图的半同步／半反应堆模式采用的事件处理模式是Reactor模式：它要求工作线程自己从socket上读取客户请求和往socket写入服务端应答。

本次项目中主线程只负责监听连接socket,调用epoll_wait();线程池中的工作线程负责从连接socket中读取数据，解析数据并且将数据发送回对应的socket。线程池中的线程通过竞争获取工作队列中的任务进行执行。

c++的API接口：

```c++
//WebServer初始化的时候创建监听套接字
int socket(AF_INET, SOCK_STREAM, 0); //创建监听套接字AF_INET:IPv4,SOCK_STREAM:基于字节流的连接，返回文件描述符
   //第一个参数指明协议族，第二个指明套接口类型，第三个可设置为0，表示选择当前前两个参数组合的系统默认值
int bind (int sockfd, const struct sockaddr * addr, socklen_t addrlen);//sockfd:即为socket描述字,他是通过socket()函数创建的,addr:一个const 						struct sockaddr*指针,描述了IP地址和端口号。addrlen:对应地址的长度
int listen(int sockfd, int backlog)//listen函数的第一个参数时即将要监听的socket描述字，第二个参数为相应的socket可以排队的最大连接数。
int connect(int sockfd, const struct sockaddr *addr, socklen_t addrlen)//第一个参数是客户端socket的描述子，第二个参数是socket的地址，第三个函数是socket的地址的长度
int cfd = accept(m_listenFd, (struct sockaddr *)&clientAddr, &len);//第一个参数监听描述符，返回客户端的协议地址，第三个表示地址的长度
```



### 7、线程池

```c++
#include <pthread.h>   //linux线程库
template <typename T>
class Threadpool
{
public:
    Threadpool(int thread_num = 8, int max_requests = 10000); // thread_num线程池中线程的数量，max_requests请求队列中最多允许的请求数量
    ~Threadpool();
    bool append(T *request); //请求队列中添加任务
private:
    static void *worker(void *arg); //工作线程运行的函数，它不断的从工作队列取出任务并执行
    void run();
    int m_thread_number;        //线程池中的线程数
    int m_max_requests;         //请求队列中的最大请求数
    pthread_t *m_threads;       //描述线程池的数组，pthread_t为线程ID类型
    std::list<T *> m_workqueue; //请求队列，将准备就绪的任务放在请求序列中
    locker m_queuelocker;       //保护请求队列的互斥锁
    sem m_queuestat;            //是否有任务需要处理，信号量
    bool m_stop;                //是否结束线程
};
```

信号量：往工作队列添加任务之后，增加信号量信号量加1，当信号量大于0时，其他正在调用sem_wait的等待信号量的线程将被唤醒。此时调用sem_wait函数等待信号量的线程唤醒，进行加锁，处理工作队列中的任务。

```c++
//将任务添加到工作队列中
bool Threadpool<T>::append(T *request)
{
    //操作工作队列时一定要加锁，因为它被所有线程共享
    m_queuelocker.lock();
    if (m_workqueue.size() >= m_max_requests) //超出最大数量限制
    {
        m_queuelocker.unlock();
        return false;
    }
    m_workqueue.push_back(request); //工作队列添加任务
    m_queuelocker.unlock();
    m_queuestat.post(); //增加信号量
    return true;
}

```

互斥锁：在访问工作队列前加锁，访问完工作队列之后解锁。

```c++
//各个线程执行的代码
void Threadpool<T>::run()
{

    while (!m_stop)
    {
        std::cout << "thread run" << pthread_self() << std::endl;
        m_queuestat.wait();   // p操作，将sem减1，如果sem<0线程阻塞等待，否则调用sem_wait函数等待信号量的线程唤醒，进行加锁，处理工作队列中的任务。
        m_queuelocker.lock(); //加锁也是为了访问工作队列
        if (m_workqueue.empty())
        { //没有任务
            m_queuelocker.unlock();
            continue;
        }
        T *request = m_workqueue.front();
        m_workqueue.pop_front();
        m_queuelocker.unlock();
        if (!request)
        {
            continue;
        }
        request->process();
    }
}
```

cloc命令统计代码

```shell
cloc .   //后跟文件夹
```

```c++
pthread_create(m_threads + i, NULL, worker, this) != 0)
```

pthread_create是UNIX环境创建线程的函数

第一个参数为指向**线程标识符的指针**。

第二个参数用来设置**线程属性**。

第三个参数是**线程运行函数的起始地址**。

最后一个参数是**运行函数的参数**。

若线程创建成功，则返回0。若线程创建失败，则返回出错编号.因为pthread并非Linux系统的默认库，而是POSIX线程库。在Linux中将其作为一个库来使用，因此加上 -lpthread（或-pthread）以显式链接该库。

**该线程池利用互斥锁实现多线程之间的互斥，信号量实现多线程之间的同步。**

### 8、数据库

mysql：

```mysql
sudo mysql -u root -p //登录
create database name;//创建name表
```

```c++
class SQLconnect
{
private:
    SQLconnect(/* args */);
    ~SQLconnect();
    int m_MaxConn;  //最大连接数
    int m_CurConn;  //当前已使用的连接数
    int m_FreeConn; //当前空闲的连接数
    locker lock;
    std::queue<MYSQL *> connQueue; //连接池队列
    sem m_queuestat;

public:
    std::string m_url;                //主机地址
    std::string m_Port;               //数据库端口号
    std::string m_User;               //登陆数据库用户名
    std::string m_PassWord;           //登陆数据库密码
    std::string m_DatabaseName;       //使用数据库名
    int m_close_log;                  //日志开关
    MYSQL *GetConnnect();             //获取数据库连接
    bool ReleaseConnect(MYSQL *conn); //释放连接
    int GetFreeConn();                //获取连接
    void DestroyPool();               //销毁所有连接
    //单例模式
    static SQLconnect *GetInstance();
    void init(std::string url, std::string user, std::string password, std::string databasename, int port, int maxconn, int close_log);
};
class ConnectRAII
{
public:
    ConnectRAII(MYSQL **con, SQLconnect *connPool);
    ~ConnectRAII();

private:
    MYSQL *connRAII;
    SQLconnect *poolRAII;
};
```

c++的API接口：

```c++
mysql_init(MYSQL *con );//初始化
//连接数据库
mysql_real_connect(con, “localhost”, user.c_str(), m_PassWord.c_str(), m_DatabaseName.c_str(), port, nullptr, 0);
//第一个参数为数据库连接
//第二个参数为主机
//用户名
//密码
//数据库名称
mysql_query(mysql, command))//数据库操作函数，command为数据库命令
    //从表中检索完整的结果集
                MYSQL_RES *result = mysql_store_result(mysql); //结果集
                //从结果集中获取每一行
                while (MYSQL_ROW row = mysql_fetch_row(result))//读取完会自动流向下一行
                {
                    std::cout << row[0] << std::endl;
                }
```

数据库连接池

> - 单例模式，保证唯一
> - 队列实现连接池
> - 连接池为静态大小
> - 互斥锁实现线程安全

### 9、面试问题相关

#### 1、线程池相关

- 手写线程池

- 线程的同步机制有哪些？

  信号量、锁

- 线程池中的工作线程是一直等待吗？

  是一直等待

- 你的线程池工作线程处理完一个任务后的状态是什么？

  会进入阻塞态，当HTTP连接有新的数据，主线程会将该连接添加到工作队列中，并且增加信号量。线程池中的线程检测到信号量增加，就绪工作线程会通过竞争获取资源进行处理。

- 如果同时1000个客户端进行访问请求，线程数不多，怎么能及时响应处理每一个呢？

  **目前实现的是一个工作线程同一时间只能处理一个客户连接**。一种相对高效的半同步/半异步模式，它的每一个工作线程都能同时处理多个客户连接。主线程只管理监听socket, 连接socket由工作线程来管理。当有新的连接到来时， 主线程就接受之并将新返回的连接socket派发给某个工作线程， 此后该新socket上
  的任何1/0操作都由被选中的工作线程来处理， 直到客户关闭连接。每个线程（主线程和工作线程）都维持自己的率件循环， 它们各自独立地监听不同的车件。因此， 在这种商效的半同步／半异步模式中， 每个线程都工作在异步模式。

  ![image-20220512105208153](F:/%E6%88%91%E7%9A%84%E6%96%87%E4%BB%B6_%E5%BC%A0%E5%85%B5/%E6%89%BE%E5%B7%A5%E4%BD%9C/image-20220512105208153.png)

  方法二：在事件处理模式中，使用异步处理模式，减少IO操作时间，工作线程只负责业务逻辑。同步写非阻塞模型优化成异步写非阻塞(aio_read)，也就是Proactor模式使用异步IO模型。

- 如果一个客户请求需要占用线程很久的时间，会不会影响接下来的客户请求呢，有什么好的策略呢?

  

- 如何确定线程池中线程的数量？

  - CPU密集型，线程数和CPU数目相同即可
  - I/O密集型，线程数目可以大一点。（线程等待时间/线程CPU时间 + 1）* CPU数目

#### 2、并发模型相关

- 简单说一下服务器使用的并发模型？

  并发模型是半同步半异步并发模型。并发模式中，同步指程序完全按照代码序列的顺序执行，异步指程序的执行需要系统事件来驱动。常见的系统事件有中断、信号。按照同步方式运行的线程称为同步线程，按照异步方式运行的线程称为异步线程．显然，异步线程的执行效率高，实时性强，这是很多嵌入式程序采用的模型。但编写以异步方 式执行的程序相对复杂，难以调试和扩展，而且不适合于大量的并发。而同步线程则相反， 它虽然效率相对较低，实时性较差，但逻辑简单。因此，对于像服务器这种既要求较好的实时性，又要求能同时处理多个客户诘求的应用程序，我们就应该同时使用同步线程和异步线程来实现，即采用半同步／半异步模式来实现。

  ​		半同步／半异步模式中，同步线程用于处理客户逻辑，异 步线程用于处理IO事件，异步线程监听到客户请求后， 就将其封装成请求对象并插人请求队列中。请求队列将通知某个工作在同步模式式的工作线程来读取并处理该请求对象。

  ​		

  ​        如果结合考虑两种事件处理模式和几种IO模型， 则半同步／半异步模式就存在多种变体。 其中有一种变体称为半同步／半反应堆 (half-sync/haIf-reactive) 模式：

  1、异步线程只有一个，由主线程来充当，它负责监听所有 socket 上的事件。

  2、所有工作线程都睡眠在请求队列上， 当有任务到来时， 它们将通过竞争（比 如申请互斥锁）获得任务的接管权。 这种竞争机制使得只有空闲的工作线程才有机会来处理新任务， 

- reactor、proactor、主从reactor模型的区别？

- 你用了epoll，说一下为什么用epoll，还有其他复用方式吗？区别是什么？

- 高并发优化

  集群服务器，负载均衡服务器nginx（即分布式架构）

#### 3、HTTP报文解析

- 用了状态机啊，为什么要用状态机？

  状态机是逻辑单元内部的一种高效的编程方式，主要是HTTP数据的解析用到状态机

- 状态机的转移图画一下

  初始状态是解析请求行状态，读取完第一行之后状态转移到解析请求头状态，当读取到空行，状态转移到解析数据体状态；请求头中有个content-length字段是为请求数据的长度，当解析完之后进入结束状态。

- https协议为什么安全？

- https的ssl连接过程

- GET和POST的区别

#### 4、定时器相关

定时器工作原理：

- 为什么要用定时器？

  ​	清理超时的HTTP连接，也是服务器资源的一种节省

- 说一下定时器的工作原理

  首先epoll会检测连接的HTTP，如果是新的连接会插入到堆结构中，之后每次循环前都先求出堆中求出下一个清理HTTP需要的时间time（如果time等于0，就会调用回调函数清理该连接，并对堆结构进行更新）,并且让epoll_wait函数在time这一段超时时间之内等待一组文件描述符上的事件。这样能保证堆及时的更新需要清理下一个HTTP的时间

- 堆结构，删除和添加的时间复杂度说一下？还可以优化吗？

  堆是一个 `完全二叉树`，每一个节点的值都必须 `大于等于` 或者 `小于等于` 其孩子节点的值，`插入`的[时间复杂度](https://so.csdn.net/so/search?q=时间复杂度&spm=1001.2101.3001.7020)：O(lgn)，`删除` 的时间复杂度：O(lgn)，利用小顶堆结构实现，堆的排序依据是清理下一个HTTP连接需要的时间，那么值越小越先被清理，应该在堆顶

### 10、压力测试

Webbench是有名的网站压力测试工具，它是由[Lionbridge](http://www.lionbridge.com/)公司开发。

> - 测试处在相同硬件上，不同服务的性能以及不同硬件上同一个服务的运行状况。
> - 展示服务器的两项内容：每秒钟响应请求数和每秒钟传输数据量。
> - 每秒钟响应请求数： pages/min
> - 每秒钟传输数据量：1031990 bytes/sec
>
> 

QPS：全名 Queries Per Second，意思是“每秒查询率”，是一台服务器每秒能够响应的查询次数，是对一个特定的查询服务器在规定Queries Per Second时间内所处理流量多少的衡量标准。

QPS = 并发量 / 平均响应时间

**Webbench最多可以模拟3万个并发连接去测试网站的负载能力**.使用 fork() 模拟多个客户端，可以使用 HTTP/0.9-HTTP/1.1 请求

-c表示并发数Z

-t表示运行测试URL的时间(秒)

压测结果：

ubuntu:18  cpu:i5-9400F  内存8G  六核心，在同一电脑进行压力测试

./webbench -c 100  http://192.168.1.100:8080/      100个客户端

![image-20220522151534070](F:/%E6%88%91%E7%9A%84%E6%96%87%E4%BB%B6_%E5%BC%A0%E5%85%B5/%E6%89%BE%E5%B7%A5%E4%BD%9C/image-20220522151534070.png)

./webbench -c 1000  http://192.168.1.100:8080/      1000个客户端

![image-20220522151420257](F:/%E6%88%91%E7%9A%84%E6%96%87%E4%BB%B6_%E5%BC%A0%E5%85%B5/%E6%89%BE%E5%B7%A5%E4%BD%9C/image-20220522151420257.png)

./webbench -c 10000   http://192.168.1.100:8080/       10000个客户端

![image-20220522151727834](F:/%E6%88%91%E7%9A%84%E6%96%87%E4%BB%B6_%E5%BC%A0%E5%85%B5/%E6%89%BE%E5%B7%A5%E4%BD%9C/image-20220522151727834.png)

可以实现上万的并发连接

## 2、教研室项目

### 1、研究背景及意义

#### 1.1、SAR图像成像原理

**什么是SAR?** SAR合成孔径雷达，利用合成孔径原理，实现高分辨率的微波成像，是一种主动式的对地观测系统。

​		SAR的成像原理比较简单，主要是通过向地面发射电磁波，并接收地物的散射的电磁波，利用得到的散射数据，经过相关的处理来得到SAR图像。SAR相比原来的真实孔径雷达运用了两个相对比较先进的技术，即即距离方向上的调频技术与方位向上的用小孔径雷达天线虚拟成大的雷达天线，这两个技术的采用使得SAR图像的距离向与方位向的分辨率得到了很大的提升。SAR图像也逐渐的被应用到各种领域，在人们的工作与生活中发挥着重大的作用。

​		SAR是主动式侧视雷达系统，微波波长范围在1毫米至1米之间，（哨兵1波长5.6cm,分辨率5*20m;高分3,分辨率可达1m）微波是指频率为300MHz至300GHz的电磁波，是无线电波中一个有限频带的简称，是分米波、厘米波、毫米波的统称.

​		SAR影像的每一像素不仅包含反映地表微波反射强度即所谓的灰度值（后向散射系数），而且还包含与雷达斜距(一般取样到垂直于平台飞行方向的斜距上)有关相位值，这两个信息分量可用一个复数 (a +b·i)来表达。



### 2、基于变化检测与极化分解技术的SAR图像滑坡提取方法研究

#### 2.1、论文及项目简介

​		本文提出了一种结合灰度共生矩阵（GLCM）和极化分解技术的山体滑坡检测方法。该方法充分利用了SAR图像的特征，将极化信息与纹理特征融合，利用GLCM确定滑坡候选区，然后对提取出的滑坡候选区域进行双极化H/α分解来分析该区域散射熵H和散射角α的变化情况，来确定最终的滑坡区域。论文中以四川省广元市为研究区，对滑坡前后的两景SLC Sentinel-1A C波段VV、VH双极化SAR图像进行变化检测，证明了该方法的有效性。

#### 2.2、算法流程

##### 2.3.1、灰度共生矩阵

​		灰度共生矩阵（GLCM）是一种通过研究灰度的空间相关性描述纹理特征的重要方法。它描述的是像素和角度的矩阵函数，通过计算图像中一定距离和一定方向的两点灰度之间的相关性，从而反映图像灰度在方向、间隔、变化幅度及快慢上的综合信息。利用一定的算法提取SAR图像的纹理特征可以对其进行分类与变化检测。GLCM定义为图像中相距为d的两个灰度像素同时出现的联合概率密度分布的估计，通过计算相对距离和特定空间关系的像素对在图像中出现的概率来求出GLCM，然后利用这个矩阵求出可以描述图像纹理特征的特征值。

​		极化方式：如果发射的是水平极化方式的电磁波，与地物表面发生作用后会使电磁波极化方向产生不同程度的旋转，形成水平和垂直两个分量，用不同极化方式的天线接收，形成HH和HV两种极化方式的图像。若雷达发射的是垂直极化方式的电磁波，同理，会产生VV和VH两种极化方式的图像。当极化雷达脉冲被土壤或岩石等材料的粗糙表面散射时(表面散射)，返回天线的大部分散射能量与发射脉冲具有相同的极化。但是当脉冲击中植物时，它会不同程度地穿透(取决于长)，并与树叶、细枝和树干分枝发生多次碰撞，产生许多散射活动。虽然物理机制尚不清楚，但这种体散射会导致雷达信号的部分去极化，从而使一些散射波向各个方向振动。去极化在某种程度上降低了返回到雷达天线的类极化信号的强度，但是植被仍然在适当的波长产生强的同极化信号

##### 2.3.2、双极化分解

​	极化方法中散射熵H和散射角α所构成的特征空间中不同地表覆盖区域所对应的散射机制不同。虽然全极化数据覆盖信息全面、更加有利于变化区域的检测，但受到很多实际因素的影响，实际应用成本较高。而对使用双极化进行分类与变化检测的研究较少，双极化的H/α分解已经被证明可以应用于表面和体积散射的理论模型中。首先求出极化散射矩阵，进而求出相干矩阵。

##### 2.3、项目难点

​	如何降低虚警率。

##### 2.4、改进

​    将图像的灰度信息与极化信息进行了融合。

### 3、SAR大气校正

#### 3.1、论文及项目介绍

​		大气效应是影响InSAR技术提取高程和形变信息的主要因素之一。**其产生原因是两幅SAR图像由于成像时大气状况不同而产生干涉结果中的大气延迟误差**。在干涉测量过程中必须考虑大气效应的影响，并尽可能削弱或去除大气效应。由于不同时间大气的分布存在随机性，在相位图中很难直接分辨出大气相位，在小范围的地面研究中，很难利用气象数据对大气进行校正。因此可以采用时序差分干涉算法，利用研究区域地表散射特性稳定的点，对大气相位进行校正[5]。采用时序分析方法测量和去除大气效应是非常有效的方法。

​      论文是在SAR大气校正的基础上进行了应用来验证该大气校正方法的有效性。

​		本文采用永久散射体技术（PS-InSAR）提取了输电杆塔塔基形变，并将提取结果与实测结果进行了对比，验证了提取结果的正确性。论文选用2021年1月至12月期间的26景SAR图像对四川省广元市内发生山体滑坡的区域附近高压输电杆塔塔基形变进行了提取，利用StaMPS软件进行了时序分析，选用GACOS产品进行了大气校正，并将最终的形变结果与安装在输电杆塔上的传感器监测的结果进行对比，说明了该方法的有效性，并对电力维修人员提供一定的指导建议。

#### 3.2、算法流程

​		传统的InSAR方法能够在良好的相干区域进行形变监测，但是在非人工区域，如地表被植被覆盖区由于失相关的原因无法很好的应用。StaMPS是由Hooper等人于2004年提出的时序差分干涉算法[3]，主要用于非城市环境中的形变监测，其核心思想主要是利用覆盖同一地区的多景SAR影像,基于相位稳定性来进行PS点的选取，该方法可以有效的识别散射强度低但稳定性高的目标点，如房屋、道路、桥梁、输电塔等。然后对这些PS点进行时序分析。总而言之，StaMPS算法最主要的是对生成的干涉图进行PS点的高效选择和相位解缠。输电杆塔塔基形变提取流程主要分为两部分，第一部分为差分干涉对的生成，StaMPS主要处理第二部分，即PS点的选择和时序分析。

#### 3.3、创新点

​    应用创新。
